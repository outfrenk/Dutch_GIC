{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIC: \n",
    "    def __init__(self,netpath,base,respath,date=None,qdate=None):\n",
    "        \"\"\" Sets basic paths for location of files and sets dates\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        netpath : string (required) \n",
    "           location to folder where powernetwork csv files are\n",
    "        base : string (required)\n",
    "           general location to folder where data magnetic stations should be unpacked\n",
    "        respath : string (required)\n",
    "           location to folder where results need to be written\n",
    "        date : string (optional)\n",
    "           date of event for GIC calculation. Should be given as dd-mm-yyyy. Standard set as None type\n",
    "        qdate : string (optional) \n",
    "           quiet magnetic day --> used to substract base magnetic value from active day (given by date). Should be given as dd-mm-yyyy. Standard set as None type\n",
    "\n",
    "        Created Folders \n",
    "        ---------------\n",
    "        \"{self.base}/{self.date}\" : folder where data magnetic station of active day is unpacked\n",
    "        \"{self.base}/{self.qdate}\" : folder where data magnetic station of quiet day is unpacked\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.minute : boolean\n",
    "           if True, data is recorded per minute; if False, data is recorded per second (set at False)\n",
    "        self.samples : integer \n",
    "           nr of samples per day (set at zero)\n",
    "        self.days : integer \n",
    "           number of days to be calculated (set at one)\n",
    "        self.lentrafo : integer\n",
    "           number of transformers in powernetwork csv file\n",
    "        self.day : string \n",
    "           day number of event\n",
    "        self.month : string\n",
    "           month number of event\n",
    "        self.year : string \n",
    "           year of event\n",
    "        self.datevar : string \n",
    "           date returned as yyyy-mm-dd\n",
    "        self.statpath : string\n",
    "           exact location to folder where data magnetic station of active day is unpacked\n",
    "        self.quietpath : string\n",
    "           exact location to folder where data magnetic station of quiet day is unpacked\n",
    "        self.netpath, self.base, self.respath, self.date, self.qdate (see Parameters) : all strings\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        self.netpath=netpath\n",
    "        self.base=base\n",
    "        self.respath=respath\n",
    "        self.date=date\n",
    "        self.qdate=qdate\n",
    "        self.minute=None\n",
    "        self.samples=0\n",
    "        self.days=1\n",
    "        self.lentrafo=len(pd.read_csv(self.netpath+'/spreadsheettrafo.csv', delimiter = ';')) \n",
    "        if not date == None:\n",
    "            try:\n",
    "                datesplit=self.date.split('-')\n",
    "                self.day=str(datesplit[0]).zfill(2)\n",
    "                self.month=str(datesplit[1]).zfill(2)\n",
    "                self.year=str(datesplit[2])\n",
    "                self.datevar=f'{self.year}-{self.month}-{self.day}' #get day string in reverse order, so yyyy-mm-dd\n",
    "            except:\n",
    "                logging.warning('Date has not been inputted correctly, it should be dd-mm-yyyy')\n",
    "            try:\n",
    "                self.statpath=f'{self.base}/{self.date}'\n",
    "                os.mkdir(f'{self.base}/{self.date}')\n",
    "            except:\n",
    "                logging.warning(f\"Directory '{self.statpath}' might already exist, or cannot be formed\")\n",
    "        else:\n",
    "            self.day = self.month = self.year = self.datevar = self.statpath = None\n",
    "            \n",
    "        if not self.qdate==None:\n",
    "            self.quietpath=f'{self.base}/{self.qdate}'\n",
    "            try:\n",
    "                os.mkdir(f'{self.base}/{self.qdate}')\n",
    "            except:\n",
    "                logging.warning(f\"Directory '{self.quietpath}' might already exist, or cannot be formed\")\n",
    "        else:\n",
    "            self.quietpath=None\n",
    "        #create topomap for plotting GICs in correct colour, blue is into network, red is into ground\n",
    "        f=open(\"topo.cpt\",\"w+\")\n",
    "        f.write(\"-10000 0/0/100 0 0/0/100\\n\")\n",
    "        f.write(\"0 100/0/0 10000 100/0/0\")\n",
    "        f.close()\n",
    "\n",
    "    def BtoE(self,model,scaling=1):\n",
    "        \"\"\" Transforms magnetic field values to electric field value using a given conductivity model. \n",
    "        Theory by Weaver's 'Mathematical methods for geo-electromagnetic induction' (1994) and Wait's 'Propagation of radio waves over a stratified ground' (1985)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        model : integer (required)\n",
    "           determines which conductivity model is used to transform magnetic field observations to electric field\n",
    "        scaling : float (optional)\n",
    "           factor that is multiplied with magnetic field observations/interpolations to create extreme events. Standard set at one (no extra scaling).\n",
    "        \n",
    "        NEEDS MAGNETIC INTERPOLATED VALUES (.csv and .csv.Y) TO WORK!\n",
    " \n",
    "        Functions\n",
    "        ----------\n",
    "        check_sampling() : obtain amount of samples, minute or second data, and amount of days from magnetic data\n",
    "        filt(f,y) : applies a Wiener filter to remove high frequency noise\n",
    "        Parzen(N) : creates a Parzen window for given length\n",
    "        transferfunction(f,model) : gives factor to transform magnetic to electric field\n",
    "        writing_electric(proc#,path,E,start,stop,lon,lat,localvar) : writes electric field into files per timestep\n",
    "        \n",
    "        Created Folders\n",
    "        ---------------\n",
    "        \"{self.respath}/{self.date}/electric_field_north\" : folder where electric field values in northern direction per timestep are stored\n",
    "        \"{self.respath}/{self.date}/electric_field_east\" : folder where electric field values in eastern direction per timestep are stored\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Electric_*.csv : csv file\n",
    "           writes electric files per timestep into folder \"{self.respath}/{self.date}/electric_field_north\" and \"{self.respath}/{self.date}/electric_field_east\"\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import os\n",
    "        from multiprocessing import Process\n",
    "        import pandas as pd\n",
    "        from threading import local\n",
    "        import logging\n",
    "        localvar=local()\n",
    "\n",
    "        # import magnetic field data in X/Y-direction (north)\n",
    "        magnetic_Xfiles=[]\n",
    "        magnetic_Yfiles=[]\n",
    "        self.check_sampling()\n",
    "        ############################# get the strings ###################################\n",
    "        if self.minute==True:\n",
    "            os.system(f\"ls {self.respath}/{self.date}/interpolation/minute_????.csv > {self.respath}/{self.date}/tempX.txt\")\n",
    "            os.system(f\"ls {self.respath}/{self.date}/interpolation/minute_????.csv.Y > {self.respath}/{self.date}/tempY.txt\")\n",
    "            f=open(f'{self.respath}/{self.date}/tempX.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Xfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempX.txt')\n",
    "            f=open(f'{self.respath}/{self.date}/tempY.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Yfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempY.txt')\n",
    "        else:\n",
    "            for item in range(self.samples//10000+1):\n",
    "                os.system(f\"ls {self.respath}/{self.date}/interpolation/second_{item}????.csv >> {self.respath}/{self.date}/tempX.txt\")\n",
    "                os.system(f\"ls {self.respath}/{self.date}/interpolation/second_{item}????.csv.Y >> {self.respath}/{self.date}/tempY.txt\")\n",
    "            f=open(f'{self.respath}/{self.date}/tempX.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Xfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempX.txt')\n",
    "            f=open(f'{self.respath}/{self.date}/tempY.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Yfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempY.txt')\n",
    "\n",
    "        magnetic_Xfiles=sorted(magnetic_Xfiles) #sort to number 0000-1440 or 86400\n",
    "        magnetic_Yfiles=sorted(magnetic_Yfiles)\n",
    "        \n",
    "        for file in magnetic_Xfiles:\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            break\n",
    "        for file in magnetic_Yfiles:\n",
    "            Yfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            break\n",
    "\n",
    "        lat=np.zeros(len(Xfile))\n",
    "        lon=np.zeros(len(Xfile))\n",
    "        MX_matrix=np.zeros((len(magnetic_Xfiles),len(Xfile)))#matrix for storing values (vertical same place, horizontal same time)\n",
    "        MX_parz=np.zeros((3*len(magnetic_Xfiles),len(Xfile)))\n",
    "        MXft_matrix=np.zeros((int(3*len(magnetic_Xfiles)/2)+1,len(Xfile)),dtype='complex')\n",
    "        EX_matrix=np.zeros((len(magnetic_Yfiles),len(Yfile)))\n",
    "        EX_parz=np.zeros((3*len(magnetic_Yfiles),len(Yfile)))\n",
    "        EXft_matrix=np.zeros((int(3*len(magnetic_Yfiles)/2)+1,len(Yfile)),dtype='complex')\n",
    "        MY_matrix=np.zeros((len(magnetic_Yfiles),len(Yfile))) #matrix for storing values (vertical same place, horizontal same time)\n",
    "        MY_parz=np.zeros((3*len(magnetic_Yfiles),len(Yfile)))\n",
    "        MYft_matrix=np.zeros((int(3*len(magnetic_Yfiles)/2)+1,len(Yfile)),dtype='complex')\n",
    "        EY_matrix=np.zeros((len(magnetic_Xfiles),len(Xfile)))\n",
    "        EY_parz=np.zeros((3*len(magnetic_Xfiles),len(Xfile)))\n",
    "        EYft_matrix=np.zeros((int(3*len(magnetic_Xfiles)/2)+1,len(Xfile)),dtype='complex')\n",
    "        ################################################################################# \n",
    "        ########################### get the values ######################################\n",
    "        ######################### first x-direction #####################################\n",
    "        print('setting up matrices!')\n",
    "        for counter,file in enumerate(magnetic_Xfiles):\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Xfile.to_numpy()\n",
    "            if np.isnan(values).any():\n",
    "                print(counter, np.argwhere(np.isnan(values)))\n",
    "            MX_matrix[counter,:]=values[:,2]/(10**9)*scaling #scaling factor\n",
    "        lat=values[:,1]\n",
    "        lon=values[:,0]\n",
    "        for counter,file in enumerate(magnetic_Yfiles):\n",
    "            Yfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Yfile.to_numpy()\n",
    "            MY_matrix[counter,:]=values[:,2]/(10**9)*scaling\n",
    "   \n",
    "        ############## start fourier transformation ######################\n",
    "        print('starting fourier transformation')\n",
    "\n",
    "    # try Parzen window now\n",
    "        MX_parz[0:len(magnetic_Xfiles),:]=MX_matrix[0,:]\n",
    "        MX_parz[2*len(magnetic_Xfiles):,:]=MX_matrix[-1,:]\n",
    "        MX_parz[len(magnetic_Xfiles):2*len(magnetic_Xfiles),:]=MX_matrix\n",
    "        MY_parz[0:len(magnetic_Yfiles),:]=MY_matrix[0,:]\n",
    "        MY_parz[2*len(magnetic_Yfiles):,:]=MY_matrix[-1,:]\n",
    "        MY_parz[len(magnetic_Yfiles):2*len(magnetic_Yfiles),:]=MY_matrix\n",
    "        for column in range(len(MX_matrix[0])):\n",
    "            MXft_matrix[:,column]=np.fft.rfft(MX_parz[:,column]*self.Parzen(len(MX_parz))) #multiply with hanning window to reduce edge effects\n",
    "        for column in range(len(MY_matrix[0])):\n",
    "            MYft_matrix[:,column]=np.fft.rfft(MY_parz[:,column]*self.Parzen(len(MY_parz)))\n",
    "\n",
    "        ######################### calculate Electric field in frequency direction #############################3\n",
    "        # make frequencyvector in seconds\n",
    "        df=1./(24*60*60.*self.days*3) # seconds! #aangepast\n",
    "        if self.minute:\n",
    "            fmax=1./(2*60.)\n",
    "        else:\n",
    "            fmax=1./(2*1)\n",
    "        freqvec=np.arange(0,fmax+0.5*df,df)\n",
    "\n",
    "        #filter signal for noise\n",
    "        MXft_matrix=self.filt(freqvec,MXft_matrix)\n",
    "        MYft_matrix=self.filt(freqvec,MYft_matrix)\n",
    "        \n",
    "        # t3_start=process_time() #1d conductivity model!\n",
    "        for row in range(1,len(MXft_matrix)): #zero is not allowed, same row = same frequency\n",
    "            EYft_matrix[row,:]=-1*MXft_matrix[row,:]*self.transferfunction(freqvec[row],model)\n",
    "        for row in range(1,len(MYft_matrix)): #zero is not allowed\n",
    "            EXft_matrix[row,:]=MYft_matrix[row,:]*self.transferfunction(freqvec[row],model)\n",
    "\n",
    "        ######################## fourier transform back ####################################\n",
    "        # t4_start=process_time()\n",
    "        for column in range(len(EYft_matrix[0])):\n",
    "            EY_parz[:,column]=np.fft.irfft(EYft_matrix[:,column])\n",
    "        for column in range(len(EXft_matrix[0])):\n",
    "            EX_parz[:,column]=np.fft.irfft(EXft_matrix[:,column])\n",
    "            \n",
    "        EX_matrix=EX_parz[len(magnetic_Xfiles):2*len(magnetic_Xfiles),:]\n",
    "        EY_matrix=EY_parz[len(magnetic_Yfiles):2*len(magnetic_Yfiles),:]\n",
    "\n",
    "        del MX_matrix, MX_parz, MXft_matrix, EX_parz, EXft_matrix, MY_matrix, MY_parz, MYft_matrix, EY_parz, EYft_matrix\n",
    "        ######################### writing E field to files #################################\n",
    "        # t5_start=process_time()\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/electric_field_east')\n",
    "        except:\n",
    "            logging.warning('Directory is already created, data could be overwritten.')\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/electric_field_north')\n",
    "        except:\n",
    "            logging.warning('Directory is already created, data could be overwritten.')\n",
    "\n",
    "        n=6\n",
    "        nrsteps=int(self.samples*self.days/n) #aangepast\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.writing_electric, args=(index+1, f'{self.respath}/{self.date}/electric_field_east', EY_matrix, nrsteps*index, nrsteps*(index+1), lon, lat, localvar))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.writing_electric, args=(index+1, f'{self.respath}/{self.date}/electric_field_north', EX_matrix, nrsteps*index, nrsteps*(index+1), lon, lat, localvar))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "    def calculate_GIC(self,guess=80, plotting=True):\n",
    "        \"\"\" Calculates geomagnetically induced current in a given powergrid\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function.\n",
    "        guess : integer (optional)\n",
    "           gives an estimation in how many pieces the integration of the electric field should be executed in the calcE function. Standard set at 80.\n",
    "        plotting : boolean (optional)\n",
    "           if True, figures are generated containing the spatial variation of GICs in the given powergrid per timestep. Standard set at True\n",
    "\n",
    "        NEEDS POWERGRID CSV FILES AND ELECTRIC FIELD TO WORK\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        check_sampling() : obtain amount of samples, minute or second data, and amount of days from magnetic data\n",
    "        GICfunction(proc#,start,stop,trafo,EX_matrix,EY_matrix,lat,lon,station_lat,station_lon,trafo_connect,trafo_cond,ground_cond,kabels,trafo_all_connections,guess,localvar,lock,plotting) : calculates the GICs in the network\n",
    "        \n",
    "        Created Folders\n",
    "        ---------------\n",
    "        \"{self.respath}/{self.date}/GIC\" : folder that contains results of GIC calculation\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        GIC_*.csv : csv file\n",
    "           textfiles containing GICs at every transformer station per timestep.\n",
    "        GIC_at_*.png : png file \n",
    "           if Plotting=True, images of spatial variation GICs in powergrid per timestep\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import logging\n",
    "        from threading import local\n",
    "        localvar=local()\n",
    "        from multiprocessing import Process\n",
    "        from multiprocessing import Lock\n",
    "        lock=Lock()\n",
    "        self.check_sampling()\n",
    "        # create basic file: coordinates of trafo and cables\n",
    "        netwerk=pd.read_csv(f'{self.netpath}/spreadsheetcables.csv', delimiter = ';')\n",
    "        coord2=pd.DataFrame(columns=['lon', 'lat'])\n",
    "        coord1=pd.DataFrame(columns=['lon', 'lat'])\n",
    "        for line in range(len(netwerk)): # put end locations under start location for gmt, so that you double the lines\n",
    "            coord1.at[2*line,'lon']=netwerk.at[line,'strtlon'] \n",
    "            coord1.at[2*line,'lat']=netwerk.at[line,'strtlat'] \n",
    "            coord1.at[2*line+1,'lon']=netwerk.at[line,'eindlon']\n",
    "            coord1.at[2*line+1,'lat']=netwerk.at[line,'eindlat'] \n",
    "            # if statement to spot discontinuities\n",
    "            if line>0 and coord1.at[2*line-1,'lat']!=coord1.at[2*line,'lat'] and coord1.at[2*line-1,'lon']!=coord1.at[2*line,'lon']:\n",
    "                coord3=pd.DataFrame([[coord1.at[2*line,'lon'], coord1.at[2*line,'lat']]], columns=['lon', 'lat']) #create new dataframe\n",
    "                coord1.at[2*line,'lon']='>'+str(coord1.at[2*line,'lon']) #add > for gmt\n",
    "                coord2=coord2.append(coord1.loc[2*line]) #append it\n",
    "                coord2=coord2.append(coord3) #append old one, otherwise no line will be drawn\n",
    "                coord2=coord2.append(coord1.loc[2*line+1]) #append the one after\n",
    "                del coord3\n",
    "            else:\n",
    "                coord2=coord2.append(coord1.loc[2*line])\n",
    "                coord2=coord2.append(coord1.loc[2*line+1])\n",
    "\n",
    "        #write to a file with no header and column titles\n",
    "        coord2.to_csv(path_or_buf=f'{self.netpath}/cables.csv', sep=' ', index=False, header=False)\n",
    "        \n",
    "        #################################### first reading in datasets #####################################################  \n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/GIC')\n",
    "        except:\n",
    "            logging.warning(f\"Directory '{self.respath}/{self.date}/GIC' has already been created, data could be destroyed!\")\n",
    "            print(f\"Directory '{self.respath}/{self.date}/GIC' has already been created, data could be destroyed!\")\n",
    "        logging.info('Reading in datasets!')\n",
    "        Electric_Xfiles=[]\n",
    "        Electric_Yfiles=[]\n",
    "        if self.minute:\n",
    "            os.system(f' ls {self.respath}/{self.date}/electric_field_north/*.csv > {self.respath}/{self.date}/tempX.txt')\n",
    "            os.system(f' ls {self.respath}/{self.date}/electric_field_east/*.csv > {self.respath}/{self.date}/tempY.txt')\n",
    "        else:\n",
    "            for item in range(self.samples//10000+1):\n",
    "                os.system(f' ls {self.respath}/{self.date}/electric_field_north/electric_{item}????.csv >> {self.respath}/{self.date}/tempX.txt')\n",
    "                os.system(f' ls {self.respath}/{self.date}/electric_field_east/electric_{item}????.csv >> {self.respath}/{self.date}/tempY.txt')\n",
    "            \n",
    "        f=open(f'{self.respath}/{self.date}/tempX.txt')\n",
    "        for item in f:\n",
    "            item=item.strip('\\n')\n",
    "            Electric_Xfiles.append(item)\n",
    "        f.close()\n",
    "        \n",
    "        f=open(f'{self.respath}/{self.date}/tempY.txt')\n",
    "        for item in f:\n",
    "            item=item.strip('\\n')\n",
    "            Electric_Yfiles.append(item)\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/tempX.txt')\n",
    "        os.system(f'rm {self.respath}/{self.date}/tempY.txt')\n",
    "        logging.debug('Electric files created!')\n",
    "\n",
    "        for counter,file in enumerate(Electric_Xfiles):\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Xfile.to_numpy()\n",
    "            break\n",
    "        EX_matrix=np.zeros((len(Electric_Xfiles),len(values)))    \n",
    "        EY_matrix=np.zeros((len(Electric_Xfiles),len(values)))\n",
    "        logging.debug('Electric matrices have been made in memory!')\n",
    "\n",
    "        for counter,file in enumerate(Electric_Xfiles):\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Xfile.to_numpy()\n",
    "            EX_matrix[counter,:]=values[:,2]\n",
    "        logging.debug('EX_matrix has been made!')\n",
    "        lat=values[:,1]\n",
    "        lon=values[:,0]\n",
    "        for counter,file in enumerate(Electric_Yfiles):\n",
    "            Yfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Yfile.to_numpy()\n",
    "            EY_matrix[counter,:]=values[:,2]\n",
    "        del item, f, Xfile, values, Yfile\n",
    "\n",
    "        ######################################### Getting the needed GIC matrices and code #################################\n",
    "        logging.info('Starting with the GIC code!')\n",
    "        kabels=pd.read_csv(self.netpath+'/spreadsheetcables.csv', delimiter = ';')\n",
    "        trafo=pd.read_csv(self.netpath+'/spreadsheettrafo.csv', delimiter = ';')\n",
    "        trafo_connect=np.zeros((len(trafo),len(trafo))) #connectivity trafo\n",
    "        trafo_all_connections=np.zeros((len(trafo),len(kabels))) #connections possible between trafo and every cable\n",
    "        trafo_cond=np.zeros((len(trafo),len(trafo))) # The conductivity matrix\n",
    "        station_lat=np.zeros(len(trafo)) #latitude stations in degrees\n",
    "        station_lon=np.zeros(len(trafo)) #longitude stations in degrees\n",
    "        ground_cond=np.zeros(len(trafo))\n",
    "        cable_icon=np.zeros(len(kabels)) # icon array for cable and trafo resp.\n",
    "        trafo_icon=np.zeros(len(trafo))\n",
    "\n",
    "        ##### connect trafo and cable number to position in matrix #####\n",
    "        for line in range(len(kabels)):\n",
    "            cable_icon[line]=kabels.at[line,'kabelnr']\n",
    "        for line in range(len(trafo)):\n",
    "            trafo_icon[line]=trafo.at[line,'trafonr']\n",
    "        ##### make trafo-trafo connectivity matrix ######\n",
    "        for line in range(len(trafo)): \n",
    "            temp=str(trafo.at[line,'verbonden trafo']) #get right column\n",
    "            temp=temp.split(\",\") #split values\n",
    "\n",
    "            for item in temp:\n",
    "                temp2=int(item)\n",
    "                trafo_connect[line,np.where(trafo_icon == temp2)[0]]=True #check for connection other trafo\n",
    "                del temp2\n",
    "            del temp\n",
    "        ###### make trafo-cable connectivity matrix ######\n",
    "        for line in range(len(trafo)):\n",
    "            temp=str(trafo.at[line,'alle aansluitingen'])\n",
    "            temp=temp.split(\",\")\n",
    "            for item in temp:\n",
    "                temp2=int(item)\n",
    "                trafo_all_connections[line,np.where(cable_icon == temp2)[0]]=True\n",
    "                del temp2\n",
    "            del temp\n",
    "        ###### make conductivity matrix ######\n",
    "        for row,line in enumerate(trafo_connect):\n",
    "            trafo_cond[row,row]=trafo.at[row,'conductivity total']\n",
    "            for column,item in enumerate(line):\n",
    "                if item:\n",
    "                    temp=trafo_all_connections[row,:]+trafo_all_connections[column,:]\n",
    "                    temp2=0\n",
    "                    for counter,value in enumerate(temp):\n",
    "                        if value == 2: # if 2 then we have found the connecting cables\n",
    "                            temp2+=1/(float(kabels.at[counter,'conductivity'])*kabels.at[counter,'kab/3'])  #because of serieschain we have to add 1/sigma\n",
    "\n",
    "                    trafo_cond[row,column]=-1/temp2 #add cable resistance to off-diagonal\n",
    "                    trafo_cond[row,row]+=1/temp2 #add cable resistance to trace\n",
    "                    del temp, temp2\n",
    "\n",
    "        ######### get necessary arrays ########\n",
    "        for item in range(len(trafo)):\n",
    "            station_lat[item]=trafo.at[item,'lat']\n",
    "            station_lon[item]=trafo.at[item,'lon']\n",
    "            ground_cond[item]=trafo.at[item,'conductivity total']\n",
    "        ############################### Run the function with multiple processors ##########################################\n",
    "        logging.info('Start multiprocessing!')\n",
    "        print(\"New data is added now!\")\n",
    "        n=6\n",
    "        nrsteps=int(self.samples*self.days/n)\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.GICfunction, args=(index+1,nrsteps*index,nrsteps*(index+1),trafo,EX_matrix,EY_matrix,lat,lon,station_lat,station_lon,trafo_connect,trafo_cond,ground_cond,kabels,trafo_all_connections,guess,localvar,lock,plotting))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        logging.info(\"Script has been completed!\")\n",
    "        print(\"Script has been completed!\")\n",
    "        \n",
    "    def calcE(self,kabels,EX_matrix,EY_matrix,lat,lon,time,guess,localvar): #E for all cables\n",
    "        \"\"\" Integrates the electric field over the given cables to obtain potentials\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        kabels : pandas dataframe (required)\n",
    "           contains information about the transmission cables, see spreadsheetcables.ods for clarification\n",
    "        EX_matrix : numpy matrix (required)\n",
    "           electric field in northern direction stored in a (tsteps,npts) matrix. tsteps are the amount of timesteps, npts are the number of spatial points for which the electric field is calculated\n",
    "        EY_matrix : numpy matrix (required)\n",
    "           electric field in eastern direction stored in a (tsteps,npts) matrix. tsteps are the amount of timesteps, npts are the number of spatial points for which the electric field is calculated\n",
    "        lat : numpy array (required)\n",
    "           latitude of spatial points where electric field is calculated\n",
    "        lon : numpy array (required)\n",
    "           longitude of spatial points where electric field is calculated\n",
    "        time : integer (required)\n",
    "           timestep for which the integration has to be carried out\n",
    "        guess : integer (required)\n",
    "           initial amount of integration intervals to calculate the electric potential\n",
    "        localvar : object (required)\n",
    "           object were every single processor can store its variables separately without mixing them up between processors\n",
    "        \n",
    "        NEEDS TO BE CALLED WITH GICfunction() TO WORK PROPERLY\n",
    "           \n",
    "        Returns\n",
    "        -------\n",
    "        localvar.E_all : numpy matrix\n",
    "           electric potential (V/m) of every transmission cable\n",
    "        \"\"\"\n",
    "        from scipy.interpolate import griddata\n",
    "        from scipy.integrate import simps\n",
    "        import numpy as np\n",
    "        import logging\n",
    "                         \n",
    "        localvar.heading=np.zeros(len(kabels))\n",
    "        localvar.old=np.zeros((len(kabels),2))\n",
    "        nr=guess # amount of nodes\n",
    "        while True:\n",
    "            localvar.E_all=np.zeros((len(kabels),2))\n",
    "            localvar.latrange=np.zeros((len(kabels),nr))\n",
    "            localvar.lonrange=np.zeros((len(kabels),nr))\n",
    "            localvar.GridEX=np.zeros((len(kabels),nr))\n",
    "            localvar.GridEY=np.zeros((len(kabels),nr))\n",
    "            for number in range(len(kabels)):\n",
    "                localvar.latrange[number,:]=np.linspace(kabels.at[number,'strtlat'],kabels.at[number,'eindlat'],nr) \n",
    "                localvar.lonrange[number,:]=np.linspace(kabels.at[number,'strtlon'],kabels.at[number,'eindlon'],nr) \n",
    "                localvar.heading[number]=kabels.at[number,'heading']\n",
    "            localvar.GridEX=griddata((lat,lon),EX_matrix[time,:],(localvar.latrange,localvar.lonrange),method='cubic') #interpolate value\n",
    "            localvar.GridEY=griddata((lat,lon),EY_matrix[time,:],(localvar.latrange,localvar.lonrange),method='cubic')\n",
    "            for number in range(len(kabels)):\n",
    "                localvar.E_all[number,0]+=abs(np.cos(np.radians(localvar.heading[number])))*simps(localvar.GridEX[number,:],np.linspace(0,kabels.at[number,'length'],nr))\n",
    "                localvar.E_all[number,1]+=abs(np.sin(np.radians(localvar.heading[number])))*simps(localvar.GridEY[number,:],np.linspace(0,kabels.at[number,'length'],nr))\n",
    "            if np.sum(abs(localvar.old-localvar.E_all))<10**-5: #only continue when difference in integration is lower than tolerance\n",
    "                logging.info(f'{nr-(guess-1)} iterations were used for time={time}')\n",
    "                break\n",
    "            else:\n",
    "                localvar.old[:,0]=localvar.E_all[:,0]\n",
    "                localvar.old[:,1]=localvar.E_all[:,1]\n",
    "                nr+=1\n",
    "        return localvar.E_all\n",
    "    \n",
    "    def check_sampling(self):\n",
    "        \"\"\" Checks magnetic data to get various 'self' objects, when functions are called separately.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "\n",
    "        NEEDS MAGNETIC INTERPOLATED DATA TO WORK\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self.samples : integer\n",
    "           amount of samples per day (either 1440 or 86400)\n",
    "        self.days : integer\n",
    "           amount of days for which GICs should be calculated\n",
    "        self.minute : boolean\n",
    "           if True, data is recorded per minute; if False, data is recorded per second        \n",
    "        \"\"\"\n",
    "        import os\n",
    "        self.samples=len([name for name in os.listdir(f'{self.respath}/{self.date}/interpolation') if os.path.isfile(os.path.join(f'{self.respath}/{self.date}/interpolation', name))])/2 #count amount of files in folder\n",
    "        if self.samples%(24*60*60)==0:\n",
    "            self.minute=False \n",
    "            self.days=int(self.samples/(24*60*60))\n",
    "            self.samples=24*60*60\n",
    "        elif self.samples%(24*60)==0:\n",
    "            self.minute=True\n",
    "            self.days=int(self.samples/(24*60))\n",
    "            self.samples=24*60\n",
    "        else:\n",
    "            raise Exception(\"Data is missing, or it is no minute or second data\")\n",
    "        \n",
    "    def download_data(self,day,month,year,station,types=True):\n",
    "        \"\"\" Automatically downloads magnetic data from the Intermagnet ftp server\n",
    "           ('ftp://ftp.seismo.nrcan.gc.ca/intermagnet')\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        day : string (required)\n",
    "           daynumber of to be downloaded date\n",
    "        month : string (required)\n",
    "           monthnumber of to be downloaded date\n",
    "        year : string (required)\n",
    "           year of to be downloaded date\n",
    "        station : string of length 3 (required)\n",
    "           abbreviation of magnetic observatory in IAGA code\n",
    "        types : boolean (optional)\n",
    "           if True, minute data is to be downloaded (not available before 1991); if False, second data is to be downloaded (not available before 2011)\n",
    "           \n",
    "        Created Folders\n",
    "        ---------------\n",
    "        '{self.base}/{day}-{month}-{year}' : folder that will contain downloaded data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        *dmin.min or *qsec.sec : text files\n",
    "           header information and magnetic observations for one day\n",
    "        \"\"\"\n",
    "        from urllib.request import urlretrieve\n",
    "        import os\n",
    "        import logging\n",
    "        day=str(day).zfill(2)\n",
    "        month=str(month).zfill(2)\n",
    "        try:\n",
    "            os.mkdir(f'{self.base}/{day}-{month}-{year}')\n",
    "        except:\n",
    "            logging.warning(f\"Directory '{self.base}/{day}-{month}-{year}' might already exist, or cannot be formed\")\n",
    "        logging.info(f'Downloading data for station {station} on {day}-{month}-{year}')\n",
    "        if types==True: #minute data\n",
    "            URL=\"ftp://ftp.seismo.nrcan.gc.ca/intermagnet/minute/definitive/IAGA2002\"\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/{year}/{month}/{station}{year}{month}{day}dmin.min.gz', f'{self.base}/{day}-{month}-{year}/{station}{year}{month}{day}dmin.min.gz')\n",
    "            except:\n",
    "                raise Exception('Data does not exist for given input, station might not be recorded yet. Input should have length: 3-2-2-4')\n",
    "            os.system(f'gunzip {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}dmin.min.gz')\n",
    "            os.system(f'rm {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}dmin.min.gz')\n",
    "            \n",
    "        else: #second data\n",
    "            URL=\"ftp://ftp.seismo.nrcan.gc.ca/intermagnet/second/quasi-definitive/IAGA2002\"\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/{year}/{month}/{station}{year}{month}{day}qsec.sec.gz', f'{self.base}/{day}-{month}-{year}/{station}{year}{month}{day}qsec.sec.gz')\n",
    "            except:\n",
    "                raise Exception('Data does not exist for given input, station might not be recorded yet. Input should have length: 3-2-2-4')\n",
    "            os.system(f'gunzip {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}qsec.sec.gz') \n",
    "            os.system(f'rm {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}qsec.sec.gz') \n",
    "\n",
    "    def filt(self,x,ft_matrix): \n",
    "        \"\"\" Applies Wiener filter to given data to remove noise\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy array (required)\n",
    "           contains frequency components from zero to larger\n",
    "        ft_matrix : numpy matrix (required)\n",
    "           contains Fourier transformed data (frequency domain) in a (fstep,pnts) matrix. fstep is amount of frequency steps, pnts is the amount of spatial points. \n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        func(x,a,b) : creates exponential function of type b*10^(a*x)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        signal : numpy matrix\n",
    "           (fstep,pnts) matrix containing Wiener filtered data\n",
    "        \"\"\"\n",
    "        from scipy.optimize import curve_fit\n",
    "        import numpy as np\n",
    "        signal=np.zeros((len(ft_matrix),len(ft_matrix[0])), dtype='complex')\n",
    "        n=len(x)\n",
    "        \n",
    "        PSD=2*np.nansum(abs(ft_matrix), axis=1)/len(ft_matrix) #create mean power spectrum density\n",
    "        a,sigma=curve_fit(self.func, x[2*int(n/3):], 2*np.nansum(abs(ft_matrix[2*int(n/3):]), axis=1)/len(ft_matrix)) #fit a exp line to end graph\n",
    "        Wiener=(PSD-self.func(x,*a))/PSD #create filter\n",
    "        for i in range(len(ft_matrix[0])):\n",
    "            signal[:,i]=ft_matrix[:,i]*Wiener #apply filter\n",
    "        return signal\n",
    "            \n",
    "    def find_quiet_date(self):\n",
    "        \"\"\" Find solar quiet day nearest to inputted assumed solar active day using the ftp server of Potzdam\n",
    "           ('ftp://ftp.gfz-potsdam.de/pub/home/obs/kp-ap/quietdst')\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        \n",
    "        NEED DATE OF ACTIVE DAY TO WORK\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Quiet.day : string\n",
    "           daynumber of nearest solar quiet day\n",
    "        Quiet.month : string\n",
    "           monthnumber of nearest solar quiet day\n",
    "        Quiet.year : string\n",
    "            year of nearest solar quiet day\n",
    "        \"\"\"\n",
    "        from urllib.request import urlretrieve\n",
    "        import os\n",
    "        import logging\n",
    "        import datetime\n",
    "        URL='ftp://ftp.gfz-potsdam.de/pub/home/obs/kp-ap/quietdst'\n",
    "        monthlist=[0,2,3,4,5,6,7,9,10,11,12,13,14]\n",
    "        try: #retrieve data from the Potzdam website\n",
    "            urlretrieve(f'{URL}/qd{self.year[0:3]}0{self.year[2]}9.txt', f'{self.base}/Kp_index_{self.year}.txt')\n",
    "        except:\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/qd{self.year[0:3]}0{self.year[2]}x.txt', f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            except:\n",
    "                raise Exception('URL could not be retrieved, check your date string!')\n",
    "        # find correct files on potzdam website and extract quiet days of the month for variety of situations\n",
    "        if self.month=='12' and self.year[3]=='9':\n",
    "            newyear=str(int(self.year)+1)\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}9.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            except:\n",
    "                try:\n",
    "                    urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}x.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "                except:\n",
    "                    raise Exception('URL could not be retrieved, check your date string!')\n",
    "            f=open(f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)-1]+2:\n",
    "                    words=line.split()\n",
    "                    option0=[''.join(i for i in words[2] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                    option0A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)-1, self.year]\n",
    "\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                    words=line.split()\n",
    "                    option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                    option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                    break\n",
    "            f=open(f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==4:\n",
    "                    words=line.split()\n",
    "                    option2=[''.join(i for i in words[2] if i.isdigit()), 1, int(self.year)+1]\n",
    "                    option2A=[''.join(i for i in words[3] if i.isdigit()), 1, int(self.year)+1]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{newyear}.txt')\n",
    "                    break\n",
    "            \n",
    "        elif self.month=='01' and self.year[3]=='0':\n",
    "            newyear=str(int(self.year)-1)\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}9.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            except:\n",
    "                try:\n",
    "                    urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}x.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "                except:\n",
    "                    raise Exception('URL could not be retrieved, check your date string!')\n",
    "            f=open(f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==130:\n",
    "                    words=line.split()\n",
    "                    option0=[''.join(i for i in words[2] if i.isdigit()), 12, int(self.year)-1]\n",
    "                    option0A=[''.join(i for i in words[3] if i.isdigit()), 12, int(self.year)-1]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{newyear}.txt')\n",
    "                    break\n",
    "            f=open(f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                    words=line.split()\n",
    "                    option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                    option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)+1]+2:\n",
    "                    words=line.split()\n",
    "                    option2=[''.join(i for i in words[2] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                    option2A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                    break\n",
    "        \n",
    "        else:\n",
    "            f=open(f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if self.month=='12':\n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)-1]+2:\n",
    "                        words=line.split()\n",
    "                        option0=[''.join(i for i in words[2] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                        option0A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                        words=line.split()\n",
    "                        option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                        option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                        \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10+1)*14+4:\n",
    "                        words=line.split()\n",
    "                        option2=[''.join(i for i in words[2] if i.isdigit()), 1, int(self.year)+1]\n",
    "                        option2A=[''.join(i for i in words[3] if i.isdigit()), 1, int(self.year)+1]\n",
    "                        f.close()\n",
    "                        os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                        break\n",
    "                elif self.month=='1':\n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+2:\n",
    "                        words=line.split()\n",
    "                        option0=[''.join(i for i in words[2] if i.isdigit()), 12, int(self.year)-1]\n",
    "                        option0A=[''.join(i for i in words[3] if i.isdigit()), 12, int(self.year)-1]\n",
    "                \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                        words=line.split()\n",
    "                        option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                        option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                        \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)+1]+2:\n",
    "                        words=line.split()\n",
    "                        option2=[''.join(i for i in words[2] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        option2A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        f.close()\n",
    "                        os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                        break\n",
    "                else:\n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)-1]+2:\n",
    "                        words=line.split()\n",
    "                        option0=[''.join(i for i in words[2] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                        option0A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                        words=line.split()\n",
    "                        option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                        option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                        \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)+1]+2:\n",
    "                        words=line.split()\n",
    "                        option2=[''.join(i for i in words[2] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        option2A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        f.close()\n",
    "                        os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                        break\n",
    "                        \n",
    "        #which option is closest to disturbed day?\n",
    "        logging.info(f\"optional quiet days are (previous/this/next month): {option0} OR {option0A} / {option1} OR {option1A} / {option2} OR {option2A}\")\n",
    "        datestring=[datetime.datetime(int(option0[2]),int(option0[1]),int(option0[0])),datetime.datetime(int(option1[2]),int(option1[1]),int(option1[0])),datetime.datetime(int(option2[2]),int(option2[1]),int(option2[0])),datetime.datetime(int(option0A[2]),int(option0A[1]),int(option0A[0])),datetime.datetime(int(option1A[2]),int(option1A[1]),int(option1A[0])),datetime.datetime(int(option2A[2]),int(option2A[1]),int(option2A[0]))]\n",
    "        Quiet=min(datestring, key=lambda x: abs(x - datetime.datetime(int(self.year),int(self.month),int(self.day))))\n",
    "        return Quiet.day, Quiet.month, Quiet.year\n",
    "        \n",
    "    def func(self,x,a,b):\n",
    "        \"\"\" Calculates a exponential function\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : float (required)\n",
    "           variable\n",
    "        a : float (required)\n",
    "           constant\n",
    "        b : float (required)\n",
    "           constant\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        b*10 ** (a*x) : float\n",
    "            exponential function\n",
    "        \"\"\"\n",
    "        return b*10 ** (a*x)\n",
    "    \n",
    "    def GICfunction(self,q,begin,end,trafo,EX_matrix,EY_matrix,lat,lon,station_lat,station_lon,trafo_connect,trafo_cond,\n",
    "                    ground_cond,kabels,trafo_all_connections,guess,localvar,lock,plotting):\n",
    "        \"\"\" Calculate and plot the GICs in the powergrid\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        q : integer (required)\n",
    "           processor number\n",
    "        begin : integer (required)\n",
    "           starting timestep of calculation\n",
    "        end : integer (required)\n",
    "           ending timestep of calculation\n",
    "        trafo : pandas dataframe (required)\n",
    "           dataframe containing information about the transformers, see spreadsheettrafo.ods for clarification\n",
    "        EX_matrix : numpy matrix (required)\n",
    "           electric field in northern direction stored in a (tsteps,npts) matrix. tsteps are the amount of timesteps, npts are the number of spatial points for which the electric field is calculated\n",
    "        EY_matrix : numpy matrix (required)\n",
    "           electric field in eastern direction stored in a (tsteps,npts) matrix. tsteps are the amount of timesteps, npts are the number of spatial points for which the electric field is calculated\n",
    "        lat : numpy array (required)\n",
    "           latitude of spatial points where electric field is calculated\n",
    "        lon : numpy array (required)\n",
    "           longitude of spatial points where electric field is calculated\n",
    "        station_lat : float (required)\n",
    "           latitude of tranformer station\n",
    "        station_lon : float (required)\n",
    "           longitude of tranformer station\n",
    "        trafo_connect : boolean numpy matrix (required)\n",
    "           symmetric matrix (len(trafo),len(trafo)) that determines whether tranformers are directly connected to each other (=True) or not (=False)\n",
    "        trafo_cond : numpy matrix (required)\n",
    "           conductivity matrix as defined by Boteler & Pirjola's 'Modeling geomagnetically induced currents' (2017)\n",
    "        ground_cond : numpy array (required)\n",
    "           conductivity of transformer to ground\n",
    "        kabels : pandas dataframe (required)\n",
    "           contains information about the transmission cables, see spreadsheetcables.ods for clarification\n",
    "        trafo_all_connections : boolean numpy array (required)\n",
    "           matrix (size: amount of transformers x amount of cables) that determines which cables are connected to a transformer (=True) or not (=False)\n",
    "        guess : integer (required)\n",
    "           initial amount of integration intervals to calculate the electric potential\n",
    "        localvar : object (required)\n",
    "           object were every single processor can store its variables separately without mixing them up between processors\n",
    "        lock : object (required)\n",
    "           locks a piece of code for other processors when one processor is working on it\n",
    "        plotting : boolean (required)\n",
    "           if True, GIC_at_*.png files are created\n",
    "\n",
    "        NEEDS TO BE CALLED WITH calculate_GIC() TO WORK PROPERLY \n",
    "\n",
    "        Functions\n",
    "        ---------\n",
    "        ObtainJ(proc#,kabels,EX_matrix,EY_matrix,lat,lon,localvar.time,trafo_connect,trafo_all_connections,trafo_cond,trafo,guess,localvar) : calculates induced currents in transmission cables\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        GIC_*.csv : csv file\n",
    "           textfiles containing GICs at every transformer station per timestep.\n",
    "        GIC_at_*.png : png file \n",
    "           if Plotting=True, images of spatial variation GICs in powergrid per timestep\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import os\n",
    "        import logging\n",
    "    ######################################### interpolation ############################################################\n",
    "        localvar.volt_result=np.zeros(len(trafo))\n",
    "        localvar.J_total=np.zeros(len(trafo))\n",
    "        logging.info(f'Thread {q} has started interpolation!')\n",
    "        for localvar.time in range(begin,end):#range(len(grid_EX)):\n",
    "            localvar.J_north, localvar.J_east=self.ObtainJ(q,kabels,EX_matrix,EY_matrix,lat,lon,localvar.time,trafo_connect,trafo_all_connections,trafo_cond,trafo,guess,localvar)\n",
    "            localvar.J_total=localvar.J_north+localvar.J_east\n",
    "            localvar.volt_result=np.linalg.solve(trafo_cond,localvar.J_total)\n",
    "            localvar.I_GIC=localvar.volt_result*ground_cond\n",
    "            if np.isnan(min(localvar.I_GIC)):\n",
    "                raise ValueError(\"OOPS, your current is NaN!\")\n",
    "    ##################################### getting max I_GIC and writing results ########################################\n",
    "            logging.info(f'Thread {q} is writing results to files for timestep {localvar.time}!')\n",
    "            localvar.maxAMP=1 #1\n",
    "            if self.minute:\n",
    "                localvar.tijd=str(localvar.time).zfill(4)\n",
    "            else:\n",
    "                localvar.tijd=str(localvar.time).zfill(5)\n",
    "            ##### Save files #######\n",
    "            localvar.GIC=pd.DataFrame(columns=['lon','lat','GIC',f'GIC/{localvar.maxAMP}'])\n",
    "            localvar.GIC.at[:,'lon']=station_lon\n",
    "            localvar.GIC.at[:,'lat']=station_lat\n",
    "            localvar.GIC.at[:,'GIC']=localvar.I_GIC\n",
    "            localvar.GIC.at[:,f'GIC/{localvar.maxAMP}']=localvar.I_GIC/localvar.maxAMP\n",
    "            localvar.GIC.to_csv(path_or_buf=f'{self.respath}/{self.date}/GIC/GIC_{localvar.tijd}.csv', sep=';', index=False, header=True)\n",
    "            logging.info(f'Thread {q} has written, now plotting GIC!')\n",
    "    ################################### Plotting results ###############################################################\n",
    "            if plotting==True:\n",
    "                lim1=3.3\n",
    "                lim2=7.5\n",
    "                lim3=50.5\n",
    "                lim4=54\n",
    "                legendlon=lim1+0.18\n",
    "                legendlat=lim4-0.1\n",
    "                textlon=legendlon+0.40 #0.33\n",
    "                textlat=legendlat-0.01\n",
    "\n",
    "                with lock:\n",
    "                    legend=open(f'{self.netpath}/legend.txt','w+')\n",
    "                    legend.write(f'{legendlon} {legendlat} 1 1')\n",
    "                    legend.close()\n",
    "                    legendtxt=open(f'{self.netpath}/legendtext.txt', 'w+')\n",
    "                    legendtxt.write(f'{textlon} {textlat} {localvar.maxAMP}A')\n",
    "                    legendtxt.close()\n",
    "\n",
    "                    ##### Use GMT to plot GICs ######\n",
    "                    if self.minute:\n",
    "                        minute=str(localvar.time%60).zfill(2)\n",
    "                        hour=str(int(localvar.time/60)%24).zfill(2)\n",
    "                        DAY=int(localvar.time/(60*24))\n",
    "                        title=f'GIC at {self.date} - {DAY}:{hour}:{minute}'\n",
    "                        proj='-JM15C -P'\n",
    "                        lims=f'-R{lim1}/{lim2}/{lim3}/{lim4}'\n",
    "                        psfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.ps' #aanpassen\n",
    "                        pngfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.png' #aanpassen\n",
    "                        os.system(f'gmt pscoast {proj} {lims} -W0.5p -K -Ggrey -Slightblue -Df -N1/0.25p> {psfile}' )\n",
    "                        os.system(f'gmt psbasemap {proj} {lims} -Ba1g1 -BWeSn+t\"{title}\" -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.netpath}/cables.csv {proj} {lims} -W0.5p -Wred -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.respath}/{self.date}/GIC/GIC_{localvar.tijd}.csv {proj} {lims} -Ctopo.cpt -Scc -O -K>> {psfile}')    \n",
    "                        os.system(f'gmt psxy {self.netpath}/legend.txt {proj} {lims} -Ctopo.cpt -W -Scc -O -K>> {psfile}')\n",
    "                        os.system(f'gmt pstext {self.netpath}/legendtext.txt {proj} {lims} -F+f30pHelvetica,black -O>> {psfile}')\n",
    "                    else:\n",
    "                        second=str(localvar.time%60).zfill(2)\n",
    "                        minute=str(int(localvar.time/60)%60).zfill(2)\n",
    "                        hour=str(int(localvar.time/(60*60))%24).zfill(2)\n",
    "                        DAY=int(localvar.time/(60*60*24))\n",
    "                        title=f'GIC at {self.date} - {DAY}:{hour}:{minute}:{second}'\n",
    "                        proj='-JM15C -P'\n",
    "                        lims=f'-R{lim1}/{lim2}/{lim3}/{lim4}'\n",
    "                        psfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.ps' #aanpassen\n",
    "                        pngfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.png' #aanpassen\n",
    "                        os.system(f'gmt pscoast {proj} {lims} -W0.5p -K -Ggrey -Slightblue -Df -N1/0.25p> {psfile}' )\n",
    "                        os.system(f'gmt psbasemap {proj} {lims} -Ba1g1 -BWeSn+t\"{title}\" -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.netpath}/cables.csv {proj} {lims} -W0.5p -Wred -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.respath}/{self.date}/GIC/GIC_{localvar.tijd}.csv {proj} {lims} -Ctopo.cpt -Scc -O -K>> {psfile}')    \n",
    "                        os.system(f'gmt psxy {self.netpath}/legend.txt {proj} {lims} -Ctopo.cpt -W -Scc -O -K>> {psfile}')\n",
    "                        os.system(f'gmt pstext {self.netpath}/legendtext.txt {proj} {lims} -F+f30pHelvetica,black -O>> {psfile}')\n",
    "                os.system(f'convert -density 300 {psfile} {pngfile}')\n",
    "                os.system(f'rm {psfile}')\n",
    "\n",
    "            logging.info(f'Thread {q} has fulfilled timestep {localvar.time}!')\n",
    "        logging.info(f'Thread {q} is finished!')\n",
    "    \n",
    "    def GIC_index(self,overwrite=False):\n",
    "        \"\"\" Calculates the GIC index for all given magnetic station observatories according to \n",
    "        Marshall et al.'s 'A preliminary risk assessment of the Australian region power network to space weather' (2011)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        overwrite : boolean (optional)\n",
    "           if True, old maximum GIC values are overwritten\n",
    "           \n",
    "        NEEDS MAGNETIC OBSERVATIONS TO WORK\n",
    "         \n",
    "        Functions\n",
    "        ---------\n",
    "        check_sampling() : obtain amount of samples, minute or second data, and amount of days from magnetic data\n",
    "        Parzen(N) : creates a Parzen window for given length\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        GIC_index.txt : text file\n",
    "           textfile containing the maximum GIC index per magnetic observatory, in following order : lon, lat, GICx-index, GICy-index\n",
    "        GICx_index.png/GICy_index.png : png file\n",
    "           graph of GIC index in both northern and eastern direction\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.check_sampling()\n",
    "        if overwrite:\n",
    "            g=open(f'{self.respath}/{self.date}/GIC_index.txt','w+')\n",
    "        else:\n",
    "            g=open(f'{self.respath}/{self.date}/GIC_index.txt','a+')\n",
    "        maxx=0\n",
    "        maxy=0\n",
    "        Xcomp=np.zeros(self.samples*self.days)\n",
    "        XParz=np.zeros(self.samples*3*self.days)\n",
    "        GICxft=np.zeros((int(self.samples/2*3*self.days)+1), dtype='complex')\n",
    "        GICx=np.zeros(self.samples*3*self.days)\n",
    "        Ycomp=np.zeros(self.samples*self.days)\n",
    "        YParz=np.zeros(self.samples*3*self.days)\n",
    "        GICyft=np.zeros((int(self.samples/2*3*self.days)+1), dtype='complex')\n",
    "        GICy=np.zeros(self.samples*3*self.days)\n",
    "        df=1/(60*60*24*3.*self.days) # *3 for Parzen window\n",
    "        if self.minute:\n",
    "            fmax=1/(2*60.)\n",
    "        else:\n",
    "            fmax=1/(2*1)\n",
    "        freqvector=np.arange(0,fmax+df,df) #create frequency vector\n",
    "        timevector=np.linspace(0,24*self.days,self.samples*self.days)\n",
    "\n",
    "        figx=plt.figure(figsize=(15,10)) #initialize plotting GICx\n",
    "        axx=figx.add_subplot()\n",
    "        axx.set_title('GICx index')\n",
    "        axx.set_ylabel('GICx')\n",
    "        axx.set_xlabel('Time (h)')\n",
    "        axx.axhline(16, linestyle='--', color='green')#, label='5%')\n",
    "        axx.axhline(43, linestyle='--', color='yellow')#, label='35%')\n",
    "        axx.axhline(114, linestyle='--', color='orange')#, label='65%')\n",
    "        axx.axhline(304, linestyle='--', color='red')#, label='95%')\n",
    "        figy=plt.figure(figsize=(15,10)) #initialize plotting GICy\n",
    "        axy=figy.add_subplot()\n",
    "        axy.set_title('GICy index')\n",
    "        axy.set_ylabel('GICy')\n",
    "        axy.set_xlabel('Time (h)')\n",
    "        axy.axhline(39, linestyle='--', color='green')#, label='5%')\n",
    "        axy.axhline(97, linestyle='--', color='yellow')#, label='35%')\n",
    "        axy.axhline(241, linestyle='--', color='orange')#, label='65%')\n",
    "        axy.axhline(600, linestyle='--', color='red')#, label='95%')\n",
    "#         axx.legend(loc='upper right')\n",
    "#         axy.legend(loc='upper right')\n",
    "        \n",
    "        os.system(f'ls -d {self.respath}/{self.date}/*/ > {self.respath}/{self.date}/temp.txt') #get location\n",
    "        f=open(f'{self.respath}/{self.date}/temp.txt')\n",
    "        string=[]\n",
    "        for item in f:\n",
    "            item=item.strip(\"\\n\")\n",
    "            string.append(item)\n",
    "        string=sorted(string)\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "        os.system(f'ls {self.statpath} > {self.respath}/{self.date}/temp.txt') #get coordinates\n",
    "        f=open(f'{self.respath}/{self.date}/temp.txt')\n",
    "        string2=[]\n",
    "        for item in f:\n",
    "            item=item.strip(\"\\n\")\n",
    "            string2.append(item)\n",
    "        string2=sorted(string2)\n",
    "        lat=np.zeros(len(string2))\n",
    "        lon=np.zeros(len(string2))\n",
    "        stat=[]\n",
    "        for counter2,item in enumerate(string2):\n",
    "            File=open(f'{self.statpath}/{item}')\n",
    "            for counter,line in enumerate(File):\n",
    "                if counter==2:\n",
    "                    words=line.split()\n",
    "                    stat.append(words[2])\n",
    "                if counter==4:\n",
    "                    words=line.split()\n",
    "                    lat[counter2]=float(words[2]) # latitude station\n",
    "                if counter==5:\n",
    "                    words=line.split()\n",
    "                    lon[counter2]=float(words[2]) # longitude station\n",
    "                    break\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "        for counter3,station in enumerate(string):\n",
    "            if self.days==1:\n",
    "                newfile=pd.read_csv(f'{station}/allresults.csv', delimiter=';')\n",
    "            else:\n",
    "                newfile=pd.read_csv(f'{station}/merged_allresults.csv', delimiter=';')\n",
    "            Xcomp=newfile['B_theta (nt)'].to_numpy()\n",
    "            Ycomp=newfile['B_phi (nt)'].to_numpy()\n",
    "            XParz[:self.samples*self.days]=Xcomp[0] #make Parzen vector\n",
    "            XParz[self.samples*self.days:self.samples*2*self.days]=Xcomp\n",
    "            XParz[self.samples*2*self.days:]=Xcomp[-1]\n",
    "            YParz[:self.samples*self.days]=Ycomp[0]\n",
    "            YParz[self.samples*self.days:self.samples*2*self.days]=Ycomp\n",
    "            YParz[self.samples*2*self.days:]=Ycomp[-1]\n",
    "            Xft=np.fft.rfft(XParz*self.Parzen(self.samples*3*self.days)) #fourier transform into frequency domain\n",
    "            Yft=np.fft.rfft(YParz*self.Parzen(self.samples*3*self.days))\n",
    "\n",
    "            for counter,freq in enumerate(freqvector):\n",
    "                GICxft[counter]=Yft[counter]*np.exp(1j*np.pi/4.)*np.sqrt(freq/fmax)\n",
    "                GICyft[counter]=Xft[counter]*np.exp(1j*np.pi/4.)*np.sqrt(freq/fmax)\n",
    "            GICx=np.fft.irfft(GICxft)\n",
    "            GICy=np.fft.irfft(GICyft)\n",
    "\n",
    "            g.write(f\"{lon[counter3]} {lat[counter3]} {max(GICx[self.samples*self.days:self.samples*2*self.days])} {max(GICy[self.samples*self.days:self.samples*2*self.days])} {stat[counter3]}\\n\")\n",
    "            axx.plot(timevector,GICx[self.samples*self.days:self.samples*2*self.days],label=f'{stat[counter3]}')\n",
    "            axy.plot(timevector,GICy[self.samples*self.days:self.samples*2*self.days],label=f'{stat[counter3]}')\n",
    "            if max(GICx)>maxx:\n",
    "                maxx=max(GICx)\n",
    "            if max(GICy)>maxy:\n",
    "                maxy=max(GICy)\n",
    "                \n",
    "        g.close()\n",
    "        axx.legend()\n",
    "        axy.legend()\n",
    "        axx.set_ylim(0,maxx+10)\n",
    "        axy.set_ylim(0,maxy+10)\n",
    "        figx.savefig(f'{self.respath}/{self.date}/GICx_index.png')\n",
    "        figy.savefig(f'{self.respath}/{self.date}/GICy_index.png')\n",
    "        \n",
    "    def glue_data(self,paths,foldername):\n",
    "        \"\"\" Put data of mutiple consequental days together\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        paths : array of strings (required)\n",
    "           paths, IN RIGHT ORDER, of the magnetic interpolated data of the consequental days\n",
    "        foldername : string (required)\n",
    "           name of the folder where these combined magnetic interpolations need to go\n",
    "        \"\"\"\n",
    "        import os #BE SURE TO PLACE THEM (Magnetic interpolation) IN CORRECT ORDER! SO E.G.: [29-10-2003, 30-10-2003, 31-10-2003]\n",
    "        import logging\n",
    "        logging.warning(f'Look Out! self.date is now changed from {self.date} to {foldername}!')\n",
    "        self.date=foldername\n",
    "        for path in paths:\n",
    "            if self.samples==0:\n",
    "                self.samples=len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])/2 #both x and y files\n",
    "                if self.samples==24*60:\n",
    "                    self.minute=True\n",
    "                elif self.samples==24*60*60:\n",
    "                    self.minute=False\n",
    "                else:\n",
    "                    raise Exception(\"Folders do not contain minute or second data, or data is missing!\")\n",
    "            elif self.samples!=0 and self.samples!=int(len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])/2):\n",
    "                raise Exception(\"Folders contain different amount of files!\")\n",
    "            else:\n",
    "                pass\n",
    "        test=str(int(self.samples*len(paths)))\n",
    "        fill=len(test) #get length of number string\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{foldername}')\n",
    "        except:\n",
    "            logging.warning(f'Directory \"{self.respath}/{foldername}\" is already created, data could be lost forever!')\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{foldername}/interpolation')\n",
    "        except:\n",
    "            logging.warning(f'Directory \"{self.respath}/{foldername}/interpolation\" is already created, data could be lost forever!')\n",
    "        #give files new numbering\n",
    "        if self.minute:\n",
    "            for counter,item in enumerate(paths):\n",
    "                for nr in range(int(self.samples)):\n",
    "                    os.system(f'cp {item}/minute_{str(nr).zfill(4)}.csv {self.respath}/{foldername}/interpolation/minute_{str(int(nr+counter*self.samples)).zfill(fill)}.csv')\n",
    "                    os.system(f'cp {item}/minute_{str(nr).zfill(4)}.csv.Y {self.respath}/{foldername}/interpolation/minute_{str(int(nr+counter*self.samples)).zfill(fill)}.csv.Y')\n",
    "        else:\n",
    "            for counter,item in enumerate(paths):\n",
    "                for nr in range(int(self.samples)):\n",
    "                    os.system(f'cp {item}/second_{str(nr).zfill(5)}.csv {self.respath}/{foldername}/interpolation/second_{str(int(nr+counter*self.samples)).zfill(fill)}.csv')\n",
    "                    os.system(f'cp {item}/second_{str(nr).zfill(5)}.csv.Y {self.respath}/{foldername}/interpolation/second_{str(int(nr+counter*self.samples)).zfill(fill)}.csv.Y')\n",
    "        logging.info('Data copying is finished!')\n",
    "                    \n",
    "    def glue_video(self,nameout,gluefile=None,videos=None):\n",
    "        \"\"\" Combine multiple mp4-videos together\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        nameout : string (required)\n",
    "           name of the new mp4-video file\n",
    "        gluefile : string (only if videos=None, required; else optional)\n",
    "           file containing the location of the videos to be merged, starting with `file'\n",
    "        videos : array of strings (only if gluefile=None, required; else optional)\n",
    "           array containing the location of the different videos in consequental order\n",
    "           \n",
    "        Returns\n",
    "        -------\n",
    "        *.mp4 : mp4-video file\n",
    "           merged video\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if gluefile==None:\n",
    "            f=open('gluefile.txt', 'w+')\n",
    "            for item in videos:\n",
    "                f.write(f\"file '{item}' \\n\")\n",
    "            f.close()\n",
    "            os.system(f'ffmpeg -f concat -safe 0 -i gluefile.txt -c copy {self.respath}/{nameout}.mp4')\n",
    "            os.system('rm gluefile.txt')\n",
    "        else:\n",
    "            os.system(f'ffmpeg -f concat -safe 0 -i {gluefile} -c copy {self.respath}/{nameout}.mp4')\n",
    "        # gluefile should have lines like: file '/usr/people/out/Documents/Magnetic_field/station_results/31-10-2003/GIC.mp4'\n",
    "        \n",
    "    def iteratestation(self,figures=False,plots=True):\n",
    "        \"\"\" Iterate the function newplotspace for multiple magnetic observatories\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        figures : boolean (optional)\n",
    "           if True, figures are opened in the terminal\n",
    "        plots : boolean (optional)\n",
    "           if True, plots of mangetic signal are generated and placed in a folder\n",
    "        \n",
    "        NEEDS RAW DATA MAGNETIC OBSERVATORIES TO WORK\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        newplotspace(stringactive,stringquiet,figures,plots) : function that extract magnetic data and returns reduced magnetic signal by subtracting quiet day from active day\n",
    "        \"\"\"\n",
    "        import os\n",
    "        string=os.listdir(self.statpath)\n",
    "        string=sorted(string)\n",
    "        stringquiet=os.listdir(self.quietpath)\n",
    "        stringquiet=sorted(stringquiet)\n",
    "        if len(string)!=len(stringquiet):\n",
    "            raise Exception(f'Quiet and active days should have the same stations, now there are {len(stringquiet)} quiet stations and {len(string)} active stations!')\n",
    "        for counter,item in enumerate(string):\n",
    "            self.newplotspace(string[counter],stringquiet[counter],figures=False,plots=True)\n",
    "     \n",
    "    def magnetic_interpolation(self):\n",
    "        \"\"\" Interpolates magnetic field for given domain\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "           \n",
    "        NEEDS PROCESSED DATA MAGNETIC OBSERAVTORIES TO WORK\n",
    "        NR OF PROCESSORS IS SET AT 3, DUE TO COMPUTATIONAL LIMITS. NR CAN BE INCREASED AT OWN RISK\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        magnetic_time(proc#,start,stop,location,string,localvar) : function that interpolates and write interpolated magnetic values to files per timestep\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        *csv and *csv.Y : csv files\n",
    "           interpolated magnetic signal over northwest Europe\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import threading\n",
    "        from multiprocessing import Process\n",
    "        localvar=threading.local()\n",
    "        RE=6371000\n",
    "        \n",
    "        string=(file for file in os.listdir(self.statpath) if os.path.isfile(os.path.join(self.statpath, file)))\n",
    "        string=sorted(string) #sort alphabetically, otherwise problems later\n",
    "        logging.debug(f'Used stations are: {string} \\n')\n",
    "        location=np.zeros((len(string),3))\n",
    "        location[:,2]=RE\n",
    "        for counter1,item in enumerate(string):\n",
    "            File=open(f'{self.statpath}/{item}','r')\n",
    "            for counter2,line in enumerate(File):\n",
    "                words=line.split()\n",
    "                if counter2==4:\n",
    "                    word=line.split()\n",
    "                    location[counter1,0]=word[2] #latitude\n",
    "                if counter2==5:\n",
    "                    word=line.split()\n",
    "                    location[counter1,1]=word[2] #longitude           \n",
    "                if words[0]=='DATE':\n",
    "                    datastart=counter2\n",
    "                    \n",
    "            File.close()\n",
    "            self.samples=counter2-datastart\n",
    "            if self.samples == 24*60:\n",
    "                self.minute = True\n",
    "            elif self.samples == 24*60*60:\n",
    "                self.minute = False\n",
    "            else:\n",
    "                raise ValueError(f\"Amount of samples ({self.samples}) does not correspond to minute or second data!\")\n",
    "        string=[]\n",
    "        os.system(f' ls -d {self.respath}/{self.date}/*{self.datevar} > {self.respath}/{self.date}/temp.txt') \n",
    "        f=open(f'{self.respath}/{self.date}/temp.txt')\n",
    "        for item in f:\n",
    "            item=item.strip('\\n')\n",
    "            string.append(item)\n",
    "        string=sorted(string) #sort alphabetically, otherwise problems now\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "        print(string)\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/interpolation')\n",
    "        except:\n",
    "            print('Directory is already created, data could be overwritten.')\n",
    "            logging.info('Directory is already created, data could be overwritten.')\n",
    "\n",
    "        n=3 #no more than 3 processors at a time for 16GB memory\n",
    "        nrsteps=int(self.samples/n)\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.magnetic_time, args=(index+1, nrsteps*index, nrsteps*(index+1),location,string,localvar))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "    def magnetic_time(self,q,stepmin,stepmax,location,string,localvar):\n",
    "        \"\"\" Calculated interpolated values and write them to files\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        q : integer (required)\n",
    "           processor number\n",
    "        stepmin : integer (required)\n",
    "           starting timestep\n",
    "        stepmax : integer (required)\n",
    "           ending timestep\n",
    "        location : numpy matrix (required)\n",
    "           (#stations,3) matrix containing latitude, longitude, and radius (of the Earth) per station\n",
    "        string : array of string (required)\n",
    "          path to folders of magnetic observatories\n",
    "        localvar : object (required)\n",
    "           object were every single processor can store its variables separately without mixing them up between processors\n",
    "        \n",
    "        NEEDS TO BE USED WITH FUNCTION magnetic_interpolation() TO WORK PROPERLY\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        mag_interpolate(location,localvar.values,np.array([43,63,-13,20]),0.5) : function that carries out the actual interpolation per timestep\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        *csv and *csv.Y : csv files\n",
    "           interpolated magnetic signal over northwest Europe        \n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import logging\n",
    "        \n",
    "        logging.info(f'Thread {q} is running, starting at {stepmin}.')\n",
    "        for counter3 in range(stepmin,stepmax): #minutes per day\n",
    "            localvar.values=np.zeros((len(string),3))\n",
    "            logging.info(f'Thread {q} got a lock')\n",
    "            for localvar.counter1,localvar.item in enumerate(string):\n",
    "                localvar.File=open(f'{localvar.item}/allresults.csv')\n",
    "                for localvar.counter2,localvar.line in enumerate(localvar.File):\n",
    "                    if localvar.counter2==(counter3+1):\n",
    "                        localvar.word=localvar.line.split(';')\n",
    "                        localvar.values[localvar.counter1,:]=[localvar.word[0],localvar.word[1],localvar.word[2]]\n",
    "                        break\n",
    "                localvar.File.close()\n",
    "\n",
    "            localvar.result=self.mag_interpolate(location,localvar.values,np.array([52,71,14,31]),0.5)\n",
    "            if np.isnan(localvar.result).any():\n",
    "                print(counter3, np.argwhere(np.isnan(localvar.result)))\n",
    "            logging.info(f'Thread {q} released lock and finished interpolating for step {counter3}.')\n",
    "            \n",
    "            localvar.newfile1=pd.DataFrame(columns=['lon','lat','Bx'])\n",
    "            localvar.newfile2=pd.DataFrame(columns=['lon','lat','By'])\n",
    "\n",
    "            logging.info(f'Thread {q} is busy writing to file.')\n",
    "            localvar.newfile1['lon']=localvar.result[:,1]\n",
    "            localvar.newfile1['lat']=localvar.result[:,0]\n",
    "            localvar.newfile1['Bx']=localvar.result[:,2]\n",
    "            localvar.newfile2['lon']=localvar.result[:,1]\n",
    "            localvar.newfile2['lat']=localvar.result[:,0]\n",
    "            localvar.newfile2['By']=localvar.result[:,3]\n",
    " \n",
    "            logging.info(f'Thread {q} is searching.')\n",
    "            if self.minute==True:\n",
    "                localvar.newfile1.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(4)}.csv', sep=' ', index=False, header=False)\n",
    "                localvar.newfile2.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(4)}.csv.Y', sep=' ', index=False, header=False)\n",
    "            else:\n",
    "                localvar.newfile1.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(5)}.csv', sep=' ', index=False, header=False)\n",
    "                localvar.newfile2.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(5)}.csv.Y', sep=' ', index=False, header=False)\n",
    "        \n",
    "            logging.info(f'Thread {q} has found.')\n",
    "        logging.warning(f'Thread {q} has finished.')\n",
    "            \n",
    "    def mag_interpolate(self,loc,val,latlon,delta):\n",
    "        \"\"\" Interpolates magnetic data over northwestern European domain\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        loc : numpy matrix (required)\n",
    "           (#stations,3) matrix containing latitude, longitude, and radius (of the Earth) per station\n",
    "        val : numpy matrix (required)\n",
    "           (#stations,3) matrix containing radial, latitudonal, and longitudonal component of the magnetic field at a station for a specific timestep\n",
    "        latlon : numpy array (required)\n",
    "           area over which we want to interpolate the magnetic data, given as [minimum_latitude, maximum_latitude, minimum_longitude, maximum_longitude]\n",
    "        delta : float (required)\n",
    "           spacing of the area over which we want to interpolate; here 0.5 is a safe guess\n",
    "        \n",
    "        NEEDS TO BE USED WITH magnetic_time() TO WORK PROPERLY\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        USES THE SPECIAL PACKAGE pySECS (class SECS); INSTALL BEFOREHAND!\n",
    "        SECS(location_of_poles) : initialise class\n",
    "        SECS.fit(loc,val) : scale poles to observed values (val) at given locations (loc) (upscaling)\n",
    "        SECS.predict(prediction_location, False) : project the scaled poles back to the whole domain (downscaling)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result : numpy array\n",
    "           (points in domain, 4) matrix contains latitude, longitude, interpolated northern component, interpolated eastern component for every point in the given domain per timestep\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        from pySECS import SECS \n",
    "        \n",
    "        if loc.shape[-1] != 3:\n",
    "            raise ValueError(\"Observation locations must have 3 columns (lat, lon, r)\")\n",
    "        if val.shape[-1] != 3:\n",
    "            raise ValueError(\"Observed values must have 3 columns (Bx(theta), By(phi), Bz(r))\")\n",
    "        if latlon.shape[-1] != 4:\n",
    "            raise ValueError(\"Observed values must have 1 row and 4 columns (latmin, latmax, lonmin, lonmax)\")\n",
    "        RE=6371e3\n",
    "\n",
    "        latlon[1]+=delta\n",
    "        latlon[3]+=delta\n",
    "\n",
    "        lats = np.arange(latlon[0], latlon[1], delta)\n",
    "        lons = np.arange(latlon[2], latlon[3], delta)\n",
    "\n",
    "        nlat = len(lats)\n",
    "        nlon = len(lons)\n",
    "\n",
    "        xx, yy = np.meshgrid(lons, lats) #make nice mesh\n",
    "\n",
    "        sec_loc=np.zeros((nlat*nlon,3))\n",
    "        #add poles to sec_loc\n",
    "        sec_loc[:,0]=yy.ravel()\n",
    "        sec_loc[:,1]=xx.ravel()\n",
    "        sec_loc[:,2]=RE+110e3 #system is 110 km above ground with multiple poles\n",
    "\n",
    "        system_df = SECS(sec_df_loc=sec_loc) #initiate new divergence free system using poles (only df free, see paper)\n",
    "\n",
    "        system_df.fit(loc,val) #fit currents to values\n",
    "\n",
    "    ################## The prediction/interpolation begins ################\n",
    "        \n",
    "#         predlats = np.arange(50.7, 56.3, 0.07) #England\n",
    "#         predlons = np.arange(-4.9, 0.6, 0.07)\n",
    "\n",
    "#         predlats = np.arange(59.5, 68, 0.1) #Finland\n",
    "#         predlons = np.arange(18, 32, 0.1)\n",
    "\n",
    "#         nrpoint=len(predlats)*len(predlons)\n",
    "\n",
    "#         predxx, predyy = np.meshgrid(predlons, predlats) #make nice mesh\n",
    "        \n",
    "#         pred_loc=np.zeros((nrpoint,3))\n",
    "        predlats = np.arange(48.85, 54.4, 0.05) #Netherlands+Belgium&Germany\n",
    "        predlons = np.arange(3.2, 10.1, 0.05)\n",
    "        predlatseng = np.arange(51.4, 52.04, 0.05) #seacable england\n",
    "        predlonseng = np.arange(0.7, 3.29, 0.05)\n",
    "        predlatsnor = np.arange(54.05, 58.34, 0.05) #seacable norway\n",
    "        predlonsnor = np.arange(6.1, 6.94, 0.05)\n",
    "\n",
    "        nrpoint=len(predlats)*len(predlons)+len(predlatseng)*len(predlonseng)+len(predlatsnor)*len(predlonsnor)\n",
    "\n",
    "        predxx1, predyy1 = np.meshgrid(predlons, predlats) #make nice mesh\n",
    "        predxx2, predyy2 = np.meshgrid(predlonseng, predlatseng)\n",
    "        predxx3, predyy3 = np.meshgrid(predlonsnor, predlatsnor)\n",
    "        predxx=np.concatenate((predxx1.flatten(),predxx2.flatten(),predxx3.flatten()))\n",
    "        predyy=np.concatenate((predyy1.flatten(),predyy2.flatten(),predyy3.flatten()))\n",
    "\n",
    "        pred_loc=np.zeros((nrpoint,3))\n",
    "        #add locations\n",
    "        pred_loc[:,0]=predyy.ravel()\n",
    "        pred_loc[:,1]=predxx.ravel()\n",
    "        pred_loc[:,2]=RE #system is at ground\n",
    "        prediction=system_df.predict(pred_loc, False)\n",
    "        result=np.zeros((nrpoint,4))\n",
    "        result[:,0]=predyy.ravel()\n",
    "        result[:,1]=predxx.ravel()\n",
    "        result[:,2]=prediction[:,0]\n",
    "        result[:,3]=prediction[:,1]\n",
    "        return result\n",
    "\n",
    "    def make_video(self,namein,nameout):\n",
    "        \"\"\" Creates mp4-video from png files\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        namein : string (required)\n",
    "           location + name of png file, without its timestamp number\n",
    "        nameout : string (required)\n",
    "           name of the created mp4-video\n",
    "           \n",
    "        Returns\n",
    "        -------\n",
    "        *.mp4 : mp4-video at '{self.respath}/{self.date}'\n",
    "        \"\"\"\n",
    "        import os\n",
    "        os.system(f'ffmpeg -framerate 24 -pattern_type glob -i \"{namein}*.png\" {self.respath}/{self.date}/{nameout}.mp4')\n",
    "    \n",
    "    def newplotspace(self,activeday,quietday,figures=False,plots=True):\n",
    "        \"\"\" Converts raw data to input data for interpolation by substracting quiet solar day from active day\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        activeday : string (required)\n",
    "           folder which contains the magnetic observations from the active solar day\n",
    "        quietday : string (required)\n",
    "           folder which contains the magnetic observations from the quiet solar day\n",
    "        figures : boolean (optional)\n",
    "           if True, figures are plot in the terminal\n",
    "        plots : boolean (optional)\n",
    "           if True, figures are created and placed in the appropriate station folder in '{self.respath}/{self.date}'\n",
    "        \n",
    "        Created Folders\n",
    "        ---------------\n",
    "        '{self.respath}/{self.date}' : folder where all processed stations will be stored\n",
    "        '{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}' : folder where all data of one station is stored\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        allresults.csv : csv file\n",
    "           storage of processed magnetic data per station; every row correponds to one timestep\n",
    "           file contains per column: B_theta, B_phi, B_r, B_H, dB_theta/dt, dB_phi/dt, dBH/dt\n",
    "        *.png : png file\n",
    "           various graphic overviews of the allresults.csv file\n",
    "        \"\"\"\n",
    "        #import needed packages\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib\n",
    "        %matplotlib inline\n",
    "        import matplotlib.pyplot as plt\n",
    "        import re\n",
    "        possible_characters = ('-', ' ')\n",
    "    ##### calculate values from observation station #####\n",
    "        # read-in file of station\n",
    "        File=open(f'{self.quietpath}/{quietday}','r') # open file\n",
    "        HorX=[] # make some lists\n",
    "        DeclY=[]\n",
    "        VertZ=[]\n",
    "        X2=[]\n",
    "        for counter,line in enumerate(File):\n",
    "            words=line.split()\n",
    "            if words[0]=='DATE':\n",
    "                datastart=counter+2\n",
    "                for counter2,letters in enumerate(words[3]):\n",
    "                    if counter2==3:\n",
    "                        if letters=='H':\n",
    "                            types=False\n",
    "                            break\n",
    "                        if letters=='X':\n",
    "                            types=True\n",
    "                            break\n",
    "        File=open(f'{self.quietpath}/{quietday}','r')\n",
    "        counter=0\n",
    "        for counter,line in enumerate(File):\n",
    "            if counter==2:\n",
    "                words=line.split()\n",
    "                station=words[2]\n",
    "                \n",
    "            if counter>=datastart-1: #read when the data starts\n",
    "                words=line.split()\n",
    "                if counter==datastart:\n",
    "                    for newcounter,letters in enumerate(words[1]):\n",
    "                        if newcounter==4:\n",
    "                            if letters=='1' and self.samples==0:\n",
    "                                self.minute=True\n",
    "                                self.samples=24*60\n",
    "                            if letters=='0' and self.samples==0:\n",
    "                                self.minute=False\n",
    "                                self.samples=24*60*60\n",
    "                            if letters=='1' and self.samples!=0 and self.minute==False:\n",
    "                                raise Exception('Data is not of the same type (min and s)!')\n",
    "                            if letters=='0' and self.samples!=0 and self.minute==True:\n",
    "                                raise Exception('Data is not of the same type (min and s)!')\n",
    "\n",
    "                \n",
    "                if float(words[3])>90000: #then no data is saved, but previous sample or zero is stored\n",
    "                    if counter==datastart-1:\n",
    "                        HorX.append(0)\n",
    "                    else:\n",
    "                        HorX.append(HorX[-1]) # get horizontal or X-component\n",
    "                else:\n",
    "                    HorX.append(float(words[3]))\n",
    "\n",
    "                if float(words[4])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        DeclY.append(0)\n",
    "                    else:\n",
    "                        DeclY.append(DeclY[-1]) # get 'declination' or Y-component\n",
    "                else:\n",
    "                    DeclY.append(float(words[4]))\n",
    "\n",
    "                if float(words[5])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        VertZ.append(0)\n",
    "                    else:\n",
    "                        VertZ.append(VertZ[-1]) # get vertical component or Z-component\n",
    "                else:\n",
    "                    VertZ.append(float(words[5]))\n",
    "            \n",
    "        File.close()\n",
    "\n",
    "        if types: #if given in XYZ, types==true\n",
    "            X2=HorX\n",
    "            Y2=DeclY\n",
    "            Z2=VertZ\n",
    "\n",
    "        else: #if given in HDZ, types==false\n",
    "            for item in range(len(DeclY)):\n",
    "                X2.append(np.sqrt(HorX[item]**2-DeclY[item]**2)) #minus is added to immediately transform to polar coordinates\n",
    "            Y2=DeclY\n",
    "            Z2=VertZ\n",
    "\n",
    "        File=open(f'{self.statpath}/{activeday}','r') # open file\n",
    "        HorX=[] # make some lists\n",
    "        DeclY=[]\n",
    "        VertZ=[]\n",
    "        X1=[]\n",
    "        N=0\n",
    "        for counter,line in enumerate(File):\n",
    "            words=line.split()\n",
    "            if words[0]=='DATE':\n",
    "                datastart=counter+2\n",
    "                for counter2,letters in enumerate(words[3]):\n",
    "                    if counter2==3:\n",
    "                        if letters=='H':\n",
    "                            types=False\n",
    "                            break\n",
    "                        if letters=='X':\n",
    "                            types=True\n",
    "                            break\n",
    "        File=open(f'{self.statpath}/{activeday}','r')\n",
    "        counter=0\n",
    "        for counter,line in enumerate(File):\n",
    "            if counter==2:\n",
    "                words=line.split()\n",
    "                station=words[2]\n",
    "            if counter>=datastart-1: #read when the data starts\n",
    "                N+=1\n",
    "                if counter==datastart-1:\n",
    "                    dates=re.split(\"[%s]\" % (\"\".join(possible_characters)), line) # get start date\n",
    "\n",
    "                words=line.split()\n",
    "                if float(words[3])>90000: #then no data is saved, but previous sample or zero is stored\n",
    "                    if counter==datastart-1:\n",
    "                        HorX.append(0)\n",
    "                    else:\n",
    "                        HorX.append(HorX[-1]) # get horizontal or X-component\n",
    "                else:\n",
    "                    HorX.append(float(words[3]))\n",
    "\n",
    "                if float(words[4])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        DeclY.append(0)\n",
    "                    else:\n",
    "                        DeclY.append(DeclY[-1]) # get 'declination' or Y-component\n",
    "                else:\n",
    "                    DeclY.append(float(words[4]))\n",
    "\n",
    "                if float(words[5])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        VertZ.append(0)\n",
    "                    else:\n",
    "                        VertZ.append(VertZ[-1]) # get vertical component or Z-component\n",
    "                else:\n",
    "                    VertZ.append(float(words[5]))\n",
    "\n",
    "        File.close()\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}')\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if types: #if given in XYZ, types==true\n",
    "            X1=HorX\n",
    "            Y1=DeclY\n",
    "            Z1=VertZ\n",
    "\n",
    "        else: #if given in HDZ, types==false\n",
    "            for item in range(len(DeclY)):\n",
    "                X1.append(np.sqrt(HorX[item]**2-DeclY[item]**2)) #minus is added to immediately transform to polar coordinates\n",
    "            Y1=DeclY\n",
    "            Z1=VertZ\n",
    "    ##### calculate model value of magnetic field #####\n",
    "        # set up\n",
    "        time = np.linspace(0,24,N)\n",
    "\n",
    "\n",
    "    ##### subtract the two data sets! #####\n",
    "        SpaceX=np.subtract(X1,X2)\n",
    "        SpaceY=np.subtract(Y1,Y2)\n",
    "        SpaceZ=np.subtract(Z1,Z2)\n",
    "\n",
    "    ##### plot data #####\n",
    "        if figures:\n",
    "            figx=plt.figure(figsize=(20,10))\n",
    "            ax1=figx.add_subplot(311)\n",
    "            ax11=figx.add_subplot(312)\n",
    "            ax12=figx.add_subplot(313)\n",
    "            ax1.set_title('$B_\\\\theta$ at '+ station + ' on ' + dates[0] + '-' + dates[1] + '-' + dates[2])\n",
    "            ax12.set_xlabel('time (days after 1 jan 2000)')\n",
    "            ax11.set_ylabel('$B_\\\\theta$ (nt)')\n",
    "            ax11.plot(time,X1,label='observed',color='blue')\n",
    "            ax12.plot(time,X2,label='model',color='green')\n",
    "            ax1.plot(time,SpaceX,label='residue',color='red')\n",
    "            ax1.legend()\n",
    "            ax11.legend()\n",
    "            ax12.legend()\n",
    "\n",
    "            figy=plt.figure(figsize=(20,10))\n",
    "            ax2=figy.add_subplot(311)\n",
    "            ax21=figy.add_subplot(312)\n",
    "            ax22=figy.add_subplot(313)\n",
    "            ax2.set_title('$B_\\\\phi$ at '+ station + ' on ' + dates[0] + '-' + dates[1] + '-' + dates[2])\n",
    "            ax22.set_xlabel('time (days after 1 jan 2000)')\n",
    "            ax21.set_ylabel('$B_\\\\phi$ (nt)')\n",
    "            ax21.plot(time,Y1,label='total',color='blue')\n",
    "            ax22.plot(time,Y2,label='model',color='green')\n",
    "            ax2.plot(time,SpaceY,label='residue',color='red')\n",
    "            ax2.legend()\n",
    "            ax21.legend()\n",
    "            ax22.legend()\n",
    "\n",
    "            figz=plt.figure(figsize=(20,10))\n",
    "            ax3=figz.add_subplot(311)\n",
    "            ax31=figz.add_subplot(312)\n",
    "            ax32=figz.add_subplot(313)\n",
    "            ax3.set_title('$B_r$ at '+ station + ' on ' + dates[0] + '-' + dates[1] + '-' + dates[2])\n",
    "            ax32.set_xlabel('time (days after 1 jan 2000)')\n",
    "            ax31.set_ylabel('$B_r$ (nt)')\n",
    "            ax31.plot(time,Z1,label='total',color='blue')\n",
    "            ax32.plot(time,Z2,label='model',color='green')\n",
    "            ax3.plot(time,SpaceZ,label='residue',color='red')\n",
    "            ax3.legend()\n",
    "            ax31.legend()\n",
    "            ax32.legend()\n",
    "            plt.show()\n",
    "\n",
    "        if plots:\n",
    "            figall=plt.figure(figsize=(20,10))\n",
    "            ax4=figall.add_subplot(311)\n",
    "            ax41=figall.add_subplot(312)\n",
    "            ax42=figall.add_subplot(313)\n",
    "            ax4.set_title('Radial component')\n",
    "            ax41.set_title('Longitudinal component')\n",
    "            ax41.set_ylabel('nanoteslas')\n",
    "            ax42.set_title('Latitudional component')\n",
    "            ax4.plot(time,SpaceZ,color='red')\n",
    "            ax41.plot(time,SpaceY,color='red')\n",
    "            ax42.plot(time,SpaceX,color='red')\n",
    "            plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/SWresult.png')\n",
    "\n",
    "    ##### calculate frequency spectrum #####\n",
    "        # try to get time derivative, only horizontal components matter\n",
    "        dXdt=np.zeros(len(SpaceX)) # define length array\n",
    "        dYdt=np.zeros(len(SpaceY))\n",
    "\n",
    "        for item in range(len(SpaceX)-1): # obtain derivative\n",
    "            dXdt[item]=SpaceX[item+1]-SpaceX[item]\n",
    "            dYdt[item]=SpaceY[item+1]-SpaceY[item]\n",
    "\n",
    "        if plots:\n",
    "            figx=plt.figure()\n",
    "            ax1=figx.add_subplot()\n",
    "            ax1.set_title('d$B_X$/dt at ' + station)\n",
    "            ax1.set_xlabel('time (days after 1 jan 2000)')\n",
    "            if self.minute:\n",
    "                ax1.set_ylabel(f'd$B_X$/dt (nt/min)')\n",
    "            else:\n",
    "                ax1.set_ylabel(f'd$B_X$/dt (nt/s)')\n",
    "            ax1.plot(time,dXdt,label='residue',color='red')\n",
    "            ax1.legend()\n",
    "            plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/db\\dtX.png')\n",
    "\n",
    "            figy=plt.figure()\n",
    "            ax2=figy.add_subplot()\n",
    "            ax2.set_title('d$B_Y$/dt at ' + station)\n",
    "            ax2.set_xlabel('time (days after 1 jan 2000)')\n",
    "            if self.minute:\n",
    "                ax1.set_ylabel(f'd$B_Y$/dt (nt/min)')\n",
    "            else:\n",
    "                ax1.set_ylabel(f'd$B_Y$/dt (nt/s)')\n",
    "            ax2.plot(time,dYdt,label='residue',color='red')\n",
    "            ax2.legend()\n",
    "\n",
    "            plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/db\\dtY.png')\n",
    "\n",
    "        ### horizontal component ###\n",
    "        Hor_comp=np.sqrt(SpaceX**2+SpaceY**2)\n",
    "        dHdt=np.zeros(len(Hor_comp))\n",
    "        for item in range(len(Hor_comp)-1): # obtain derivative\n",
    "            dHdt[item]=Hor_comp[item+1]-Hor_comp[item]\n",
    "\n",
    "        figH=plt.figure()\n",
    "        ax1=figH.add_subplot(211)\n",
    "        ax1.set_title('horizontal component at ' + station)\n",
    "        ax1.set_xlabel('time')\n",
    "        ax1.set_ylabel('nT')\n",
    "        ax1.plot(time,Hor_comp,color='red')\n",
    "        ax2=figH.add_subplot(212)\n",
    "        ax2.set_xlabel('time')\n",
    "        if self.minute:\n",
    "            ax2.set_ylabel('nT/min')\n",
    "        else:\n",
    "            ax2.set_ylabel('nT/s')\n",
    "        ax2.plot(time,dHdt,color='red')\n",
    "        plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/Horizontal_data.png')\n",
    "\n",
    "    # ##### save files #####\n",
    "        newfile=pd.DataFrame(columns=['B_theta (nt)','B_phi (nt)','B_r (nt)','B_H','dBx/dt','dBy/dt','dBH/dt'])\n",
    "        newfile['B_theta (nt)']=SpaceX\n",
    "        newfile['B_phi (nt)']=SpaceY\n",
    "        newfile['B_r (nt)']=SpaceZ\n",
    "        newfile['B_H']=Hor_comp\n",
    "        newfile['dBx/dt']=dXdt\n",
    "        newfile['dBy/dt']=dYdt\n",
    "        newfile['dBH/dt']=dHdt\n",
    "        newfile.to_csv(path_or_buf=f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/allresults.csv', sep=';', index=False, header=True)\n",
    "        plt.close('all')\n",
    "\n",
    "    def ObtainJ(self,q,kabels,EX_matrix,EY_matrix,lat,lon,time,trafo_connect,trafo_all_connections,trafo_cond,trafo,guess,localvar):\n",
    "        \"\"\" Calculates the induced current in the cables and 'sums' them together per transformerstation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        q : integer (required)\n",
    "           processor number\n",
    "        kabels : pandas dataframe (required)\n",
    "           contains information about the transmission cables, see spreadsheetcables.ods for clarification\n",
    "        EX_matrix : numpy matrix (required)\n",
    "           electric field in northern direction stored in a (tsteps,npts) matrix. tsteps are the amount of timesteps, npts are the number of spatial points for which the electric field is calculated\n",
    "        EY_matrix : numpy matrix (required)\n",
    "           electric field in eastern direction stored in a (tsteps,npts) matrix. tsteps are the amount of timesteps, npts are the number of spatial points for which the electric field is calculated\n",
    "        lat : numpy array (required)\n",
    "           latitude of spatial points where electric field is calculated\n",
    "        lon : numpy array (required)\n",
    "           longitude of spatial points where electric field is calculated\n",
    "        time : integer (required)\n",
    "           timestep for which the integration has to be carried out\n",
    "        trafo_connect : boolean numpy matrix (required)\n",
    "           symmetric matrix (len(trafo),len(trafo)) that determines whether tranformers are directly connected to each other (=True) or not (=False)\n",
    "        trafo_cond : numpy matrix (required)\n",
    "           conductivity matrix as defined by Boteler & Pirjola's 'Modeling geomagnetically induced currents' (2017)\n",
    "        trafo : pandas dataframe (required)\n",
    "           dataframe containing information about the transformers, see spreadsheettrafo.ods for clarification\n",
    "        guess : integer (required)\n",
    "           initial amount of integration intervals to calculate the electric potential\n",
    "        localvar : object (required)\n",
    "           object were every single processor can store its variables separately without mixing them up between processors\n",
    "        \n",
    "        NEEDS TO BE USED WITH GICfunction() TO WORK PROPERLY\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        calcE(kabels,EX_matrix,EY_matrix,lat,lon,time,guess,localvar) : calculates the electric potential per transmission cable\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        localvar.J_north : numpy array\n",
    "           contains the sum of all northern directed induced currents per transformer station\n",
    "        localvar.J_east :  numpy array\n",
    "           contains the sum of all eastern directed induced currents per transformer station\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import logging\n",
    "        \n",
    "        localvar.cablecheck=np.zeros(len(kabels))\n",
    "        localvar.E_kabels=np.zeros((len(kabels),2))      \n",
    "        logging.info(f'Thread {q} has started integration procedure!')\n",
    "        localvar.E_kabels=self.calcE(kabels,EX_matrix,EY_matrix,lat,lon,time,guess,localvar)\n",
    "        logging.info(f'Thread {q} has finished integration procedure and is now writing results!')\n",
    "        localvar.stat_voltN=np.zeros((len(trafo_connect),len(trafo_connect)))\n",
    "        localvar.stat_voltE=np.zeros((len(trafo_connect),len(trafo_connect)))\n",
    "        localvar.J_north=np.zeros(len(trafo_connect))\n",
    "        localvar.J_east=np.zeros(len(trafo_connect))\n",
    "        for localvar.row,localvar.line in enumerate(trafo_connect):\n",
    "            ruleA=999\n",
    "            for localvar.column,localvar.item in enumerate(localvar.line):\n",
    "                if localvar.item:\n",
    "                    for localvar.number in range(len(kabels)):\n",
    "                        localvar.cablecheck[localvar.number]=trafo_all_connections[localvar.row,localvar.number]+trafo_all_connections[localvar.column,localvar.number]\n",
    "                    localvar.A=np.array(np.where(localvar.cablecheck==2)) #find indices that indicate cables connected\n",
    "\n",
    "                    localvar.coord=trafo.at[localvar.row,'lat']\n",
    "                    for localvar.counter2 in range(len(localvar.A[0])): #double loop to check the cable connections\n",
    "                        for localvar.counter in range(len(localvar.A[0])):\n",
    "                            if abs(localvar.coord-kabels.at[localvar.A[0,localvar.counter],'strtlat'])<0.00001 and abs(ruleA-localvar.A[0,localvar.counter])>0.51: #check coord for which cable is connected and same cable is not allowed!\n",
    "                                localvar.coord=kabels.at[localvar.A[0,localvar.counter],'eindlat']\n",
    "                                ruleA=localvar.A[0,localvar.counter] #rule to ensure that the same cable is not picked again\n",
    "\n",
    "                                # first North component\n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlat'] < kabels.at[localvar.A[0,localvar.counter],'eindlat']:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]*-1\n",
    "                                else:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]\n",
    "                                # now East component    \n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlon'] < kabels.at[localvar.A[0,localvar.counter],'eindlon']:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]*-1\n",
    "                                else:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]\n",
    "                                break                           \n",
    "                            elif abs(localvar.coord-kabels.at[localvar.A[0,localvar.counter],'eindlat'])<0.00001 and abs(ruleA-localvar.A[0,localvar.counter])>0.51:\n",
    "                                ruleA=localvar.A[0,localvar.counter]\n",
    "                                localvar.coord=kabels.at[localvar.A[0,localvar.counter],'strtlat']\n",
    "\n",
    "                                # first North component\n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlat'] < kabels.at[localvar.A[0,localvar.counter],'eindlat']:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]\n",
    "                                else:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]*-1\n",
    "                                # now East component    \n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlon'] < kabels.at[localvar.A[0,localvar.counter],'eindlon']:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]\n",
    "                                else:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]*-1\n",
    "                                break\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "                localvar.J_north[localvar.row]+=localvar.stat_voltN[localvar.row,localvar.column]*trafo_cond[localvar.row,localvar.column]*-1*-1 #extra -1 -1 to get J in opposite direction of E\n",
    "                localvar.J_east[localvar.row]+=localvar.stat_voltE[localvar.row,localvar.column]*trafo_cond[localvar.row,localvar.column]*-1*-1\n",
    "        return localvar.J_north, localvar.J_east\n",
    "    \n",
    "    def Parzen(self,N):\n",
    "        \"\"\" Creates a Parzen window/filter for inputted length\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        N : integer (required)\n",
    "           sets length of Parzen window\n",
    "           \n",
    "        Returns\n",
    "        -------\n",
    "        W : numpy array\n",
    "           the Parzen filter to be applied to the data with length N\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        W=np.zeros(N)\n",
    "        for nr in range(N):\n",
    "            W[nr]=1-(2*(nr-N/2)/N)**8\n",
    "        return W\n",
    "    \n",
    "    def plottinglatlon(self,q,string,string2,start,end,lock,lock2):\n",
    "        \"\"\" Optional plotting of the magnetic interpolated values over Dutch powergrid\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        q : integer (required)\n",
    "           processor number\n",
    "        string : list of strings (required)\n",
    "           list to location of northward directed mangetic values\n",
    "        string2 : list of strings (required)\n",
    "           list to location of eastward directed mangetic values\n",
    "        start : integer (required)\n",
    "           starting timestep \n",
    "        end : integer (required)\n",
    "           ending timestep\n",
    "        lock : object (required)\n",
    "           locks a piece of code for other processors when one processor is working on it\n",
    "        lock2 : object (required)\n",
    "           locks a piece of code for other processors when one processor is working on it\n",
    "        \n",
    "        NEEDS TO BE USED WITH plot_magnetic() TO WORK PROPERLY\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        minlat_*.png : png files\n",
    "           visual representation of magnetic contourlines over the Dutch (and surrounding) area\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        import os\n",
    "        proj='-JM15C -P'\n",
    "        lims1='-R18/30/59.5/70'#'-R-4.9/0.6/50.7/56.3'\n",
    "        lims2='-R18/30/59.5/70'#'-R-4.9/0.6/50.7/56.3'\n",
    "        for item in string[start:end]:\n",
    "            with lock:\n",
    "                item2=item.strip('.csv')\n",
    "                nr=item2.strip('minute_')\n",
    "                logging.info(f'Thread {q} has obtained latlock for step {nr}.')\n",
    "                time1=[int(int(nr)/60),int(nr)%60]\n",
    "                time1[0]=str(time1[0]).zfill(2)\n",
    "                time1[1]=str(time1[1]).zfill(2)\n",
    "\n",
    "                os.system(f'gmt xyz2grd {self.respath}/{self.date}/interpolation/{item} -G{self.respath}/{self.date}/Graphs/gridlat{nr}.grd -I0.1 -V -N0 {lims1}')\n",
    "                psfile1=f'{self.respath}/{self.date}/Graphs/minlat_{nr}.ps'\n",
    "                os.system(f'gmt pscoast {proj} {lims2} -W0.25p -Ggrey -Slightblue -N1/0.25p -Df -K> {psfile1}' )\n",
    "                os.system(f'gmt psbasemap {proj} {lims2} -Ba1 -BWeSn+t\"Bx at {self.date} -- {time1[0]}:{time1[1]}\" -O -K>> {psfile1}' )\n",
    "                os.system(f'gmt grdcontour {self.respath}/{self.date}/Graphs/gridlat{nr}.grd -C10 -A50+f9p {proj} {lims2} -O >>{psfile1}')\n",
    "                logging.info(f'Thread {q} has released latlock.')\n",
    "#             os.system(f'convert -density 300 {psfile1} {self.respath}/{self.date}/Graphs/minlat_{nr}.png')\n",
    "#             os.system(f'rm {psfile1}')\n",
    "            os.system(f'rm {self.respath}/{self.date}/Graphs/gridlat{nr}.grd')\n",
    "            logging.info(f'Thread {q} has finished plotting lat for step {nr}.')  \n",
    "\n",
    "        for item in string2[start:end]:\n",
    "            with lock2:\n",
    "                item2=item.strip('.csv.Y')\n",
    "                nr=item2.strip('minute_')\n",
    "                logging.info(f'Thread {q} has obtained lonlock for step {nr}.')\n",
    "                time2=[int(int(nr)/60),int(nr)%60]\n",
    "                time2[0]=str(time2[0]).zfill(2)\n",
    "                time2[1]=str(time2[1]).zfill(2)\n",
    "\n",
    "                os.system(f'gmt xyz2grd {self.respath}/{self.date}/interpolation/{item} -G{self.respath}/{self.date}/Graphs/gridlon{nr}.grd -I0.1 -V -N0 {lims1}')\n",
    "                psfile2=f'{self.respath}/{self.date}/Graphs/minlon_{nr}.ps'\n",
    "                os.system(f'gmt pscoast {proj} {lims2} -W0.25p -Ggrey -Slightblue -N1/0.25p -Df -K> {psfile2}' )\n",
    "                os.system(f'gmt psbasemap {proj} {lims2} -Ba1 -BWeSn+t\"By at {self.date} -- {time2[0]}:{time2[1]}\" -O -K>> {psfile2}' )\n",
    "                os.system(f'gmt grdcontour {self.respath}/{self.date}/Graphs/gridlon{nr}.grd -C10 -A50+f9p {proj} {lims2} -O >>{psfile2}')\n",
    "                logging.info(f'Thread {q} has released lonlock.')\n",
    "#             os.system(f'convert -density 300 {psfile2} {self.respath}/{self.date}/Graphs/minlon_{nr}.png')\n",
    "#             os.system(f'rm {psfile2}')\n",
    "            os.system(f'rm {self.respath}/{self.date}/Graphs/gridlon{nr}.grd')\n",
    "            logging.info(f'Thread {q} has finished plotting lon for step {nr}.')\n",
    "        \n",
    "    def plot_GIC(self,stationlist=None):\n",
    "        \"\"\" Gives a visual representation of GIC per transformer over time\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        stationlist : list of integers (optional)\n",
    "           this list of numbers represents the transformer stations we want to use for our visualisation\n",
    "        \n",
    "        NEEDS GIC_*.csv FILES TO FUNCTION. GIC_*.csv FILES ARE OBTAINED IN calculate_GIC()\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        check_sampling() : obtain amount of samples, minute or second data, and amount of days from magnetic data\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        GIC_allstations.png : png file\n",
    "           a visual representation of GIC per transformer over time\n",
    "        \"\"\"\n",
    "        # plot timelapse GIC\n",
    "        import matplotlib.pyplot as plt\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        self.check_sampling()\n",
    "        if all(elements is None for elements in stationlist):\n",
    "            # Dutch stations to plot\n",
    "            A=np.arange(3,21)\n",
    "            B=np.arange(46,54,1)\n",
    "            stationlist=np.hstack([0,1,A,28,29,32,33,35,43,44,B])\n",
    "           \n",
    "        #reading in all GIC files\n",
    "        if self.minute:\n",
    "            os.system(f\"ls {self.respath}/{self.date}/GIC/GIC_*.csv > {self.respath}/{self.date}/temp.txt\")\n",
    "        else:\n",
    "            for item in range(self.samples//10000+1):\n",
    "                os.system(f\"ls {self.respath}/{self.date}/GIC/GIC_{item}*.csv >> {self.respath}/{self.date}/temp.txt\")\n",
    "        f=open(f\"{self.respath}/{self.date}/temp.txt\")\n",
    "        string=[]\n",
    "\n",
    "        GIC_data=np.zeros((self.samples*self.days,self.lentrafo))\n",
    "\n",
    "        for item in f:\n",
    "            item=item.rstrip('\\n')\n",
    "            string.append(item)\n",
    "        string=sorted(string)\n",
    "        for counter,time in enumerate(string):\n",
    "            GIC_file=pd.read_csv(time, delimiter=';')\n",
    "            GIC=GIC_file.to_numpy()\n",
    "            GIC_data[counter]=GIC[:,2]\n",
    "\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "\n",
    "        stationframe=pd.read_csv(f'{self.netpath}/spreadsheettrafo.csv', delimiter=';')\n",
    "        # plot it, per station\n",
    "        plt.rcParams.update({'font.size': 14}) \n",
    "        timevector=np.linspace(0,24*self.days,self.samples*self.days)\n",
    "        fig1=plt.figure(figsize=(20,15))\n",
    "        ax1=fig1.add_subplot()\n",
    "        ax1.set_title(f'GIC during {self.date}')\n",
    "        ax1.set_ylabel('GIC (A)')\n",
    "        ax1.set_xlabel('Time (hours)')\n",
    "        for station in stationlist:\n",
    "            ax1.plot(timevector,GIC_data[:,station],label=stationframe.at[station,'naam'])\n",
    "        # plt.subplots_adjust(left=0)\n",
    "        lgd=ax1.legend(bbox_to_anchor=(1.01,1))\n",
    "        plt.savefig(f'{self.respath}/{self.date}/GIC_allstations.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "            \n",
    "    def plot_magnetic(self):\n",
    "        \"\"\" Plots interpolated magnetic data as contour lines over the Netherlands (and surrounding area)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        plottinglatlon(q,string,string2,start,end,lock,lock2) : plots the magnetic data using gmt tools\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        minlat_*.png : png files\n",
    "           visual representation of magnetic contourlines over the Dutch (and surrounding) area\n",
    "        \"\"\"\n",
    "        from multiprocessing import Process\n",
    "        import os\n",
    "        from multiprocessing import Lock\n",
    "        import logging\n",
    "        self.check_sampling()\n",
    "        lock=Lock()\n",
    "        lock2=Lock()\n",
    "\n",
    "        thing=os.listdir(f'{self.respath}/{self.date}/interpolation')\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/Graphs')\n",
    "        except:\n",
    "            logging.warning(f\"Directory '{self.respath}/{self.date}/Graphs' could not be formed or already created, data could be destroyed!\")\n",
    "        string=[]\n",
    "        string2=[]\n",
    "        for item in thing:\n",
    "            if item.endswith(\".csv\"):\n",
    "                 string.append(item)\n",
    "            if item.endswith(\".csv.Y\"):\n",
    "                 string2.append(item)\n",
    "        string=sorted(string)\n",
    "        string2=sorted(string2)\n",
    "        n=6\n",
    "        nrsteps=int(self.samples*self.days/n)\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.plottinglatlon, args=(n,string, string2, nrsteps*index, nrsteps*(index+1),lock,lock2))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        logging.info('Plotting completed!')\n",
    "        \n",
    "    def standard_download(self,list_of_stations=None,types=True): \n",
    "        \"\"\" Downloads data automatically for a range of stations from intermagnet\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        list_of_stations : list of strings (optional)\n",
    "           contains the IAGA abbreviation of the stations whose data is to be downloaded\n",
    "        types : boolean (optional)\n",
    "           if True, minute data is to be downloaded (not available before 1991); if False, second data is to be downloaded (not available before 2011)\n",
    "           \n",
    "        Functions\n",
    "        ---------\n",
    "        download_data(day,month,year,station,types) : downloads data from the intermagnet ftp server\n",
    "        find_quiet_date() : finds the solar quiet day which is nearest to the inputted solar 'active' date\n",
    "        \n",
    "        Created Folders\n",
    "        ---------------\n",
    "        '{self.base}/{self.qdate}' : folder where station data of the nearest solar quiet day is stored\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        *dmin.min or *qsec.sec : text files\n",
    "           header information and magnetic observations for one day\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        import os\n",
    "        if list_of_stations==None:\n",
    "            list_of_stations=['fur','had','bfe','clf','dou','esk','ler','ngk','ups','wng']\n",
    "        for station in list_of_stations:\n",
    "            try:\n",
    "                self.download_data(self.day,self.month,self.year,station,types) #download data\n",
    "            except:\n",
    "                logging.warning(f'Data could not be downloaded for station {station}')\n",
    "        if self.qdate==None:\n",
    "            qday, qmonth, qyear = self.find_quiet_date() #find the nearest quiet solar day\n",
    "            self.qdate=f'{qday}-{qmonth}-{qyear}'\n",
    "        else:\n",
    "            quietday = self.qdate.split('-')\n",
    "            qday, qmonth, qyear = quietday[0], quietday[1], quietday[2]\n",
    "        qday=str(qday).zfill(2)\n",
    "        qmonth=str(qmonth).zfill(2)\n",
    "        logging.info(f'Quiet day is {self.qdate}')\n",
    "        print(f'Quiet day is {self.qdate}')\n",
    "        try:\n",
    "            self.quietpath=f'{self.base}/{self.qdate}'\n",
    "            os.mkdir(f'{self.base}/{self.qdate}')\n",
    "        except:\n",
    "            logging.warning(f\"Directory '{self.quietpath}' might already exist, or cannot be formed\")\n",
    "        for station in list_of_stations:\n",
    "            try:\n",
    "                self.download_data(qday,qmonth,qyear,station,types) #download quiet data\n",
    "            except:\n",
    "                logging.warning(f'Data could not be downloaded for station {station}')\n",
    "                \n",
    "    def transferfunction(self,freq,model=7): \n",
    "        \"\"\" Generates the transferfunction to calculate the electric field from a given magnetic field\n",
    "        NB. Where B is given, NOT H!\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        freq : float (required)\n",
    "           frequency of signal\n",
    "        model : integer (optional)\n",
    "           modelnumber of the conductivitymodel that will be used (see code)\n",
    "        \n",
    "        NEEDS TO BE USED WITH BtoE() TO WORK PROPERLY\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Zn/mu : complex float\n",
    "           (complex) number that relates the magnetic field (B) to the electric field (E).\n",
    "           Therefore we divided by mu (=mu0, magnetic permeability in vacuum)\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        mu=4*np.pi*10**(-7)\n",
    "        if freq<=0:\n",
    "            raise Exception('Frequency cannot be any lower or equal to zero!')\n",
    "        elif freq<10**-5:\n",
    "            Zn=0\n",
    "        else:\n",
    "            if model == 1:\n",
    "                cond=np.zeros((2,4)) #business as usual\n",
    "                cond[0,:]=[1./1.,1./5000.,1./1.,1./10.] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,6000,4000,0] #depth top to bottom in m\n",
    "            elif model == 2:\n",
    "                cond=np.zeros((2,4)) #deep ocean\n",
    "                cond[0,:]=[4.,1./5000.,1./1.,1./10.] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,6000,4000,0] #depth top to bottom in m\n",
    "            elif model == 3:\n",
    "                cond=np.zeros((2,2)) #GIC in Europe paper\n",
    "                cond[0,:]=[1./38.5,1./0.385] #conductivity top to bottom\n",
    "                cond[1,:]=[150000,0] #depth top to bottom in m\n",
    "            elif model == 4:\n",
    "                cond=np.zeros((2,4)) #MODELLING OCEAN EFFECT IN LOCAL C-RESPONSES: oceanic mantle\n",
    "                cond[0,:]=[1./10**3,1./20.,1./2.,1./0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[100000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 5:\n",
    "                cond=np.zeros((2,4)) #MODELLING OCEAN EFFECT IN LOCAL C0-RESPONSES: continental mantle\n",
    "                cond[0,:]=[1./(3*10**3),1./70.,1./16.,1./0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[100000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 6: #Pirjola et al 2014: Geomagnetically induced currents in Europe \n",
    "                cond=np.zeros((2,5))\n",
    "                cond[0,:]=[1./(40),1./3.,1./2000.,1./118., 1/15.] #conductivity top to bottom\n",
    "                cond[1,:]=[400,1300,140000,170000,0] #depth top to bottom in m\n",
    "            elif model == 7: # combi model \n",
    "                cond=np.zeros((2,7))\n",
    "                cond[0,:]=[1.,1./5000.,1.,1./(3*10**3),1/70.,1/16.,1/0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,6000,4000,88000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 8: # test model \n",
    "                cond=np.zeros((2,6))\n",
    "                cond[0,:]=[1.,1./5000.,1./(3*10**3),1/70.,1/16.,1/0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,10000,88000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 9: # England model\n",
    "                cond=np.zeros((2,4))\n",
    "                cond[0,:]=[1./500.,1./2000.,1./500.,1./900.] #conductivity top to bottom\n",
    "                cond[1,:]=[10000,10000,10000,0] #depth top to bottom in m\n",
    "            elif model == 10: #Sweden/Finland\n",
    "                cond=np.zeros((2,2))\n",
    "                cond[0,:]=[1./5000.,1./200.]\n",
    "                cond[1,:]=[200000,0]\n",
    "            else:\n",
    "                cond=np.zeros((2,5)) #bit of water (50m)\n",
    "                cond[0,:]=[4,1./1.,1./5000.,1./1.,1./10.] #conductivity top to bottom\n",
    "                cond[1,:]=[50,2000,6000,4000,0] #depth top to bottom in m\n",
    "\n",
    "            #first do bottom layer\n",
    "            kn=np.sqrt(1j*freq*mu*cond[0,-1])\n",
    "            Zn=1j*freq*mu/kn\n",
    "\n",
    "            # iterate from bottom to top\n",
    "            for item in range(2,len(cond[0])+1): #we go in opposite direction later, see Trichtchenko and Boteler (2002)\n",
    "                kn=np.sqrt(1j*freq*mu*cond[0,-item])\n",
    "                rn=(1-kn*(Zn/(1j*freq*mu)))/(1+kn*(Zn/(1j*freq*mu)))\n",
    "                Zn=1j*freq*mu*((1-rn*np.exp(-2*kn*cond[1,-item]))/(kn*(1+rn*np.exp(-2*kn*cond[1,-item]))))\n",
    "\n",
    "        return Zn/mu\n",
    "\n",
    "######################## writing results ###########################################\n",
    "    def writing_electric(self,thread,path,Electric,begin,end,lon,lat,localvar):\n",
    "        \"\"\" Writes the electric field to separate files, depending on direction\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        thread : integer (required)\n",
    "           processor number\n",
    "        path : string (required)\n",
    "           location where files should be written towards\n",
    "        Electric : numpy matrix (required)\n",
    "           (tstep,npts) matrix that contains the electric field in a specific direction for npts points during tstep time\n",
    "        begin : integer (required)\n",
    "           beginstep in time\n",
    "        end : integer (required)\n",
    "           endstep in time\n",
    "        lon : numpy array (required)\n",
    "           longitude of spatial points where electric field is calculated\n",
    "        lat : numpy array (required)\n",
    "           latitude of spatial points where electric field is calculated\n",
    "        localvar : object (required)\n",
    "           object were every single processor can store its variables separately without mixing them up between processors\n",
    "        \n",
    "        NEEDS TO BE USED WITH BtoE() TO WORK PROPERLY\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        electric_*.csv : csv file\n",
    "           contains the electric field per timestep for all points in the given domain;\n",
    "           is in either northern or eastern direction\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        import pandas as pd\n",
    "        #reading files and writing to pandas\n",
    "        for localvar.item in range(begin,end):\n",
    "            logging.info(f'Thread {thread} is writing step {localvar.item}.')\n",
    "            localvar.newfile=pd.DataFrame(columns=['lon','lat','value'])\n",
    "            localvar.newfile.at[:,'lon']=lon\n",
    "            localvar.newfile.at[:,'lat']=lat\n",
    "            localvar.newfile.at[:,'value']=Electric[localvar.item,:]\n",
    "            #write files\n",
    "            if self.minute:\n",
    "                localvar.newfile.to_csv(path_or_buf=f'{path}/electric_{str(localvar.item).zfill(4)}.csv', sep=' ', index=False, header=False)\n",
    "            else:\n",
    "                localvar.newfile.to_csv(path_or_buf=f'{path}/electric_{str(localvar.item).zfill(5)}.csv', sep=' ', index=False, header=False)\n",
    "        \n",
    "    def runall(self,model=7,guess=80,plotgic=True):\n",
    "        \"\"\" Runs all necessary functions to obtain results from scratch \n",
    "        takes for one day and minute data about 1.5 hour with standard parameters\n",
    "        also starts up a logbook to log all processes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        self :  boolean, integer, or string (required)\n",
    "           necessary objects of self are set in the __init__ and check_sampling function. For more information look at the __init__ or check_sampling function\n",
    "        model : integer (optional)\n",
    "           selects which conductivity model is to be used for the transferfunction\n",
    "        guess : integer (optional)\n",
    "           gives an estimation in how many pieces the integration of the electric field should be executed in the calcE function. Standard set at 80.\n",
    "        plotgic : boolean (optional)\n",
    "           if True, png figures of GIC in the powergrid are plotted per timestep, also a video of these images is generated\n",
    "        \n",
    "        Functions\n",
    "        ---------\n",
    "        standard_download() : downloads for a range of stations magnetic data from intermagnet for both active and quiet solar day\n",
    "        iteratestation() : calculates the resulting magnetic field by subtracting the quiet day from the active day\n",
    "        magnetic_interpolation() : interpolates the magnetic field for the given domain\n",
    "        BtoE(model) : transfers the magnetic field into an electric field using a given conductivity model\n",
    "        calculate_GIC(guess) : calculates GICs in the powergrid and produces *.png files\n",
    "        plot_GIC() : plot GICs as a function of time per Dutch transformer station\n",
    "        make_video(namein,nameout) : makes a video of generated *.png files\n",
    "        \n",
    "        Created folders\n",
    "        ---------------\n",
    "        many folders : see other functions\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        much : see other functions\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        logging.basicConfig(filename=f'{self.respath}/logbook.log', level=logging.DEBUG, format='%(asctime)s %(message)s')\n",
    "        logging.info('Script starting')\n",
    "        \n",
    "        self.standard_download()\n",
    "        self.iteratestation()\n",
    "        self.magnetic_interpolation()\n",
    "        self.BtoE(model)\n",
    "        if plotgic:\n",
    "            self.calculate_GIC(guess)\n",
    "            self.plot_GIC()\n",
    "            self.make_video(f'{self.respath}/{self.date}/GIC/GIC_at_',f'GIC_at_{self.date}')\n",
    "        else:\n",
    "            self.calculate_GIC(guess,False)\n",
    "            self.plot_GIC()\n",
    "        logging.info('Script has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data is added now!\n",
      "Script has been completed!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "A=np.arange(3,21)\n",
    "B=np.arange(41,49)\n",
    "stationlist=np.hstack([0,1,A,25,26,29,30,32,39,40,B])\n",
    "logging.basicConfig(filename=f'/usr/people/out/Documents/logbook.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "# Halloween=GIC('/usr/people/out/Documents/Extended_powergrid','/usr/people/out/Documents/Magnetic_field/magnetic_data','/nobackup/users/out/Magnetic_field','29-10-2003')\n",
    "# Halloween.standard_download()\n",
    "# Halloween.iteratestation()\n",
    "# Halloween.magnetic_interpolation()\n",
    "# Halloween=GIC('/usr/people/out/Documents/Extended_powergrid','/usr/people/out/Documents/Magnetic_field/magnetic_data','/nobackup/users/out/Magnetic_field','30-10-2003')\n",
    "# Halloween.standard_download()\n",
    "# Halloween.iteratestation()\n",
    "# Halloween.magnetic_interpolation()\n",
    "# Halloween=GIC('/usr/people/out/Documents/Extended_powergrid','/usr/people/out/Documents/Magnetic_field/magnetic_data','/nobackup/users/out/Magnetic_field','31-10-2003')\n",
    "# Halloween.standard_download()\n",
    "# Halloween.iteratestation()\n",
    "# Halloween.magnetic_interpolation()\n",
    "# Halloween.glue_data(['/nobackup/users/out/Magnetic_field/29-10-2003/interpolation','/nobackup/users/out/Magnetic_field/30-10-2003/interpolation','/nobackup/users/out/Magnetic_field/31-10-2003/interpolation'],'new_Halloween')\n",
    "Halloween=GIC('/usr/people/out/Documents/more_reduced','/usr/people/out/Documents/Magnetic_field/magnetic_data','/nobackup/users/out/Magnetic_field','new_Halloween')\n",
    "# Halloween.BtoE(7)\n",
    "Halloween.calculate_GIC(150,False)\n",
    "Halloween.plot_GIC(stationlist)\n",
    "# Halloween.make_video(f'{Halloween.respath}/{Halloween.date}/GIC/GIC_at_',f'GIC_at_{Halloween.date}')\n",
    "# Halloween.plot_magnetic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('shutdown now')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
