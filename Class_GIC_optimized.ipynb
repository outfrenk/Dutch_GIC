{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIC: \n",
    "    # __init__ sets basic path for location:\n",
    "    # netpath: path to folder where powernetwork csv files are\n",
    "    # statpath: path to folder where unpacked data stations are for GIC calculation\n",
    "    # respath: path to where results need to be written\n",
    "    # day: day for GIC calculation given as dd-mm-yyyy\n",
    "    # quietday:path to folder where unpacked data stations are quiet reference day for GIC calculation,\n",
    "    # found by the website of Potzdam: ftp://ftp.gfz-potsdam.de/pub/home/obs/kp-ap/quietdst/\n",
    "    def __init__(self,netpath,base,respath,date=None,qdate=None):\n",
    "        import logging\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        self.netpath=netpath\n",
    "        self.base=base\n",
    "        self.respath=respath\n",
    "        self.date=date\n",
    "        self.qdate=qdate\n",
    "        self.minute=None\n",
    "        self.samples=0\n",
    "        self.days=1\n",
    "        self.lentrafo=len(pd.read_csv(self.netpath+'/spreadsheettrafo.csv', delimiter = ';')) \n",
    "        if not date == None:\n",
    "            try:\n",
    "                datesplit=self.date.split('-')\n",
    "                self.day=datesplit[0]\n",
    "                self.month=datesplit[1]\n",
    "                self.year=datesplit[2]\n",
    "                self.datevar=f'{self.year}-{self.month}-{self.day}' #get day string in reverse order, so yyyy-mm-dd\n",
    "            except:\n",
    "                raise ValueError('Date has not been inputted correctly, it should be dd-mm-yyyy')\n",
    "            try:\n",
    "                self.statpath=f'{self.base}/{self.date}'\n",
    "                os.mkdir(f'{self.base}/{self.date}')\n",
    "            except:\n",
    "                logging.warning(f\"Directory '{self.statpath}' might already exist, or cannot be formed\")\n",
    "        else:\n",
    "            self.day = self.month = self.year = self.datevar = self.statpath = None\n",
    "            \n",
    "        if not self.qdate==None:\n",
    "            self.quietpath=f'{self.base}/{self.qdate}'\n",
    "            try:\n",
    "                os.mkdir(f'{self.base}/{self.qdate}')\n",
    "            except:\n",
    "                logging.warning(f\"Directory '{self.quietpath}' might already exist, or cannot be formed\")\n",
    "        else:\n",
    "            self.quietpath=None\n",
    "        #create topomap for plotting GICs in correct colour, blue is into network, red is into ground\n",
    "        f=open(\"topo.cpt\",\"w+\")\n",
    "        f.write(\"-10000 0/0/100 0 0/0/100\\n\")\n",
    "        f.write(\"0 100/0/0 10000 100/0/0\")\n",
    "        f.close()\n",
    "\n",
    "    def BtoE(self,model,scaling=1):                        \n",
    "        import numpy as np\n",
    "        import os\n",
    "        from multiprocessing import Process\n",
    "        import pandas as pd\n",
    "        from threading import local\n",
    "        import logging\n",
    "        localvar=local()\n",
    "\n",
    "        # import magnetic field data in X/Y-direction (north)\n",
    "        magnetic_Xfiles=[]\n",
    "        magnetic_Yfiles=[]\n",
    "        self.check_sampling()\n",
    "        ############################# get the strings ###################################\n",
    "        if self.minute==True:\n",
    "            os.system(f\"ls {self.respath}/{self.date}/interpolation/minute_????.csv > {self.respath}/{self.date}/tempX.txt\")\n",
    "            os.system(f\"ls {self.respath}/{self.date}/interpolation/minute_????.csv.Y > {self.respath}/{self.date}/tempY.txt\")\n",
    "            f=open(f'{self.respath}/{self.date}/tempX.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Xfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempX.txt')\n",
    "            f=open(f'{self.respath}/{self.date}/tempY.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Yfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempY.txt')\n",
    "        else:\n",
    "            for item in range(self.samples//10000+1):\n",
    "                os.system(f\"ls {self.respath}/{self.date}/interpolation/second_{item}????.csv >> {self.respath}/{self.date}/tempX.txt\")\n",
    "                os.system(f\"ls {self.respath}/{self.date}/interpolation/second_{item}????.csv.Y >> {self.respath}/{self.date}/tempY.txt\")\n",
    "            f=open(f'{self.respath}/{self.date}/tempX.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Xfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempX.txt')\n",
    "            f=open(f'{self.respath}/{self.date}/tempY.txt')\n",
    "            for item in f:\n",
    "                item=item.strip('\\n')\n",
    "                magnetic_Yfiles.append(item)\n",
    "            f.close()\n",
    "            os.system(f'rm {self.respath}/{self.date}/tempY.txt')\n",
    "\n",
    "        magnetic_Xfiles=sorted(magnetic_Xfiles) #sort to number 0000-1440 or 86400\n",
    "        magnetic_Yfiles=sorted(magnetic_Yfiles)\n",
    "        \n",
    "        for file in magnetic_Xfiles:\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            break\n",
    "        for file in magnetic_Yfiles:\n",
    "            Yfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            break\n",
    "\n",
    "        lat=np.zeros(len(Xfile))\n",
    "        lon=np.zeros(len(Xfile))\n",
    "        MX_matrix=np.zeros((len(magnetic_Xfiles),len(Xfile)))#matrix for storing values (vertical same place, horizontal same time)\n",
    "        MX_parz=np.zeros((3*len(magnetic_Xfiles),len(Xfile)))\n",
    "        MXft_matrix=np.zeros((int(3*len(magnetic_Xfiles)/2)+1,len(Xfile)),dtype='complex')\n",
    "        EX_matrix=np.zeros((len(magnetic_Yfiles),len(Yfile)))\n",
    "        EX_parz=np.zeros((3*len(magnetic_Yfiles),len(Yfile)))\n",
    "        EXft_matrix=np.zeros((int(3*len(magnetic_Yfiles)/2)+1,len(Yfile)),dtype='complex')\n",
    "        MY_matrix=np.zeros((len(magnetic_Yfiles),len(Yfile))) #matrix for storing values (vertical same place, horizontal same time)\n",
    "        MY_parz=np.zeros((3*len(magnetic_Yfiles),len(Yfile)))\n",
    "        MYft_matrix=np.zeros((int(3*len(magnetic_Yfiles)/2)+1,len(Yfile)),dtype='complex')\n",
    "        EY_matrix=np.zeros((len(magnetic_Xfiles),len(Xfile)))\n",
    "        EY_parz=np.zeros((3*len(magnetic_Xfiles),len(Xfile)))\n",
    "        EYft_matrix=np.zeros((int(3*len(magnetic_Xfiles)/2)+1,len(Xfile)),dtype='complex')\n",
    "        ################################################################################# \n",
    "        ########################### get the values ######################################\n",
    "        ######################### first x-direction #####################################\n",
    "        print('setting up matrices!')\n",
    "        for counter,file in enumerate(magnetic_Xfiles):\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Xfile.to_numpy()\n",
    "            MX_matrix[counter,:]=values[:,2]/(10**9)*scaling #scaling factor\n",
    "        lat=values[:,1]\n",
    "        lon=values[:,0]\n",
    "        for counter,file in enumerate(magnetic_Yfiles):\n",
    "            Yfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Yfile.to_numpy()\n",
    "            MY_matrix[counter,:]=values[:,2]/(10**9)*scaling\n",
    "\n",
    "        ############## start fourier transformation ######################\n",
    "        print('starting fourier transformation')\n",
    "\n",
    "    # try Parzen window now\n",
    "        MX_parz[0:len(magnetic_Xfiles),:]=MX_matrix[0,:]\n",
    "        MX_parz[2*len(magnetic_Xfiles):,:]=MX_matrix[-1,:]\n",
    "        MX_parz[len(magnetic_Xfiles):2*len(magnetic_Xfiles),:]=MX_matrix\n",
    "        MY_parz[0:len(magnetic_Yfiles),:]=MY_matrix[0,:]\n",
    "        MY_parz[2*len(magnetic_Yfiles):,:]=MY_matrix[-1,:]\n",
    "        MY_parz[len(magnetic_Yfiles):2*len(magnetic_Yfiles),:]=MY_matrix\n",
    "        for column in range(len(MX_matrix[0])):\n",
    "            MXft_matrix[:,column]=np.fft.rfft(MX_parz[:,column]*self.Parzen(len(MX_parz))) #multiply with hanning window to reduce edge effects\n",
    "        for column in range(len(MY_matrix[0])):\n",
    "            MYft_matrix[:,column]=np.fft.rfft(MY_parz[:,column]*self.Parzen(len(MY_parz)))\n",
    "\n",
    "        ######################### calculate Electric field in frequency direction #############################3\n",
    "        # make frequencyvector in seconds\n",
    "        df=1./(24*60*60.*self.days*3) # seconds! #aangepast\n",
    "        if self.minute:\n",
    "            fmax=1./(2*60.)\n",
    "        else:\n",
    "            fmax=1./(2*1)\n",
    "        freqvec=np.arange(0,fmax+0.5*df,df) \n",
    "        #filter signal for noise\n",
    "        MXft_matrix=self.filt(freqvec,MXft_matrix)\n",
    "        MYft_matrix=self.filt(freqvec,MYft_matrix)\n",
    "        \n",
    "        # t3_start=process_time() #1d conductivity model!\n",
    "        for row in range(1,len(MXft_matrix)): #zero is not allowed, same row = same frequency\n",
    "            EYft_matrix[row,:]=-1*MXft_matrix[row,:]*self.transferfunction(freqvec[row],model)\n",
    "        for row in range(1,len(MYft_matrix)): #zero is not allowed\n",
    "            EXft_matrix[row,:]=MYft_matrix[row,:]*self.transferfunction(freqvec[row],model)\n",
    "\n",
    "        ######################## fourier transform back ####################################\n",
    "        # t4_start=process_time()\n",
    "        for column in range(len(EYft_matrix[0])):\n",
    "            EY_parz[:,column]=np.fft.irfft(EYft_matrix[:,column])\n",
    "        for column in range(len(EXft_matrix[0])):\n",
    "            EX_parz[:,column]=np.fft.irfft(EXft_matrix[:,column])\n",
    "            \n",
    "        EX_matrix=EX_parz[len(magnetic_Xfiles):2*len(magnetic_Xfiles),:]\n",
    "        EY_matrix=EY_parz[len(magnetic_Yfiles):2*len(magnetic_Yfiles),:]\n",
    "\n",
    "        del MX_matrix, MX_parz, MXft_matrix, EX_parz, EXft_matrix, MY_matrix, MY_parz, MYft_matrix, EY_parz, EYft_matrix\n",
    "        ######################### writing E field to files #################################\n",
    "        # t5_start=process_time()\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/electric_field_east')\n",
    "        except:\n",
    "            logging.warning('Directory is already created, data could be overwritten.')\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/electric_field_north')\n",
    "        except:\n",
    "            logging.warning('Directory is already created, data could be overwritten.')\n",
    "\n",
    "        n=6\n",
    "        nrsteps=int(self.samples*self.days/n) #aangepast\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.writing_electric, args=(index+1, f'{self.respath}/{self.date}/electric_field_east', EY_matrix, nrsteps*index, nrsteps*(index+1), lon, lat, localvar))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.writing_electric, args=(index+1, f'{self.respath}/{self.date}/electric_field_north', EX_matrix, nrsteps*index, nrsteps*(index+1), lon, lat, localvar))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "    def calculate_GIC(self,guess=80, plotting=True):\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import math\n",
    "        import logging\n",
    "        from scipy.interpolate import griddata\n",
    "        from threading import local\n",
    "        localvar=local()\n",
    "        from multiprocessing import Process\n",
    "        from multiprocessing import Lock\n",
    "        lock=Lock()\n",
    "        self.check_sampling()\n",
    "        # create basic file: coordinates of trafo and cables\n",
    "        netwerk=pd.read_csv(f'{self.netpath}/spreadsheetcables.csv', delimiter = ';')\n",
    "        coord2=pd.DataFrame(columns=['lon', 'lat'])\n",
    "        coord1=pd.DataFrame(columns=['lon', 'lat'])\n",
    "        for line in range(len(netwerk)): # put end locations under start location for gmt, so that you double the lines\n",
    "            coord1.at[2*line,'lon']=netwerk.at[line,'strtlon'] \n",
    "            coord1.at[2*line,'lat']=netwerk.at[line,'strtlat'] \n",
    "            coord1.at[2*line+1,'lon']=netwerk.at[line,'eindlon']\n",
    "            coord1.at[2*line+1,'lat']=netwerk.at[line,'eindlat'] \n",
    "            # if statement to spot discontinuities\n",
    "            if line>0 and coord1.at[2*line-1,'lat']!=coord1.at[2*line,'lat'] and coord1.at[2*line-1,'lon']!=coord1.at[2*line,'lon']:\n",
    "                coord3=pd.DataFrame([[coord1.at[2*line,'lon'], coord1.at[2*line,'lat']]], columns=['lon', 'lat']) #create new dataframe\n",
    "                coord1.at[2*line,'lon']='>'+str(coord1.at[2*line,'lon']) #add > for gmt\n",
    "                coord2=coord2.append(coord1.loc[2*line]) #append it\n",
    "                coord2=coord2.append(coord3) #append old one, otherwise no line will be drawn\n",
    "                coord2=coord2.append(coord1.loc[2*line+1]) #append the one after\n",
    "                del coord3\n",
    "            else:\n",
    "                coord2=coord2.append(coord1.loc[2*line])\n",
    "                coord2=coord2.append(coord1.loc[2*line+1])\n",
    "\n",
    "        #write to a file with no header and column titles\n",
    "        coord2.to_csv(path_or_buf=f'{self.netpath}/cables.csv', sep=' ', index=False, header=False)\n",
    "        \n",
    "        #################################### first reading in datasets #####################################################  \n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/GIC')\n",
    "        except:\n",
    "            logging.warning(\"Directory has already been created, data could be destroyed!\")\n",
    "            print(\"Directory has already been created, data could be destroyed!\")\n",
    "        logging.info('Reading in datasets!')\n",
    "        Electric_Xfiles=[]\n",
    "        Electric_Yfiles=[]\n",
    "        if self.minute:\n",
    "            os.system(f' ls {self.respath}/{self.date}/electric_field_north/*.csv > {self.respath}/{self.date}/tempX.txt')\n",
    "            os.system(f' ls {self.respath}/{self.date}/electric_field_east/*.csv > {self.respath}/{self.date}/tempY.txt')\n",
    "        else:\n",
    "            for item in range(self.samples//10000+1):\n",
    "                os.system(f' ls {self.respath}/{self.date}/electric_field_north/electric_{item}????.csv >> {self.respath}/{self.date}/tempX.txt')\n",
    "                os.system(f' ls {self.respath}/{self.date}/electric_field_east/electric_{item}????.csv >> {self.respath}/{self.date}/tempY.txt')\n",
    "            \n",
    "        f=open(f'{self.respath}/{self.date}/tempX.txt')\n",
    "        for item in f:\n",
    "            item=item.strip('\\n')\n",
    "            Electric_Xfiles.append(item)\n",
    "        f.close()\n",
    "        \n",
    "        f=open(f'{self.respath}/{self.date}/tempY.txt')\n",
    "        for item in f:\n",
    "            item=item.strip('\\n')\n",
    "            Electric_Yfiles.append(item)\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/tempX.txt')\n",
    "        os.system(f'rm {self.respath}/{self.date}/tempY.txt')\n",
    "        logging.debug('Electric files created!')\n",
    "\n",
    "        for counter,file in enumerate(Electric_Xfiles):\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Xfile.to_numpy()\n",
    "            break\n",
    "        EX_matrix=np.zeros((len(Electric_Xfiles),len(values)))    \n",
    "        EY_matrix=np.zeros((len(Electric_Xfiles),len(values)))\n",
    "        logging.debug('Electric matrices have been made in memory!')\n",
    "\n",
    "        for counter,file in enumerate(Electric_Xfiles):\n",
    "            Xfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Xfile.to_numpy()\n",
    "            EX_matrix[counter,:]=values[:,2]\n",
    "        logging.debug('EX_matrix has been made!')\n",
    "        lat=values[:,1]\n",
    "        lon=values[:,0]\n",
    "        for counter,file in enumerate(Electric_Yfiles):\n",
    "            Yfile=pd.read_csv(file, delimiter=' ', header=None)\n",
    "            values=Yfile.to_numpy()\n",
    "            EY_matrix[counter,:]=values[:,2]\n",
    "        del item, f, Xfile, values, Yfile\n",
    "\n",
    "        ######################################### Getting the needed GIC matrices and code #################################\n",
    "        logging.info('Starting with the GIC code!')\n",
    "        kabels=pd.read_csv(self.netpath+'/spreadsheetcables.csv', delimiter = ';')\n",
    "        trafo=pd.read_csv(self.netpath+'/spreadsheettrafo.csv', delimiter = ';')\n",
    "        trafo_connect=np.zeros((len(trafo),len(trafo))) #connectivity trafo\n",
    "        trafo_all_connections=np.zeros((len(trafo),len(kabels))) #connections possible between trafo and every cable\n",
    "        trafo_cond=np.zeros((len(trafo),len(trafo))) # The conductivity matrix\n",
    "        stat_heading=np.zeros((len(trafo),len(trafo))) #heading stations to another\n",
    "        stat_length=np.zeros((len(trafo),len(trafo))) #length between stations\n",
    "        station_lat=np.zeros(len(trafo)) #latitude stations in degrees\n",
    "        station_lon=np.zeros(len(trafo)) #longitude stations in degrees\n",
    "        ground_cond=np.zeros(len(trafo))\n",
    "        cable_icon=np.zeros(len(kabels)) # icon array for cable and trafo resp.\n",
    "        trafo_icon=np.zeros(len(trafo))\n",
    "\n",
    "        ##### connect trafo and cable number to position in matrix #####\n",
    "        for line in range(len(kabels)):\n",
    "            cable_icon[line]=kabels.at[line,'kabelnr']\n",
    "        for line in range(len(trafo)):\n",
    "            trafo_icon[line]=trafo.at[line,'trafonr']\n",
    "        ##### make trafo-trafo connectivity matrix ######\n",
    "        for line in range(len(trafo)): \n",
    "            temp=trafo.at[line,'verbonden trafo'] #get right column\n",
    "            temp=temp.split(\",\") #split values\n",
    "\n",
    "            for item in temp:\n",
    "                temp2=int(item)\n",
    "                trafo_connect[line,np.where(trafo_icon == temp2)[0]]=True #check for connection other trafo\n",
    "                del temp2\n",
    "            del temp\n",
    "        ###### make trafo-cable connectivity matrix ######\n",
    "        for line in range(len(trafo)):\n",
    "            temp=trafo.at[line,'alle aansluitingen']\n",
    "            temp=temp.split(\",\")\n",
    "            for item in temp:\n",
    "                temp2=int(item)\n",
    "                trafo_all_connections[line,np.where(cable_icon == temp2)[0]]=True\n",
    "                del temp2\n",
    "            del temp\n",
    "        ###### make conductivity matrix ######\n",
    "        for row,line in enumerate(trafo_connect):\n",
    "            trafo_cond[row,row]=trafo.at[row,'conductivity total']\n",
    "            for column,item in enumerate(line):\n",
    "                if item:\n",
    "                    temp=trafo_all_connections[row,:]+trafo_all_connections[column,:]\n",
    "                    temp2=0\n",
    "                    for counter,value in enumerate(temp):\n",
    "                        if value == 2: # if 2 then we have found the connecting cables\n",
    "                            temp2+=1/(float(kabels.at[counter,'conductivity'])*kabels.at[counter,'kab/3'])  #because of serieschain we have to add 1/sigma\n",
    "\n",
    "                    trafo_cond[row,column]=-1/temp2 #add cable resistance to off-diagonal\n",
    "                    trafo_cond[row,row]+=1/temp2 #add cable resistance to trace\n",
    "                    del temp, temp2\n",
    "        ###### get heading and length between stations #####\n",
    "        for row,line in enumerate(trafo_connect):\n",
    "            for column,item in enumerate(line):\n",
    "                if item and column>=row:\n",
    "                    Alat=np.radians(trafo.at[row,'lat'])\n",
    "                    Alon=np.radians(trafo.at[row,'lon'])\n",
    "                    Blat=np.radians(trafo.at[column,'lat'])\n",
    "                    Blon=np.radians(trafo.at[column,'lon'])\n",
    "                    temp=math.cos(Blat)*math.sin(Blon-Alon)\n",
    "                    temp2=math.cos(Alat)*math.sin(Blat)-math.sin(Alat)*math.cos(Blat)*math.cos(Blon-Alon)\n",
    "                    stat_heading[row,column]=np.abs(math.degrees(math.atan(temp/temp2)))\n",
    "                    temp3=math.sin((Blat-Alat)/2.)**2+math.cos(Alat)*math.cos(Blat)*math.sin((Blon-Alon)/2.)**2\n",
    "                    stat_length[row,column]=6371000*2*math.atan(np.sqrt(temp3)/np.sqrt(1-temp3))\n",
    "                    stat_heading[column,row]=stat_heading[row,column]\n",
    "                    stat_length[column,row]=stat_length[row,column]\n",
    "                    del temp, temp2, temp3, Alat, Alon, Blat, Blon\n",
    "        del line, item, row, column, value, counter\n",
    "        ######### get necessary arrays ########\n",
    "        for item in range(len(trafo)):\n",
    "            station_lat[item]=trafo.at[item,'lat']\n",
    "            station_lon[item]=trafo.at[item,'lon']\n",
    "            ground_cond[item]=trafo.at[item,'conductivity total']\n",
    "\n",
    "        ############################### Run the function with multiple processors ##########################################\n",
    "        logging.info('Start multiprocessing!')\n",
    "        print(\"New data is added now!\")\n",
    "        n=6\n",
    "        nrsteps=int(self.samples*self.days/n)\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.GICfunction, args=(index+1,nrsteps*index,nrsteps*(index+1),trafo,EX_matrix,EY_matrix,lat,lon,station_lat,station_lon,trafo_connect,stat_heading,stat_length,trafo_cond,ground_cond,kabels,trafo_all_connections,guess,localvar,lock,plotting))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        logging.info(\"Script has been completed!\")\n",
    "        print(\"Script has been completed!\")\n",
    "        logging.shutdown()\n",
    "        \n",
    "    def calcE(self,kabels,EX_matrix,EY_matrix,lat,lon,time,guess,localvar): #E for all cables\n",
    "        from scipy.interpolate import griddata\n",
    "        from scipy.integrate import simps\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import logging\n",
    "                         \n",
    "        localvar.heading=np.zeros(len(kabels))\n",
    "        localvar.old=np.zeros((len(kabels),2))\n",
    "        nr=guess # amount of nodes\n",
    "        while True:\n",
    "            localvar.E_all=np.zeros((len(kabels),2))\n",
    "            localvar.latrange=np.zeros((len(kabels),nr))\n",
    "            localvar.lonrange=np.zeros((len(kabels),nr))\n",
    "            localvar.GridEX=np.zeros((len(kabels),nr))\n",
    "            localvar.GridEY=np.zeros((len(kabels),nr))\n",
    "\n",
    "            for number in range(len(kabels)):\n",
    "                localvar.latrange[number,:]=np.linspace(kabels.at[number,'strtlat'],kabels.at[number,'eindlat'],nr) \n",
    "                localvar.lonrange[number,:]=np.linspace(kabels.at[number,'strtlon'],kabels.at[number,'eindlon'],nr) \n",
    "                localvar.heading[number]=kabels.at[number,'heading']\n",
    "            localvar.GridEX=griddata((lat,lon),EX_matrix[time,:],(localvar.latrange,localvar.lonrange),method='cubic') #interpolate value\n",
    "            localvar.GridEY=griddata((lat,lon),EY_matrix[time,:],(localvar.latrange,localvar.lonrange),method='cubic')\n",
    "            for number in range(len(kabels)):\n",
    "                localvar.E_all[number,0]+=abs(np.cos(np.radians(localvar.heading[number])))*simps(localvar.GridEX[number,:],np.linspace(0,kabels.at[number,'length'],nr))\n",
    "                localvar.E_all[number,1]+=abs(np.sin(np.radians(localvar.heading[number])))*simps(localvar.GridEY[number,:],np.linspace(0,kabels.at[number,'length'],nr))\n",
    "\n",
    "            if np.sum(abs(localvar.old-localvar.E_all))<10**-5:\n",
    "                logging.info(f'{nr-(guess-1)} iterations were used for time={time}')\n",
    "                break\n",
    "            else:\n",
    "                localvar.old[:,0]=localvar.E_all[:,0]\n",
    "                localvar.old[:,1]=localvar.E_all[:,1]\n",
    "                nr+=1\n",
    "        return localvar.E_all\n",
    "    \n",
    "    def check_sampling(self):\n",
    "        import os\n",
    "        self.samples=len([name for name in os.listdir(f'{self.respath}/{self.date}/interpolation') if os.path.isfile(os.path.join(f'{self.respath}/{self.date}/interpolation', name))])/2\n",
    "        if self.samples%(24*60*60)==0:\n",
    "            self.minute=False \n",
    "            self.days=int(self.samples/(24*60*60))\n",
    "            self.samples=24*60*60\n",
    "        elif self.samples%(24*60)==0:\n",
    "            self.minute=True\n",
    "            self.days=int(self.samples/(24*60))\n",
    "            self.samples=24*60\n",
    "        else:\n",
    "            raise Exception(\"Data is missing, or it is no minute or second data\")\n",
    "    \n",
    "    def download_data(self,day,month,year,station,types=True):\n",
    "        from urllib.request import urlretrieve\n",
    "        import os\n",
    "        import logging\n",
    "        day=str(day).zfill(2)\n",
    "        month=str(month).zfill(2)\n",
    "        logging.info(f'Downloading data for station {station} on {day}-{month}-{year}')\n",
    "        if types==True: #minute data\n",
    "            URL=\"ftp://ftp.seismo.nrcan.gc.ca/intermagnet/minute/definitive/IAGA2002\"\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/{year}/{month}/{station}{year}{month}{day}dmin.min.gz', f'{self.base}/{day}-{month}-{year}/{station}{year}{month}{day}dmin.min.gz')\n",
    "            except:\n",
    "                raise Exception('Data does not exist for given input, station might not be recorded yet. Input should have length: 3-2-2-4')\n",
    "            os.system(f'gunzip {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}dmin.min.gz')\n",
    "            os.system(f'rm {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}dmin.min.gz')\n",
    "            \n",
    "        else: #second data\n",
    "            URL=\"ftp://ftp.seismo.nrcan.gc.ca/intermagnet/second/quasi-definitive/IAGA2002\"\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/{year}/{month}/{station}{year}{month}{day}qsec.sec.gz', f'{self.base}/{day}-{month}-{year}/{station}{year}{month}{day}qsec.sec.gz')\n",
    "            except:\n",
    "                raise Exception('Data does not exist for given input, station might not be recorded yet. Input should have length: 3-2-2-4')\n",
    "            os.system(f'gunzip {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}qsec.sec.gz') \n",
    "            os.system(f'rm {self.base}/{day}-{month}-{year}/{station}{year}{month}{day}qsec.sec.gz') \n",
    "\n",
    "    def filt(self,x,ft_matrix): #create Wiener filter to remove noise from magnetic signal\n",
    "        from scipy.optimize import curve_fit\n",
    "        import numpy as np\n",
    "        signal=np.zeros((len(ft_matrix),len(ft_matrix[0])), dtype='complex')\n",
    "        n=len(x)\n",
    "        \n",
    "        PSD=2*np.sum(abs(ft_matrix), axis=1)/len(ft_matrix) #create mean power spectrum density\n",
    "        a,sigma=curve_fit(self.func, x[2*int(n/3):], 2*np.sum(abs(ft_matrix[2*int(n/3):]), axis=1)/len(ft_matrix)) #fit a exp line to end graph\n",
    "        Wiener=(PSD-self.func(x,*a))/PSD #create filter\n",
    "        for i in range(len(ft_matrix[0])):\n",
    "            signal[:,i]=ft_matrix[:,i]*Wiener #apply filter\n",
    "        return signal\n",
    "            \n",
    "    def find_quiet_date(self):\n",
    "        from urllib.request import urlretrieve\n",
    "        import os\n",
    "        import logging\n",
    "        import datetime\n",
    "        URL='ftp://ftp.gfz-potsdam.de/pub/home/obs/kp-ap/quietdst'\n",
    "        monthlist=[0,2,3,4,5,6,7,9,10,11,12,13,14]\n",
    "        try: #retrieve data from the Potzdam website\n",
    "            urlretrieve(f'{URL}/qd{self.year[0:3]}0{self.year[2]}9.txt', f'{self.base}/Kp_index_{self.year}.txt')\n",
    "        except:\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/qd{self.year[0:3]}0{self.year[2]}x.txt', f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            except:\n",
    "                raise Exception('URL could not be retrieved, check your date string!')\n",
    "        # find correct files and extract quiet days of the month\n",
    "        if self.month=='12' and self.year[3]=='9':\n",
    "            newyear=str(int(self.year)+1)\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}9.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            except:\n",
    "                try:\n",
    "                    urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}x.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "                except:\n",
    "                    raise Exception('URL could not be retrieved, check your date string!')\n",
    "            f=open(f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)-1]+2:\n",
    "                    words=line.split()\n",
    "                    word=words[2]\n",
    "                    option0=[''.join(i for i in words[2] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                    option0A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)-1, self.year]\n",
    "\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                    words=line.split()\n",
    "                    word=words[2]\n",
    "                    option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                    option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                    break\n",
    "            f=open(f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==4:\n",
    "                    words=line.split()\n",
    "                    word=words[2]\n",
    "                    option2=[''.join(i for i in words[2] if i.isdigit()), 1, int(self.year)+1]\n",
    "                    option2A=[''.join(i for i in words[3] if i.isdigit()), 1, int(self.year)+1]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{newyear}.txt')\n",
    "                    break\n",
    "            \n",
    "        elif self.month=='01' and self.year[3]=='0':\n",
    "            newyear=str(int(self.year)-1)\n",
    "            try:\n",
    "                urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}9.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            except:\n",
    "                try:\n",
    "                    urlretrieve(f'{URL}/qd{newyear[0:3]}0{newyear[2]}x.txt', f'{self.base}/Kp_index_{newyear}.txt')\n",
    "                except:\n",
    "                    raise Exception('URL could not be retrieved, check your date string!')\n",
    "            f=open(f'{self.base}/Kp_index_{newyear}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==130:\n",
    "                    words=line.split()\n",
    "                    word=words[2]\n",
    "                    option0=[''.join(i for i in words[2] if i.isdigit()), 12, int(self.year)-1]\n",
    "                    option0A=[''.join(i for i in words[3] if i.isdigit()), 12, int(self.year)-1]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{newyear}.txt')\n",
    "                    break\n",
    "            f=open(f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                    words=line.split()\n",
    "                    word=words[2]\n",
    "                    option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                    option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "\n",
    "                if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)+1]+2:\n",
    "                    words=line.split()\n",
    "                    word=words[2]\n",
    "                    option2=[''.join(i for i in words[2] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                    option2A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                    f.close()\n",
    "                    os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                    break\n",
    "        \n",
    "        else:\n",
    "            f=open(f'{self.base}/Kp_index_{self.year}.txt')\n",
    "            for counter,line in enumerate(f):\n",
    "                if self.month=='12':\n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)-1]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option0=[''.join(i for i in words[2] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                        option0A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                        option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                        \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10+1)*14+4:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option2=[''.join(i for i in words[2] if i.isdigit()), 1, int(self.year)+1]\n",
    "                        option2A=[''.join(i for i in words[3] if i.isdigit()), 1, int(self.year)+1]\n",
    "                        f.close()\n",
    "                        os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                        break\n",
    "                elif self.month=='1':\n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option0=[''.join(i for i in words[2] if i.isdigit()), 12, int(self.year)-1]\n",
    "                        option0A=[''.join(i for i in words[3] if i.isdigit()), 12, int(self.year)-1]\n",
    "                \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                        option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                        \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)+1]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option2=[''.join(i for i in words[2] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        option2A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        f.close()\n",
    "                        os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                        break\n",
    "                else:\n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)-1]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option0=[''.join(i for i in words[2] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                        option0A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)-1, self.year]\n",
    "                \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option1=[''.join(i for i in words[2] if i.isdigit()), self.month, self.year]\n",
    "                        option1A=[''.join(i for i in words[3] if i.isdigit()), self.month, self.year]\n",
    "                        \n",
    "                    if counter==(int(self.year)-int(self.year[0:3])*10)*14+monthlist[int(self.month)+1]+2:\n",
    "                        words=line.split()\n",
    "                        word=words[2]\n",
    "                        option2=[''.join(i for i in words[2] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        option2A=[''.join(i for i in words[3] if i.isdigit()), int(self.month)+1, self.year]\n",
    "                        f.close()\n",
    "                        os.system(f'rm {self.base}/Kp_index_{self.year}.txt')\n",
    "                        break\n",
    "                        \n",
    "        #which option is closest to disturbed day?\n",
    "        logging.info(f\"optional quiet days are (previous/this/next month): {option0} OR {option0A} / {option1} OR {option1A} / {option2} OR {option2A}\")\n",
    "        datestring=[datetime.datetime(int(option0[2]),int(option0[1]),int(option0[0])),datetime.datetime(int(option1[2]),int(option1[1]),int(option1[0])),datetime.datetime(int(option2[2]),int(option2[1]),int(option2[0])),datetime.datetime(int(option0A[2]),int(option0A[1]),int(option0A[0])),datetime.datetime(int(option1A[2]),int(option1A[1]),int(option1A[0])),datetime.datetime(int(option2A[2]),int(option2A[1]),int(option2A[0]))]\n",
    "        Quiet=min(datestring, key=lambda x: abs(x - datetime.datetime(int(self.year),int(self.month),int(self.day))))\n",
    "        return Quiet.day, Quiet.month, Quiet.year\n",
    "        \n",
    "    def func(self,x,a,b):\n",
    "        return b*10 ** (a*x)\n",
    "    \n",
    "    def GICfunction(self,q,begin,end,trafo,EX_matrix,EY_matrix,lat,lon,station_lat,station_lon,trafo_connect,stat_heading,stat_length,trafo_cond,ground_cond,kabels,trafo_all_connections,guess,localvar,lock,plotting):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import os\n",
    "        import logging\n",
    "    ######################################### interpolation ############################################################\n",
    "        localvar.volt_result=np.zeros(len(trafo))\n",
    "        localvar.J_total=np.zeros(len(trafo))\n",
    "        logging.info(f'Thread {q} has started interpolation!')\n",
    "        for localvar.time in range(begin,end):#range(len(grid_EX)):\n",
    "            localvar.J_north, localvar.J_east=self.ObtainJ(q,kabels,EX_matrix,EY_matrix,lat,lon,localvar.time,trafo_connect,trafo_all_connections,trafo_cond,trafo,guess,localvar)\n",
    "            localvar.J_total=localvar.J_north+localvar.J_east\n",
    "            localvar.volt_result=np.linalg.solve(trafo_cond,localvar.J_total)\n",
    "            localvar.I_GIC=localvar.volt_result*ground_cond\n",
    "\n",
    "    ##################################### getting max I_GIC and writing results ########################################\n",
    "            logging.info(f'Thread {q} is writing results to files for timestep {localvar.time}!')\n",
    "            localvar.maxAMP=1 #1\n",
    "            if self.minute:\n",
    "                localvar.tijd=str(localvar.time).zfill(4)\n",
    "            else:\n",
    "                localvar.tijd=str(localvar.time).zfill(5)\n",
    "#             if localvar.time<10:\n",
    "#                 localvar.tijd=f'000{localvar.time}'\n",
    "#             elif localvar.time<100 and localvar.time>9:\n",
    "#                 localvar.tijd=f'00{localvar.time}'\n",
    "#             elif localvar.time<1000 and localvar.time>99:\n",
    "#                 localvar.tijd=f'0{localvar.time}'\n",
    "#             else:\n",
    "#                 localvar.tijd=f'{localvar.time}'\n",
    "\n",
    "            ##### Save files #######\n",
    "            localvar.GIC=pd.DataFrame(columns=['lon','lat','GIC',f'GIC/{localvar.maxAMP}'])\n",
    "            GICmatrix=pd.DataFrame()\n",
    "            localvar.GIC.at[:,'lon']=station_lon\n",
    "            localvar.GIC.at[:,'lat']=station_lat\n",
    "            localvar.GIC.at[:,'GIC']=localvar.I_GIC\n",
    "            localvar.GIC.at[:,f'GIC/{localvar.maxAMP}']=localvar.I_GIC/localvar.maxAMP\n",
    "            localvar.GIC.to_csv(path_or_buf=f'{self.respath}/{self.date}/GIC/GIC_{localvar.tijd}.csv', sep=';', index=False, header=True)\n",
    "            logging.info(f'Thread {q} has written, now plotting GIC!')\n",
    "    ################################### Plotting results ###############################################################\n",
    "            if plotting==True:\n",
    "                lim1=3.3\n",
    "                lim2=7.5\n",
    "                lim3=50.5\n",
    "                lim4=54\n",
    "                legendlon=lim1+0.18\n",
    "                legendlat=lim4-0.1\n",
    "                textlon=legendlon+0.40 #0.33\n",
    "                textlat=legendlat-0.01\n",
    "\n",
    "                with lock:\n",
    "                    legend=open(f'{self.netpath}/legend.txt','w+')\n",
    "                    legend.write(f'{legendlon} {legendlat} 1 1')\n",
    "                    legend.close()\n",
    "                    legendtxt=open(f'{self.netpath}/legendtext.txt', 'w+')\n",
    "                    legendtxt.write(f'{textlon} {textlat} {localvar.maxAMP}A')\n",
    "                    legendtxt.close()\n",
    "\n",
    "                    ##### Use GMT to plot GICs ######\n",
    "                    if self.minute:\n",
    "                        minute=str(localvar.time%60).zfill(2)\n",
    "                        hour=str(int(localvar.time/60)%24).zfill(2)\n",
    "                        DAY=int(localvar.time/(60*24))\n",
    "#                         if minute < 10:\n",
    "#                             minute=f'0{minute}'\n",
    "#                         if hour < 10:\n",
    "#                             hour=f'0{hour}'\n",
    "                        title=f'GIC at {self.date} - {DAY}:{hour}:{minute}'\n",
    "                        proj='-JM15C -P'\n",
    "                        lims=f'-R{lim1}/{lim2}/{lim3}/{lim4}'\n",
    "                        psfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.ps' #aanpassen\n",
    "                        pngfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.png' #aanpassen\n",
    "                        os.system(f'gmt pscoast {proj} {lims} -W0.5p -K -Ggrey -Slightblue -Df -N1/0.25p> {psfile}' )\n",
    "                        os.system(f'gmt psbasemap {proj} {lims} -Ba1g1 -BWeSn+t\"{title}\" -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.netpath}/cables.csv {proj} {lims} -W0.5p -Wred -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.respath}/{self.date}/GIC/GIC_{localvar.tijd}.csv {proj} {lims} -Ctopo.cpt -Scc -O -K>> {psfile}')    \n",
    "                        os.system(f'gmt psxy {self.netpath}/legend.txt {proj} {lims} -Ctopo.cpt -W -Scc -O -K>> {psfile}')\n",
    "                        os.system(f'gmt pstext {self.netpath}/legendtext.txt {proj} {lims} -F+f30pHelvetica,black -O>> {psfile}')\n",
    "                    else:\n",
    "                        second=str(localvar.time%60).zfill(2)\n",
    "                        minute=str(int(localvar.time/60)%60).zfill(2)\n",
    "                        hour=str(int(localvar.time/(60*60))%24).zfill(2)\n",
    "                        DAY=int(localvar.time/(60*60*24))\n",
    "#                         if second < 10:\n",
    "#                             second=f'0{second}'     \n",
    "#                         if minute < 10:\n",
    "#                             minute=f'0{minute}'\n",
    "#                         if hour < 10:\n",
    "#                             hour=f'0{hour}'\n",
    "\n",
    "                        title=f'GIC at {self.date} - {DAY}:{hour}:{minute}:{second}'\n",
    "                        proj='-JM15C -P'\n",
    "                        lims=f'-R{lim1}/{lim2}/{lim3}/{lim4}'\n",
    "                        psfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.ps' #aanpassen\n",
    "                        pngfile=f'{self.respath}/{self.date}/GIC/GIC_at_{localvar.tijd}.png' #aanpassen\n",
    "                        os.system(f'gmt pscoast {proj} {lims} -W0.5p -K -Ggrey -Slightblue -Df -N1/0.25p> {psfile}' )\n",
    "                        os.system(f'gmt psbasemap {proj} {lims} -Ba1g1 -BWeSn+t\"{title}\" -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.netpath}/cables.csv {proj} {lims} -W0.5p -Wred -O -K>> {psfile}' )\n",
    "                        os.system(f'gmt psxy {self.respath}/{self.date}/GIC/GIC_{localvar.tijd}.csv {proj} {lims} -Ctopo.cpt -Scc -O -K>> {psfile}')    \n",
    "                        os.system(f'gmt psxy {self.netpath}/legend.txt {proj} {lims} -Ctopo.cpt -W -Scc -O -K>> {psfile}')\n",
    "                        os.system(f'gmt pstext {self.netpath}/legendtext.txt {proj} {lims} -F+f30pHelvetica,black -O>> {psfile}')\n",
    "                os.system(f'convert -density 300 {psfile} {pngfile}')\n",
    "                os.system(f'rm {psfile}')\n",
    "\n",
    "            logging.info(f'Thread {q} has fulfilled timestep {localvar.time}!')\n",
    "        logging.info(f'Thread {q} is finished!')\n",
    "    \n",
    "    def GIC_index(self,overwrite=False):\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.check_sampling()\n",
    "        if overwrite:\n",
    "            g=open(f'{self.respath}/{self.date}/GIC_index.txt','w+')\n",
    "        else:\n",
    "            g=open(f'{self.respath}/{self.date}/GIC_index.txt','a+')\n",
    "        maxx=0\n",
    "        maxy=0\n",
    "        GIC=pd.DataFrame(columns=['lon','lat','GICx','GICy'])\n",
    "        Xcomp=np.zeros(self.samples*self.days)\n",
    "        XParz=np.zeros(self.samples*3*self.days)\n",
    "        GICxft=np.zeros((int(self.samples/2*3*self.days)+1), dtype='complex')\n",
    "        GICx=np.zeros(self.samples*3*self.days)\n",
    "        Ycomp=np.zeros(self.samples*self.days)\n",
    "        YParz=np.zeros(self.samples*3*self.days)\n",
    "        GICyft=np.zeros((int(self.samples/2*3*self.days)+1), dtype='complex')\n",
    "        GICy=np.zeros(self.samples*3*self.days)\n",
    "        df=1/(60*60*24*3.*self.days) # *3 for Parzen window\n",
    "        if self.minute:\n",
    "            fmax=1/(2*60.)\n",
    "        else:\n",
    "            fmax=1/(2*1)\n",
    "        freqvector=np.arange(0,fmax+df,df) #create frequency vector\n",
    "        timevector=np.linspace(0,24*self.days,self.samples*self.days)\n",
    "\n",
    "        figx=plt.figure(figsize=(15,10)) #initialize plotting GICx\n",
    "        axx=figx.add_subplot()\n",
    "        axx.set_title('GICx index')\n",
    "        axx.set_ylabel('GICx')\n",
    "        axx.set_xlabel('Time (h)')\n",
    "        axx.axhline(16, linestyle='--', color='green')#, label='5%')\n",
    "        axx.axhline(43, linestyle='--', color='yellow')#, label='35%')\n",
    "        axx.axhline(114, linestyle='--', color='orange')#, label='65%')\n",
    "        axx.axhline(304, linestyle='--', color='red')#, label='95%')\n",
    "        figy=plt.figure(figsize=(15,10)) #initialize plotting GICy\n",
    "        axy=figy.add_subplot()\n",
    "        axy.set_title('GICy index')\n",
    "        axy.set_ylabel('GICy')\n",
    "        axy.set_xlabel('Time (h)')\n",
    "        axy.axhline(39, linestyle='--', color='green')#, label='5%')\n",
    "        axy.axhline(97, linestyle='--', color='yellow')#, label='35%')\n",
    "        axy.axhline(241, linestyle='--', color='orange')#, label='65%')\n",
    "        axy.axhline(600, linestyle='--', color='red')#, label='95%')\n",
    "#         axx.legend(loc='upper right')\n",
    "#         axy.legend(loc='upper right')\n",
    "        \n",
    "        os.system(f'ls -d {self.respath}/{self.date}/*/ > {self.respath}/{self.date}/temp.txt') #get location\n",
    "        f=open(f'{self.respath}/{self.date}/temp.txt')\n",
    "        string=[]\n",
    "        for item in f:\n",
    "            item=item.strip(\"\\n\")\n",
    "            string.append(item)\n",
    "        string=sorted(string)\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "        os.system(f'ls {self.statpath} > {self.respath}/{self.date}/temp.txt') #get coordinates\n",
    "        f=open(f'{self.respath}/{self.date}/temp.txt')\n",
    "        string2=[]\n",
    "        for item in f:\n",
    "            item=item.strip(\"\\n\")\n",
    "            string2.append(item)\n",
    "        string2=sorted(string2)\n",
    "        lat=np.zeros(len(string2))\n",
    "        lon=np.zeros(len(string2))\n",
    "        stat=[]\n",
    "        for counter2,item in enumerate(string2):\n",
    "            File=open(f'{self.statpath}/{item}')\n",
    "            for counter,line in enumerate(File):\n",
    "                if counter==2:\n",
    "                    words=line.split()\n",
    "                    stat.append(words[2])\n",
    "                if counter==4:\n",
    "                    words=line.split()\n",
    "                    lat[counter2]=float(words[2]) # latitude station\n",
    "                if counter==5:\n",
    "                    words=line.split()\n",
    "                    lon[counter2]=float(words[2]) # longitude station\n",
    "                    break\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "        for counter3,station in enumerate(string):\n",
    "            if self.days==1:\n",
    "                newfile=pd.read_csv(f'{station}/allresults.csv', delimiter=';')\n",
    "            else:\n",
    "                newfile=pd.read_csv(f'{station}/merged_allresults.csv', delimiter=';')\n",
    "            Xcomp=newfile['B_theta (nt)'].to_numpy()\n",
    "            Ycomp=newfile['B_phi (nt)'].to_numpy()\n",
    "            XParz[:self.samples*self.days]=Xcomp[0] #make Parzen vector\n",
    "            XParz[self.samples*self.days:self.samples*2*self.days]=Xcomp\n",
    "            XParz[self.samples*2*self.days:]=Xcomp[-1]\n",
    "            YParz[:self.samples*self.days]=Ycomp[0]\n",
    "            YParz[self.samples*self.days:self.samples*2*self.days]=Ycomp\n",
    "            YParz[self.samples*2*self.days:]=Ycomp[-1]\n",
    "            Xft=np.fft.rfft(XParz*self.Parzen(self.samples*3*self.days)) #fourier transform into frequency domain\n",
    "            Yft=np.fft.rfft(YParz*self.Parzen(self.samples*3*self.days))\n",
    "\n",
    "            for counter,freq in enumerate(freqvector):\n",
    "                GICxft[counter]=Yft[counter]*np.exp(1j*np.pi/4.)*np.sqrt(freq/fmax)\n",
    "                GICyft[counter]=Xft[counter]*np.exp(1j*np.pi/4.)*np.sqrt(freq/fmax)\n",
    "            GICx=np.fft.irfft(GICxft)\n",
    "            GICy=np.fft.irfft(GICyft)\n",
    "\n",
    "            g.write(f\"{lon[counter3]} {lat[counter3]} {max(GICx[self.samples*self.days:self.samples*2*self.days])} {max(GICy[self.samples*self.days:self.samples*2*self.days])} {stat[counter3]}\\n\")\n",
    "            axx.plot(timevector,GICx[self.samples*self.days:self.samples*2*self.days],label=f'{stat[counter3]}')\n",
    "            axy.plot(timevector,GICy[self.samples*self.days:self.samples*2*self.days],label=f'{stat[counter3]}')\n",
    "            if max(GICx)>maxx:\n",
    "                maxx=max(GICx)\n",
    "            if max(GICy)>maxy:\n",
    "                maxy=max(GICy)\n",
    "                \n",
    "        g.close()\n",
    "        axx.legend()\n",
    "        axy.legend()\n",
    "        axx.set_ylim(0,maxx+10)\n",
    "        axy.set_ylim(0,maxy+10)\n",
    "        figx.savefig(f'{self.respath}/{self.date}/GICx_index.png')\n",
    "        figy.savefig(f'{self.respath}/{self.date}/GICy_index.png')\n",
    "        \n",
    "    def glue_data(self,paths,foldername):#days\n",
    "        import os #BE SURE TO PLACE THEM (Magnetic interpolation) IN CORRECT ORDER! SO E.G.: [29-10-2003, 30-10-2003, 31-10-2003]\n",
    "        import logging\n",
    "        logging.warning(f'Look Out! self.date is now changed from {self.date} to {foldername}!')\n",
    "        self.date=foldername\n",
    "        for path in paths:\n",
    "            if self.samples==None:\n",
    "                self.samples=len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])/2 #both x and y files\n",
    "                if self.samples==24*60:\n",
    "                    self.minute=True\n",
    "                elif self.samples==24*60*60:\n",
    "                    self.minute=False\n",
    "                else:\n",
    "                    raise Exception(\"Folders do not contain minute or second data, or data is missing!\")\n",
    "            elif self.samples!=None and self.samples!=len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])/2:\n",
    "                raise Exception(\"Folders contain different amount of files!\")\n",
    "            else:\n",
    "                pass\n",
    "        test=str(self.samples*len(paths))\n",
    "        fill=len(test)\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{foldername}')\n",
    "        except:\n",
    "            logging.warning(f'Directory \"{self.respath}/{foldername}\" is already created, data could be lost forever!')\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{foldername}/interpolation')\n",
    "        except:\n",
    "            logging.warning(f'Directory \"{self.respath}/{foldername}/interpolation\" is already created, data could be lost forever!')\n",
    "        \n",
    "        if self.minute:\n",
    "            for counter,item in enumerate(paths):\n",
    "                for nr in range(int(self.samples)):\n",
    "                    os.system(f'cp {item}/minute_{str(nr).zfill(4)}.csv {self.respath}/{foldername}/interpolation/minute_{str(nr+counter*self.samples).zfill(fill)}.csv')\n",
    "                    os.system(f'cp {item}/minute_{str(nr).zfill(4)}.csv.Y {self.respath}/{foldername}/interpolation/minute_{str(nr+counter*self.samples).zfill(fill)}.csv.Y')\n",
    "        else:\n",
    "            for counter,item in enumerate(paths):\n",
    "                for nr in range(int(self.samples)):\n",
    "                    os.system(f'cp {item}/second_{str(nr).zfill(5)}.csv {self.respath}/{foldername}/interpolation/second_{str(nr+counter*self.samples).zfill(fill)}.csv')\n",
    "                    os.system(f'cp {item}/second_{str(nr).zfill(5)}.csv.Y {self.respath}/{foldername}/interpolation/second_{str(nr+counter*self.samples).zfill(fill)}.csv.Y')\n",
    "        logging.info('Data copying is finished!')\n",
    "                    \n",
    "    def glue_video(self,nameout,gluefile=None,videos=None):\n",
    "        import os\n",
    "        if gluefile==None:\n",
    "            f=open('gluefile.txt', 'w+')\n",
    "            for item in videos:\n",
    "                f.write(f\"file '{item}' \\n\")\n",
    "            f.close()\n",
    "            os.system(f'ffmpeg -f concat -safe 0 -i gluefile.txt -c copy {self.respath}/{nameout}.mp4')\n",
    "            os.system('rm gluefile.txt')\n",
    "        else:\n",
    "            os.system(f'ffmpeg -f concat -safe 0 -i {gluefile} -c copy {self.respath}/{nameout}.mp4')\n",
    "        # gluefile should have lines like: file '/usr/people/out/Documents/Magnetic_field/station_results/31-10-2003/GIC.mp4'\n",
    "        \n",
    "    def iteratestation(self,figures=False,plots=True):\n",
    "        import os\n",
    "        string=os.listdir(self.statpath)\n",
    "        string=sorted(string)\n",
    "        stringquiet=os.listdir(self.quietpath)\n",
    "        stringquiet=sorted(stringquiet)\n",
    "        if len(string)!=len(stringquiet):\n",
    "            raise Exception(f'Quiet and active days should have the same stations, now there are {len(stringquiet)} quiet stations and {len(string)} active stations!')\n",
    "        for counter,item in enumerate(string):\n",
    "            self.newplotspace(string[counter],stringquiet[counter],figures=False,plots=True)\n",
    "     \n",
    "    def magnetic_interpolation(self): #interpolate magnetic field\n",
    "        import re\n",
    "        import logging\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import threading\n",
    "        from multiprocessing import Process\n",
    "        from multiprocessing import Lock  \n",
    "        localvar=threading.local()\n",
    "        lock=Lock()\n",
    "        RE=6371000\n",
    "        \n",
    "        string=os.listdir(self.statpath)\n",
    "        string=sorted(string) #sort alphabetically, otherwise problems later\n",
    "        logging.debug(f'Used stations are: {string} \\n')\n",
    "        location=np.zeros((len(string),3))\n",
    "        location[:,2]=RE\n",
    "        for counter1,item in enumerate(string):\n",
    "            File=open(f'{self.statpath}/{item}','r')\n",
    "            for counter2,line in enumerate(File):\n",
    "                words=line.split()\n",
    "                if counter2==4:\n",
    "                    word=line.split()\n",
    "                    location[counter1,0]=word[2] #latitude\n",
    "                if counter2==5:\n",
    "                    word=line.split()\n",
    "                    location[counter1,1]=word[2] #longitude           \n",
    "                if words[0]=='DATE':\n",
    "                    datastart=counter2\n",
    "                    \n",
    "            File.close()\n",
    "            self.samples=counter2-datastart\n",
    "        string=[]\n",
    "        os.system(f' ls -d {self.respath}/{self.date}/*{self.datevar} > {self.respath}/{self.date}/temp.txt') \n",
    "        f=open(f'{self.respath}/{self.date}/temp.txt')\n",
    "        for item in f:\n",
    "            item=item.strip('\\n')\n",
    "            string.append(item)\n",
    "        string=sorted(string) #sort alphabetically, otherwise problems now\n",
    "        f.close()\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "        print(string)\n",
    "        \n",
    "        values=np.zeros((len(string),3))\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/interpolation')\n",
    "        except:\n",
    "            print('Directory is already created, data could be overwritten.')\n",
    "            logging.info('Directory is already created, data could be overwritten.')\n",
    "\n",
    "        n=3 #no more than 3 processors at a time for 16GB memory\n",
    "        nrsteps=int(self.samples/n)\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.magnetic_time, args=(index+1, nrsteps*index, nrsteps*(index+1),location,string,localvar))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        \n",
    "    def magnetic_time(self,q,stepmin,stepmax,location,string,localvar):\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import logging\n",
    "        \n",
    "        logging.info(f'Thread {q} is running, starting at {stepmin}.')\n",
    "        for counter3 in range(stepmin,stepmax): #minutes per day\n",
    "            localvar.values=np.zeros((len(string),3))\n",
    "    #         with lock:\n",
    "            logging.info(f'Thread {q} got a lock')\n",
    "            for localvar.counter1,localvar.item in enumerate(string):\n",
    "                localvar.File=open(f'{localvar.item}/allresults.csv')\n",
    "                for localvar.counter2,localvar.line in enumerate(localvar.File):\n",
    "                    if localvar.counter2==(counter3+1):\n",
    "                        localvar.word=localvar.line.split(';')\n",
    "                        localvar.values[localvar.counter1,:]=[localvar.word[0],localvar.word[1],localvar.word[2]]\n",
    "                        break\n",
    "                localvar.File.close()\n",
    "\n",
    "            localvar.result=self.mag_interpolate(location,localvar.values,np.array([43,63,-13,20]),0.5)\n",
    "            logging.info(f'Thread {q} released lock and finished interpolating for step {counter3}.')\n",
    "            \n",
    "            localvar.newfile1=pd.DataFrame(columns=['lon','lat','Bx'])\n",
    "            localvar.newfile2=pd.DataFrame(columns=['lon','lat','By'])\n",
    "\n",
    "            logging.info(f'Thread {q} is busy writing to file.')\n",
    "            localvar.newfile1['lon']=localvar.result[:,1]\n",
    "            localvar.newfile1['lat']=localvar.result[:,0]\n",
    "            localvar.newfile1['Bx']=localvar.result[:,2]\n",
    "            localvar.newfile2['lon']=localvar.result[:,1]\n",
    "            localvar.newfile2['lat']=localvar.result[:,0]\n",
    "            localvar.newfile2['By']=localvar.result[:,3]\n",
    " \n",
    "            logging.info(f'Thread {q} is searching.')\n",
    "            if self.minute==True:\n",
    "                localvar.newfile1.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(4)}.csv', sep=' ', index=False, header=False)\n",
    "                localvar.newfile2.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(4)}.csv.Y', sep=' ', index=False, header=False)\n",
    "            else:\n",
    "                localvar.newfile1.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(5)}.csv', sep=' ', index=False, header=False)\n",
    "                localvar.newfile2.to_csv(path_or_buf=f'{self.respath}/{self.date}/interpolation/minute_{str(counter3).zfill(5)}.csv.Y', sep=' ', index=False, header=False)\n",
    "        \n",
    "            logging.info(f'Thread {q} has found.')\n",
    "        logging.warning(f'Thread {q} has finished.')\n",
    "            \n",
    "    def mag_interpolate(self,loc,val,latlon,delta):\n",
    "        import numpy as np\n",
    "        from pySECS import SECS \n",
    "        \n",
    "        if loc.shape[-1] != 3:\n",
    "            raise ValueError(\"Observation locations must have 3 columns (lat, lon, r)\")\n",
    "        if val.shape[-1] != 3:\n",
    "            raise ValueError(\"Observed values must have 3 columns (Bx(theta), By(phi), Bz(r))\")\n",
    "        if latlon.shape[-1] != 4:\n",
    "            raise ValueError(\"Observed values must have 1 row and 4 columns (latmin, latmax, lonmin, lonmax)\")\n",
    "        RE=6371e3\n",
    "\n",
    "        latlon[1]+=delta\n",
    "        latlon[3]+=delta\n",
    "\n",
    "        lats = np.arange(latlon[0], latlon[1], delta)\n",
    "        lons = np.arange(latlon[2], latlon[3], delta)\n",
    "\n",
    "        nlat = len(lats)\n",
    "        nlon = len(lons)\n",
    "\n",
    "        xx, yy = np.meshgrid(lons, lats) #make nice mesh\n",
    "\n",
    "        sec_loc=np.zeros((nlat*nlon,3))\n",
    "        for i in range(nlat*nlon): #add poles to sec_loc\n",
    "            sec_loc[i,:]=[yy.item(i),xx.item(i),RE+110e3] #system is 110 km above ground with multiple poles\n",
    "\n",
    "        system_df = SECS(sec_df_loc=sec_loc) #initiate new divergence free system using poles (only df free, see paper)\n",
    "\n",
    "        system_df.fit(loc,val) #fit currents to values\n",
    "\n",
    "    ################## The prediction/interpolation begins ################\n",
    "        \n",
    "        predlats = np.arange(49, 54.04, 0.05) #Netherlands+Belgium&Germany\n",
    "        predlons = np.arange(3.3, 9.64, 0.05)\n",
    "        predlatseng = np.arange(51.4, 52.04, 0.05) #seacable england\n",
    "        predlonseng = np.arange(0.7, 3.29, 0.05)\n",
    "        predlatsnor = np.arange(54.05, 58.34, 0.05) #seacable norway\n",
    "        predlonsnor = np.arange(6.1, 6.94, 0.05)\n",
    "\n",
    "        nrpoint=len(predlats)*len(predlons)+len(predlatseng)*len(predlonseng)+len(predlatsnor)*len(predlonsnor)\n",
    "\n",
    "        predxx1, predyy1 = np.meshgrid(predlons, predlats) #make nice mesh\n",
    "        predxx2, predyy2 = np.meshgrid(predlonseng, predlatseng)\n",
    "        predxx3, predyy3 = np.meshgrid(predlonsnor, predlatsnor)\n",
    "        predxx=np.concatenate((predxx1.flatten(),predxx2.flatten(),predxx3.flatten()))\n",
    "        predyy=np.concatenate((predyy1.flatten(),predyy2.flatten(),predyy3.flatten()))\n",
    "\n",
    "        pred_loc=np.zeros((nrpoint,3))\n",
    "        for i in range(nrpoint): #add locations\n",
    "            pred_loc[i,:]=[predyy.item(i),predxx.item(i),RE] #system is at ground\n",
    "\n",
    "        prediction=system_df.predict(pred_loc, False)\n",
    "        result=np.zeros((nrpoint,4))\n",
    "        for i in range(nrpoint):\n",
    "            result[i,:]=[predyy.item(i),predxx.item(i),prediction[i,0],prediction[i,1]]\n",
    "        return result\n",
    "\n",
    "    def make_video(self,namein,nameout):\n",
    "        import os\n",
    "        os.system(f'ffmpeg -framerate 24 -pattern_type glob -i \"{namein}????.png\" {self.respath}/{self.date}/{nameout}.mp4')\n",
    "    \n",
    "    def newplotspace(self,activeday,quietday,figures=False,plots=True):\n",
    "        #import needed packages\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import re\n",
    "        from chaosmagpy.data_utils import mjd2000\n",
    "        possible_characters = ('-', ' ')\n",
    "    ##### calculate values from observation station #####\n",
    "        # read-in file of station\n",
    "        File=open(f'{self.quietpath}/{quietday}','r') # open file\n",
    "        HorX=[] # make some lists\n",
    "        DeclY=[]\n",
    "        VertZ=[]\n",
    "        X2=[]\n",
    "        for counter,line in enumerate(File):\n",
    "            words=line.split()\n",
    "            if words[0]=='DATE':\n",
    "                datastart=counter+2\n",
    "                for counter2,letters in enumerate(words[3]):\n",
    "                    if counter2==3:\n",
    "                        if letters=='H':\n",
    "                            types=False\n",
    "                            break\n",
    "                        if letters=='X':\n",
    "                            types=True\n",
    "                            break\n",
    "        File=open(f'{self.quietpath}/{quietday}','r')\n",
    "        counter=0\n",
    "        for counter,line in enumerate(File):\n",
    "            if counter==2:\n",
    "                words=line.split()\n",
    "                station=words[2]\n",
    "            if counter==4:\n",
    "                words=line.split()\n",
    "                lat=float(words[2]) # latitude station\n",
    "            if counter==5:\n",
    "                words=line.split()\n",
    "                lon=float(words[2]) # longitude station\n",
    "                \n",
    "            if counter>=datastart-1: #read when the data starts\n",
    "                words=line.split()\n",
    "                if counter==datastart:\n",
    "                    for newcounter,letters in enumerate(words[1]):\n",
    "                        if newcounter==4:\n",
    "                            if letters=='1' and self.samples==0:\n",
    "                                self.minute=True\n",
    "                                self.samples=24*60\n",
    "                            if letters=='0' and self.samples==0:\n",
    "                                self.minute=False\n",
    "                                self.samples=24*60*60\n",
    "                            if letters=='1' and self.samples!=0 and self.minute==False:\n",
    "                                raise Exception('Data is not of the same type (min and s)!')\n",
    "                            if letters=='0' and self.samples!=0 and self.minute==True:\n",
    "                                raise Exception('Data is not of the same type (min and s)!')\n",
    "\n",
    "                \n",
    "                if float(words[3])>90000: #then no data is saved, but previous sample or zero is stored\n",
    "                    if counter==datastart-1:\n",
    "                        HorX.append(0)\n",
    "                    else:\n",
    "                        HorX.append(HorX[-1]) # get horizontal or X-component\n",
    "                else:\n",
    "                    HorX.append(float(words[3]))\n",
    "\n",
    "                if float(words[4])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        DeclY.append(0)\n",
    "                    else:\n",
    "                        DeclY.append(DeclY[-1]) # get 'declination' or Y-component\n",
    "                else:\n",
    "                    DeclY.append(float(words[4]))\n",
    "\n",
    "                if float(words[5])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        VertZ.append(0)\n",
    "                    else:\n",
    "                        VertZ.append(VertZ[-1]) # get vertical component or Z-component\n",
    "                else:\n",
    "                    VertZ.append(float(words[5]))\n",
    "            \n",
    "        File.close()\n",
    "\n",
    "        if types: #if given in XYZ, types==true\n",
    "            X2=HorX\n",
    "            Y2=DeclY\n",
    "            Z2=VertZ\n",
    "\n",
    "        else: #if given in HDZ, types==false\n",
    "            for item in range(len(DeclY)):\n",
    "                X2.append(np.sqrt(HorX[item]**2-DeclY[item]**2)) #minus is added to immediately transform to polar coordinates\n",
    "            Y2=DeclY\n",
    "            Z2=VertZ\n",
    "\n",
    "        File=open(f'{self.statpath}/{activeday}','r') # open file\n",
    "        HorX=[] # make some lists\n",
    "        DeclY=[]\n",
    "        VertZ=[]\n",
    "        X1=[]\n",
    "        N=0\n",
    "        for counter,line in enumerate(File):\n",
    "            words=line.split()\n",
    "            if words[0]=='DATE':\n",
    "                datastart=counter+2\n",
    "                for counter2,letters in enumerate(words[3]):\n",
    "                    if counter2==3:\n",
    "                        if letters=='H':\n",
    "                            types=False\n",
    "                            break\n",
    "                        if letters=='X':\n",
    "                            types=True\n",
    "                            break\n",
    "        File=open(f'{self.statpath}/{activeday}','r')\n",
    "        counter=0\n",
    "        for counter,line in enumerate(File):\n",
    "            if counter==2:\n",
    "                words=line.split()\n",
    "                station=words[2]\n",
    "            if counter==4:\n",
    "                words=line.split()\n",
    "                lat=float(words[2]) # latitude station\n",
    "            if counter==5:\n",
    "                words=line.split()\n",
    "                lon=float(words[2]) # longitude station\n",
    "            if counter>=datastart-1: #read when the data starts\n",
    "                N+=1\n",
    "                if counter==datastart-1:\n",
    "                    dates=re.split(\"[%s]\" % (\"\".join(possible_characters)), line) # get start date\n",
    "\n",
    "                words=line.split()\n",
    "                if float(words[3])>90000: #then no data is saved, but previous sample or zero is stored\n",
    "                    if counter==datastart-1:\n",
    "                        HorX.append(0)\n",
    "                    else:\n",
    "                        HorX.append(HorX[-1]) # get horizontal or X-component\n",
    "                else:\n",
    "                    HorX.append(float(words[3]))\n",
    "\n",
    "                if float(words[4])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        DeclY.append(0)\n",
    "                    else:\n",
    "                        DeclY.append(DeclY[-1]) # get 'declination' or Y-component\n",
    "                else:\n",
    "                    DeclY.append(float(words[4]))\n",
    "\n",
    "                if float(words[5])>90000:\n",
    "                    if counter==datastart-1:\n",
    "                        VertZ.append(0)\n",
    "                    else:\n",
    "                        VertZ.append(VertZ[-1]) # get vertical component or Z-component\n",
    "                else:\n",
    "                    VertZ.append(float(words[5]))\n",
    "\n",
    "        File.close()\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}')\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            os.mkdir(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if types: #if given in XYZ, types==true\n",
    "            X1=HorX\n",
    "            Y1=DeclY\n",
    "            Z1=VertZ\n",
    "\n",
    "        else: #if given in HDZ, types==false\n",
    "            for item in range(len(DeclY)):\n",
    "                X1.append(np.sqrt(HorX[item]**2-DeclY[item]**2)) #minus is added to immediately transform to polar coordinates\n",
    "            Y1=DeclY\n",
    "            Z1=VertZ\n",
    "    ##### calculate model value of magnetic field #####\n",
    "        # set up\n",
    "        if int(dates[2])==31:\n",
    "            if int(dates[1])==12:\n",
    "                time = np.linspace(mjd2000(int(dates[0]),int(dates[1]),int(dates[2])), \n",
    "                                   mjd2000(int(dates[0])+1,1,1), num=N)\n",
    "            else:\n",
    "                time = np.linspace(mjd2000(int(dates[0]),int(dates[1]),int(dates[2])), \n",
    "                                   mjd2000(int(dates[0]),int(dates[1])+1,1), num=N)\n",
    "        else:\n",
    "            time = np.linspace(mjd2000(int(dates[0]),int(dates[1]),int(dates[2])),\n",
    "                               mjd2000(int(dates[0]),int(dates[1]),int(dates[2])+1), num=N)\n",
    "\n",
    "    ##### subtract the two data sets! #####\n",
    "        SpaceX=np.subtract(X1,X2)\n",
    "        SpaceY=np.subtract(Y1,Y2)\n",
    "        SpaceZ=np.subtract(Z1,Z2)\n",
    "\n",
    "    ##### plot data #####\n",
    "        if figures:\n",
    "            figx=plt.figure(figsize=(20,10))\n",
    "            ax1=figx.add_subplot(311)\n",
    "            ax11=figx.add_subplot(312)\n",
    "            ax12=figx.add_subplot(313)\n",
    "            ax1.set_title('$B_\\\\theta$ at '+ station + ' on ' + dates[0] + '-' + dates[1] + '-' + dates[2])\n",
    "            ax12.set_xlabel('time (days after 1 jan 2000)')\n",
    "            ax11.set_ylabel('$B_\\\\theta$ (nt)')\n",
    "            ax11.plot(time,X1,label='observed',color='blue')\n",
    "            ax12.plot(time,X2,label='model',color='green')\n",
    "            ax1.plot(time,SpaceX,label='residue',color='red')\n",
    "            ax1.legend()\n",
    "            ax11.legend()\n",
    "            ax12.legend()\n",
    "\n",
    "            figy=plt.figure(figsize=(20,10))\n",
    "            ax2=figy.add_subplot(311)\n",
    "            ax21=figy.add_subplot(312)\n",
    "            ax22=figy.add_subplot(313)\n",
    "            ax2.set_title('$B_\\\\phi$ at '+ station + ' on ' + dates[0] + '-' + dates[1] + '-' + dates[2])\n",
    "            ax22.set_xlabel('time (days after 1 jan 2000)')\n",
    "            ax21.set_ylabel('$B_\\\\phi$ (nt)')\n",
    "            ax21.plot(time,Y1,label='total',color='blue')\n",
    "            ax22.plot(time,Y2,label='model',color='green')\n",
    "            ax2.plot(time,SpaceY,label='residue',color='red')\n",
    "            ax2.legend()\n",
    "            ax21.legend()\n",
    "            ax22.legend()\n",
    "\n",
    "            figz=plt.figure(figsize=(20,10))\n",
    "            ax3=figz.add_subplot(311)\n",
    "            ax31=figz.add_subplot(312)\n",
    "            ax32=figz.add_subplot(313)\n",
    "            ax3.set_title('$B_r$ at '+ station + ' on ' + dates[0] + '-' + dates[1] + '-' + dates[2])\n",
    "            ax32.set_xlabel('time (days after 1 jan 2000)')\n",
    "            ax31.set_ylabel('$B_r$ (nt)')\n",
    "            ax31.plot(time,Z1,label='total',color='blue')\n",
    "            ax32.plot(time,Z2,label='model',color='green')\n",
    "            ax3.plot(time,SpaceZ,label='residue',color='red')\n",
    "            ax3.legend()\n",
    "            ax31.legend()\n",
    "            ax32.legend()\n",
    "            plt.show()\n",
    "\n",
    "        if plots:\n",
    "            figall=plt.figure(figsize=(20,10))\n",
    "            ax4=figall.add_subplot(311)\n",
    "            ax41=figall.add_subplot(312)\n",
    "            ax42=figall.add_subplot(313)\n",
    "            ax4.set_title('Radial component')\n",
    "            ax41.set_title('Longitudinal component')\n",
    "            ax41.set_ylabel('nanoteslas')\n",
    "            ax42.set_title('Latitudional component')\n",
    "            ax4.plot(time,SpaceZ,color='red')\n",
    "            ax41.plot(time,SpaceY,color='red')\n",
    "            ax42.plot(time,SpaceX,color='red')\n",
    "            plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/SWresult.png')\n",
    "\n",
    "    ##### calculate frequency spectrum #####\n",
    "        # try to get time derivative, only horizontal components matter\n",
    "        dXdt=np.zeros(len(SpaceX)) # define length array\n",
    "        dYdt=np.zeros(len(SpaceY))\n",
    "\n",
    "        for item in range(len(SpaceX)-1): # obtain derivative\n",
    "            dXdt[item]=SpaceX[item+1]-SpaceX[item]\n",
    "            dYdt[item]=SpaceY[item+1]-SpaceY[item]\n",
    "\n",
    "        if plots:\n",
    "            figx=plt.figure()\n",
    "            ax1=figx.add_subplot()\n",
    "            ax1.set_title('d$B_X$/dt at ' + station)\n",
    "            ax1.set_xlabel('time (days after 1 jan 2000)')\n",
    "            if self.minute:\n",
    "                ax1.set_ylabel(f'd$B_X$/dt (nt/min)')\n",
    "            else:\n",
    "                ax1.set_ylabel(f'd$B_X$/dt (nt/s)')\n",
    "            ax1.plot(time,dXdt,label='residue',color='red')\n",
    "            ax1.legend()\n",
    "            plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/db\\dtX.png')\n",
    "\n",
    "            figy=plt.figure()\n",
    "            ax2=figy.add_subplot()\n",
    "            ax2.set_title('d$B_Y$/dt at ' + station)\n",
    "            ax2.set_xlabel('time (days after 1 jan 2000)')\n",
    "            if self.minute:\n",
    "                ax1.set_ylabel(f'd$B_Y$/dt (nt/min)')\n",
    "            else:\n",
    "                ax1.set_ylabel(f'd$B_Y$/dt (nt/s)')\n",
    "            ax2.plot(time,dYdt,label='residue',color='red')\n",
    "            ax2.legend()\n",
    "\n",
    "            plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/db\\dtY.png')\n",
    "\n",
    "        ### horizontal component ###\n",
    "        Hor_comp=np.sqrt(SpaceX**2+SpaceY**2)\n",
    "        dHdt=np.zeros(len(Hor_comp))\n",
    "        for item in range(len(Hor_comp)-1): # obtain derivative\n",
    "            dHdt[item]=Hor_comp[item+1]-Hor_comp[item]\n",
    "\n",
    "        figH=plt.figure()\n",
    "        ax1=figH.add_subplot(211)\n",
    "        ax1.set_title('horizontal component at ' + station)\n",
    "        ax1.set_xlabel('time')\n",
    "        ax1.set_ylabel('nT')\n",
    "        ax1.plot(time,Hor_comp,color='red')\n",
    "        ax2=figH.add_subplot(212)\n",
    "        ax2.set_xlabel('time')\n",
    "        if self.minute:\n",
    "            ax2.set_ylabel('nT/min')\n",
    "        else:\n",
    "            ax2.set_ylabel('nT/s')\n",
    "        ax2.plot(time,dHdt,color='red')\n",
    "        plt.savefig(f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/Horizontal_data.png')\n",
    "\n",
    "    # ##### save files #####\n",
    "        newfile=pd.DataFrame(columns=['B_theta (nt)','B_phi (nt)','B_r (nt)','B_H','dBx/dt','dBy/dt','dBH/dt'])\n",
    "        newfile['B_theta (nt)']=SpaceX\n",
    "        newfile['B_phi (nt)']=SpaceY\n",
    "        newfile['B_r (nt)']=SpaceZ\n",
    "        newfile['B_H']=Hor_comp\n",
    "        newfile['dBx/dt']=dXdt\n",
    "        newfile['dBy/dt']=dYdt\n",
    "        newfile['dBH/dt']=dHdt\n",
    "        newfile.to_csv(path_or_buf=f'{self.respath}/{self.date}/{station}_{dates[0]}-{dates[1]}-{dates[2]}/allresults.csv', sep=';', index=False, header=True)\n",
    "        plt.close('all')\n",
    "\n",
    "    def ObtainJ(self,q,kabels,EX_matrix,EY_matrix,lat,lon,time,trafo_connect,trafo_all_connections,trafo_cond,trafo,guess,localvar):\n",
    "        import numpy as np\n",
    "        import logging\n",
    "        import pandas as pd\n",
    "        \n",
    "        localvar.cablecheck=np.zeros(len(kabels))\n",
    "        localvar.E_kabels=np.zeros((len(kabels),2))      \n",
    "        logging.info(f'Thread {q} has started integration procedure!')\n",
    "        localvar.E_kabels=self.calcE(kabels,EX_matrix,EY_matrix,lat,lon,time,guess,localvar)\n",
    "        logging.info(f'Thread {q} has finished integration procedure and is now writing results!')\n",
    "        localvar.stat_voltN=np.zeros((len(trafo_connect),len(trafo_connect)))\n",
    "        localvar.stat_voltE=np.zeros((len(trafo_connect),len(trafo_connect)))\n",
    "        localvar.J_north=np.zeros(len(trafo_connect))\n",
    "        localvar.J_east=np.zeros(len(trafo_connect))\n",
    "        for localvar.row,localvar.line in enumerate(trafo_connect):\n",
    "            ruleA=999\n",
    "            for localvar.column,localvar.item in enumerate(localvar.line):\n",
    "                if localvar.item:\n",
    "                    for localvar.number in range(len(kabels)):\n",
    "                        localvar.cablecheck[localvar.number]=trafo_all_connections[localvar.row,localvar.number]+trafo_all_connections[localvar.column,localvar.number]\n",
    "                    localvar.A=np.array(np.where(localvar.cablecheck==2)) #find indices that indicate cables connected\n",
    "\n",
    "                    localvar.coord=trafo.at[localvar.row,'lat']\n",
    "                    for localvar.counter2 in range(len(localvar.A[0])): #double loop to check the cable connections\n",
    "                        for localvar.counter in range(len(localvar.A[0])):\n",
    "                            if abs(localvar.coord-kabels.at[localvar.A[0,localvar.counter],'strtlat'])<0.00001 and abs(ruleA-localvar.A[0,localvar.counter])>0.51: #check coord for which cable is connected and same cable is not allowed!\n",
    "                                localvar.coord=kabels.at[localvar.A[0,localvar.counter],'eindlat']\n",
    "                                ruleA=localvar.A[0,localvar.counter] #rule to ensure that the same cable is not picked again\n",
    "\n",
    "                                # first North component\n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlat'] < kabels.at[localvar.A[0,localvar.counter],'eindlat']:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]*-1\n",
    "                                else:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]\n",
    "                                # now East component    \n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlon'] < kabels.at[localvar.A[0,localvar.counter],'eindlon']:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]*-1\n",
    "                                else:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]\n",
    "                                break                           \n",
    "                            elif abs(localvar.coord-kabels.at[localvar.A[0,localvar.counter],'eindlat'])<0.00001 and abs(ruleA-localvar.A[0,localvar.counter])>0.51:\n",
    "                                ruleA=localvar.A[0,localvar.counter]\n",
    "                                localvar.coord=kabels.at[localvar.A[0,localvar.counter],'strtlat']\n",
    "\n",
    "                                # first North component\n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlat'] < kabels.at[localvar.A[0,localvar.counter],'eindlat']:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]\n",
    "                                else:\n",
    "                                    localvar.stat_voltN[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],0]*-1\n",
    "                                # now East component    \n",
    "                                if kabels.at[localvar.A[0,localvar.counter],'strtlon'] < kabels.at[localvar.A[0,localvar.counter],'eindlon']:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]\n",
    "                                else:\n",
    "                                    localvar.stat_voltE[localvar.row,localvar.column]+=localvar.E_kabels[localvar.A[0,localvar.counter],1]*-1\n",
    "                                break\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "                localvar.J_north[localvar.row]+=localvar.stat_voltN[localvar.row,localvar.column]*trafo_cond[localvar.row,localvar.column]*-1*-1 #extra -1 -1 to get J in opposite direction of E\n",
    "                localvar.J_east[localvar.row]+=localvar.stat_voltE[localvar.row,localvar.column]*trafo_cond[localvar.row,localvar.column]*-1*-1\n",
    "        return localvar.J_north, localvar.J_east\n",
    "    \n",
    "    def Parzen(self,N):\n",
    "        import numpy as np\n",
    "        W=np.zeros(N)\n",
    "        for nr in range(N):\n",
    "            W[nr]=1-(2*(nr-N/2)/N)**8\n",
    "        return W\n",
    "    \n",
    "    def plottinglatlon(self,q,string,string2,start,end,path,lock,lock2):\n",
    "        import logging\n",
    "        proj='-JM15C -P'\n",
    "        lims1='-R0.7/9.6/49/58.3'\n",
    "        lims2='-R3.3/9.6/49/54'\n",
    "        for item in string[start:end]:\n",
    "            with lock:\n",
    "                item2=item.strip('.csv')\n",
    "                nr=item2.strip('minute_')\n",
    "                logging.info(f'Thread {q} has obtained latlock for step {nr}.')\n",
    "                time1=[int(int(nr)/60),int(nr)%60]\n",
    "                time1[0]=str(time1[0]).zfill(2)\n",
    "                time1[1]=str(time1[1]).zfill(2)\n",
    "\n",
    "                os.system(f'gmt xyz2grd {self.respath}/{self.date}/interpolation/{item} -G{self.respath}/{self.date}/interpolation/gridlat{nr}.grd -I0.05 -V -N0 {lims1}')\n",
    "                psfile1=f'{self.respath}/{self.date}/interpolation/minlat_{nr}.ps'\n",
    "                os.system(f'gmt pscoast {proj} {lims2} -W0.25p -Ggrey -Slightblue -N1/0.25p -Df -K> {psfile1}' )\n",
    "                os.system(f'gmt psbasemap {proj} {lims2} -Ba1 -BWeSn+t\"Bx at {day2} -- {time1[0]}:{time1[1]}\" -O -K>> {psfile1}' )\n",
    "                os.system(f'gmt grdcontour {self.respath}/{self.date}/interpolation/gridlat{nr}.grd -C10 -A50+f20p {proj} {lims2} -O >>{psfile1}')\n",
    "                logging.info(f'Thread {q} has released latlock.')\n",
    "            os.system(f'convert -density 300 {psfile1} {self.respath}/{self.date}/interpolation/minlat_{nr}.png')\n",
    "            os.system(f'rm {psfile1}')\n",
    "            os.system(f'rm {self.respath}/{self.date}/interpolation/gridlat{nr}.grd')\n",
    "            logging.info(f'Thread {q} has finished plotting lat for step {nr}.')  \n",
    "\n",
    "        for item in string2[start:end]:\n",
    "            with lock2:\n",
    "                item2=item.strip('.csv.Y')\n",
    "                nr=item2.strip('minute_')\n",
    "                logging.info(f'Thread {q} has obtained lonlock for step {nr}.')\n",
    "                time2=[int(int(nr)/60),int(nr)%60]\n",
    "                time2[0]=str(time2[0]).zfill(2)\n",
    "                time2[1]=str(time2[1]).zfill(2)\n",
    "\n",
    "                os.system(f'gmt xyz2grd {self.respath}/{self.date}/interpolation/{item} -G{self.respath}/{self.date}/interpolation/gridlon{nr}.grd -I0.05 -V -N0 {lims1}')\n",
    "                psfile2=f'{self.respath}/{self.date}/interpolation/minlon_{nr}.ps'\n",
    "                os.system(f'gmt pscoast {proj} {lims2} -W0.25p -Ggrey -Slightblue -N1/0.25p -Df -K> {psfile2}' )\n",
    "                os.system(f'gmt psbasemap {proj} {lims2} -Ba1 -BWeSn+t\"By at {day2} -- {time2[0]}:{time2[1]}\" -O -K>> {psfile2}' )\n",
    "                os.system(f'gmt grdcontour {self.respath}/{self.date}/interpolation/gridlon{nr}.grd -C10 -A50+f20p {proj} {lims2} -O >>{psfile2}')\n",
    "                logging.info(f'Thread {q} has released lonlock.')\n",
    "            os.system(f'convert -density 300 {psfile2} {self.respath}/{self.date}/interpolation/minlon_{nr}.png')\n",
    "            os.system(f'rm {psfile2}')\n",
    "            os.system(f'rm {self.respath}/{self.date}/interpolation/gridlon{nr}.grd')\n",
    "            logging.info(f'Thread {q} has finished plotting lon for step {nr}.')\n",
    "        \n",
    "    def plot_GIC(self,stationlist=None):\n",
    "        # plot timelapse GIC\n",
    "        import matplotlib.pyplot as plt\n",
    "        import os\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        self.check_sampling()\n",
    "        if stationlist==None:\n",
    "            # Dutch stations to plot\n",
    "            A=np.arange(3,21)\n",
    "            B=np.arange(46,54,1)\n",
    "            stationlist=np.hstack([0,1,A,28,29,32,33,35,43,44,B])\n",
    "           \n",
    "        #reading in all GIC files\n",
    "        if self.minute:\n",
    "            os.system(f\"ls {self.respath}/{self.date}/GIC/GIC_*.csv > {self.respath}/{self.date}/temp.txt\")\n",
    "        else:\n",
    "            for item in range(self.samples//10000+1):\n",
    "                os.system(f\"ls {self.respath}/{self.date}/GIC/GIC_{item}*.csv >> {self.respath}/{self.date}/temp.txt\")\n",
    "        f=open(f\"{self.respath}/{self.date}/temp.txt\")\n",
    "        string=[]\n",
    "\n",
    "        GIC_data=np.zeros((self.samples*self.days,self.lentrafo))\n",
    "\n",
    "        for item in f:\n",
    "            item=item.rstrip('\\n')\n",
    "            string.append(item)\n",
    "        string=sorted(string)\n",
    "        for counter,time in enumerate(string):\n",
    "            GIC_file=pd.read_csv(time, delimiter=';')\n",
    "            GIC=GIC_file.to_numpy()\n",
    "            GIC_data[counter]=GIC[:,2]\n",
    "\n",
    "        os.system(f'rm {self.respath}/{self.date}/temp.txt')\n",
    "\n",
    "        stationframe=pd.read_csv(f'{self.netpath}/spreadsheettrafo.csv', delimiter=';')\n",
    "\n",
    "        plt.rcParams.update({'font.size': 14}) \n",
    "        timevector=np.linspace(0,24*self.days,self.samples*self.days)\n",
    "        fig1=plt.figure(figsize=(20,15))\n",
    "        ax1=fig1.add_subplot()\n",
    "        ax1.set_title(f'GIC during {self.date}')\n",
    "        ax1.set_ylabel('GIC (A)')\n",
    "        ax1.set_xlabel('Time (hours)')\n",
    "        for station in stationlist:\n",
    "            ax1.plot(timevector,GIC_data[:,station],label=stationframe.at[station,'naam'])\n",
    "        # plt.subplots_adjust(left=0)\n",
    "        lgd=ax1.legend(bbox_to_anchor=(1.01,1))\n",
    "        plt.savefig(f'{self.respath}/{self.date}/GIC_allstations.png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "            \n",
    "    def plot_magnetic(self):\n",
    "        from multiprocessing import Process\n",
    "        import os\n",
    "        from multiprocessing import Lock\n",
    "        import logging\n",
    "        self.check_sampling()\n",
    "        lock=Lock()\n",
    "        lock2=Lock()\n",
    "\n",
    "        logging.basicConfig(filename=f'{self.respath}/{self.date}/logbookplot.log', level=logging.DEBUG, format='%(asctime)s %(message)s')\n",
    "\n",
    "        thing=os.listdir(f'{self.respath}/{self.date}/interpolation')\n",
    "        string=[]\n",
    "        string2=[]\n",
    "        for item in thing:\n",
    "            if item.endswith(\".csv\"):\n",
    "                 string.append(item)\n",
    "            if item.endswith(\".csv.Y\"):\n",
    "                 string2.append(item)\n",
    "        string=sorted(string)\n",
    "        string2=sorted(string2)\n",
    "        n=6\n",
    "        nrsteps=int(self.samples/n)\n",
    "        threads=list()\n",
    "        for index in range(n):\n",
    "            q=Process(target=self.plottinglatlon, args=(q,string, string2, nrsteps*index, nrsteps*(index+1),locl,lock2))\n",
    "            threads.append(q)\n",
    "            q.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        logging.info('Plotting completed!')\n",
    "        \n",
    "    def standard_download(self,types=True): #download data automatic from intermagnet\n",
    "        import logging\n",
    "        import os\n",
    "        list_of_stations=['fur','had','bfe','clf','dou','esk','ler','ngk','ups','wng']\n",
    "        for station in list_of_stations:\n",
    "            try:\n",
    "                self.download_data(self.day,self.month,self.year,station,types)\n",
    "            except:\n",
    "                logging.warning(f'Data could not be downloaded for station {station}')\n",
    "        if self.qdate==None:\n",
    "            qday, qmonth, qyear = self.find_quiet_date()\n",
    "            qday=str(qday).zfill(2)\n",
    "            qmonth=str(qmonth).zfill(2)\n",
    "            self.qdate=f'{qday}-{qmonth}-{qyear}'\n",
    "            logging.info(f'Quiet day is {self.qdate}')\n",
    "            print(f'Quiet day is {self.qdate}')\n",
    "            try:\n",
    "                self.quietpath=f'{self.base}/{self.qdate}'\n",
    "                os.mkdir(f'{self.base}/{self.qdate}')\n",
    "                for station in list_of_stations:\n",
    "                    try:\n",
    "                        self.download_data(qday,qmonth,qyear,station,types)\n",
    "                    except:\n",
    "                        logging.warning(f'Data could not be downloaded for station {station}')\n",
    "            except:\n",
    "                logging.warning(f\"Directory '{self.quietpath}' might already exist, or cannot be formed\")\n",
    "                \n",
    "    def transferfunction(self,freq,model=1): #Where B is given, NOT H!\n",
    "        import numpy as np\n",
    "        mu=4*np.pi*10**(-7)\n",
    "        if freq<=0:\n",
    "            raise Exception('Frequency cannot be any lower or equal to zero!')\n",
    "        elif freq<10**-5:\n",
    "            Zn=0\n",
    "        else:\n",
    "            if model == 1:\n",
    "                cond=np.zeros((2,4)) #business as usual\n",
    "                cond[0,:]=[1./1.,1./5000.,1./1.,1./10.] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,6000,4000,0] #depth top to bottom in m\n",
    "            elif model == 2:\n",
    "                cond=np.zeros((2,4)) #deep ocean\n",
    "                cond[0,:]=[4.,1./5000.,1./1.,1./10.] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,6000,4000,0] #depth top to bottom in m\n",
    "            elif model == 3:\n",
    "                cond=np.zeros((2,2)) #GIC in Europe paper\n",
    "                cond[0,:]=[1./38.5,1./0.385] #conductivity top to bottom\n",
    "                cond[1,:]=[150000,0] #depth top to bottom in m\n",
    "            elif model == 4:\n",
    "                cond=np.zeros((2,4)) #MODELLING OCEAN EFFECT IN LOCAL C-RESPONSES: oceanic mantle\n",
    "                cond[0,:]=[1./10**3,1./20.,1./2.,1./0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[100000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 5:\n",
    "                cond=np.zeros((2,4)) #MODELLING OCEAN EFFECT IN LOCAL C0-RESPONSES: continental mantle\n",
    "                cond[0,:]=[1./(3*10**3),1./70.,1./16.,1./0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[100000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 6: #Pirjola et al 2014: Geomagnetically induced currents in Europe \n",
    "                cond=np.zeros((2,5))\n",
    "                cond[0,:]=[1./(40),1./3.,1./2000.,1./118., 1/15.] #conductivity top to bottom\n",
    "                cond[1,:]=[400,1300,140000,170000,0] #depth top to bottom in m\n",
    "            elif model == 7: # combi model \n",
    "                cond=np.zeros((2,7))\n",
    "                cond[0,:]=[1.,1./5000.,1.,1./(3*10**3),1/70.,1/16.,1/0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,6000,4000,88000,400000,200000,0] #depth top to bottom in m\n",
    "            elif model == 8: # test model \n",
    "                cond=np.zeros((2,6))\n",
    "                cond[0,:]=[1.,1./5000.,1./(3*10**3),1/70.,1/16.,1/0.42] #conductivity top to bottom\n",
    "                cond[1,:]=[2000,10000,88000,400000,200000,0] #depth top to bottom in m\n",
    "            else:\n",
    "                cond=np.zeros((2,5)) #bit of water (50m)\n",
    "                cond[0,:]=[4,1./1.,1./5000.,1./1.,1./10.] #conductivity top to bottom\n",
    "                cond[1,:]=[50,2000,6000,4000,0] #depth top to bottom in m\n",
    "\n",
    "            #first do bottom layer\n",
    "            kn=np.sqrt(1j*freq*mu*cond[0,-1])\n",
    "            Zn=1j*freq*mu/kn\n",
    "\n",
    "            # iterate from bottom to top\n",
    "            for item in range(2,len(cond[0])+1): #we go in opposite direction later, see Trichtchenko and Boteler (2002)\n",
    "                kn=np.sqrt(1j*freq*mu*cond[0,-item])\n",
    "                rn=(1-kn*(Zn/(1j*freq*mu)))/(1+kn*(Zn/(1j*freq*mu)))\n",
    "                Zn=1j*freq*mu*((1-rn*np.exp(-2*kn*cond[1,-item]))/(kn*(1+rn*np.exp(-2*kn*cond[1,-item]))))\n",
    "\n",
    "        return Zn/mu\n",
    "\n",
    "######################## writing results ###########################################\n",
    "    def writing_electric(self,thread,path,Electric,begin,end,lon,lat,localvar):\n",
    "        import logging\n",
    "        import pandas as pd\n",
    "        for localvar.item in range(begin,end):\n",
    "            logging.info(f'Thread {thread} is writing step {localvar.item}.')\n",
    "            localvar.newfile=pd.DataFrame(columns=['lon','lat','value'])\n",
    "            localvar.newfile.at[:,'lon']=lon\n",
    "            localvar.newfile.at[:,'lat']=lat\n",
    "            localvar.newfile.at[:,'value']=Electric[localvar.item,:]\n",
    "            \n",
    "            if self.minute:\n",
    "                localvar.newfile.to_csv(path_or_buf=f'{path}/electric_{str(localvar.item).zfill(4)}.csv', sep=' ', index=False, header=False)\n",
    "            else:\n",
    "                localvar.newfile.to_csv(path_or_buf=f'{path}/electric_{str(localvar.item).zfill(5)}.csv', sep=' ', index=False, header=False)\n",
    "        \n",
    "    def runall(self,model=7,guess=80,plotgic=True):\n",
    "        import logging\n",
    "        logging.basicConfig(filename=f'{self.respath}/logbook.log', level=logging.DEBUG, format='%(asctime)s %(message)s')\n",
    "        logging.info('Script starting')\n",
    "        \n",
    "        self.standard_download()\n",
    "        self.iteratestation()\n",
    "        self.magnetic_interpolation()\n",
    "        self.BtoE(model)\n",
    "        if plotgic:\n",
    "            self.calculate_GIC(guess)\n",
    "            self.plot_GIC()\n",
    "            self.make_video(f'{self.respath}/{self.date}/GIC/GIC_at_',f'GIC_at_{self.date}')\n",
    "        else:\n",
    "            self.calculate_GIC(guess,False)\n",
    "            self.plot_GIC()\n",
    "        logging.info('Script has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiet day is 04-08-2004\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "1440\n",
      "['/nobackup/users/out/Magnetic_field/27-07-2004/Brorfelde_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Chambon_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Dourbes_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Eskdalemuir_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Furstenfeldbruck_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Hartland_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Lerwick_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Niemegk_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Uppsala_2004-07-27', '/nobackup/users/out/Magnetic_field/27-07-2004/Wingst_2004-07-27']\n",
      "setting up matrices!\n",
      "starting fourier transformation\n",
      "New data is added now!\n"
     ]
    }
   ],
   "source": [
    "# stationlist=[0,1]\n",
    "Halloween=GIC('/usr/people/out/Documents/380+220kV_extended','/usr/people/out/Documents/Magnetic_field/magnetic_data','/nobackup/users/out/Magnetic_field','27-07-2004')\n",
    "Halloween.runall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('shutdown now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Look Out! self.day is now changed from None to BigTest!\n",
      "WARNING:root:Directory \"/nobackup/users/out/Magnetic_field/BigTest\" is already created, data could be lost forever!\n",
      "WARNING:root:Directory \"/nobackup/users/out/Magnetic_field/BigTest/interpolation\" is already created, data could be lost forever!\n"
     ]
    }
   ],
   "source": [
    "Hallotest=GIC('/usr/people/out/Documents/380+220kV_extended','/usr/people/out/Documents/Magnetic_field/magnetic_data','/nobackup/users/out/Magnetic_field')\n",
    "Hallotest.glue_data(['/nobackup/users/out/Magnetic_field/29-10-2003/interpolation','/nobackup/users/out/Magnetic_field/30-10-2003/interpolation','/nobackup/users/out/Magnetic_field/31-10-2003/interpolation'],'BigTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi2\n"
     ]
    }
   ],
   "source": [
    "samples=len([name for name in os.listdir(f'/nobackup/users/out/Magnetic_field/sec_17-03-2015_2/interpolation') if os.path.isfile(os.path.join(f'/nobackup/users/out/Magnetic_field/sec_17-03-2015_2/interpolation', name))])/2\n",
    "if samples%(24*60*60)==0:\n",
    "    minute=False\n",
    "    print('hi1')\n",
    "elif samples%(24*60)==0:\n",
    "    minute=True\n",
    "    print('hi2')\n",
    "else:\n",
    "    raise Exception(\"Data is missing, or it is no minute or second data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
